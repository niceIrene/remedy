{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "772S9aKIfv-9"
      },
      "source": [
        "#Imports and Dataset processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Evnn9BbOfEme"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "import copy\n",
        "from sympy import Symbol\n",
        "from sympy.solvers import solve\n",
        "pd.options.mode.chained_assignment = None\n",
        "import csv\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Dataset"
      ],
      "metadata": {
        "id": "zZcs6RchRAWy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "_vP0FN3vfgjA",
        "outputId": "6bb16e18-3f25-4fd2-dc6f-d3abdf47e892"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
              "0        0          2  226802          1                7               4   \n",
              "1        1          2   89814         11                9               2   \n",
              "2        0          1  336951          7               12               2   \n",
              "3        1          2  160323         15               10               2   \n",
              "4        1          2  198693          0                6               4   \n",
              "...    ...        ...     ...        ...              ...             ...   \n",
              "45217    0          2  257302          7               12               2   \n",
              "45218    1          2  154374         11                9               2   \n",
              "45219    2          2  151910         11                9               6   \n",
              "45220    0          2  201490         11                9               4   \n",
              "45221    2          3  287927         11                9               2   \n",
              "\n",
              "       occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
              "0               6             3     2       1             0             0   \n",
              "1               4             0     4       1             0             0   \n",
              "2              10             0     4       1             0             0   \n",
              "3               6             0     2       1             1             0   \n",
              "4               7             1     4       1             0             0   \n",
              "...           ...           ...   ...     ...           ...           ...   \n",
              "45217          12             5     4       0             0             0   \n",
              "45218           6             0     4       1             0             0   \n",
              "45219           0             4     4       0             0             0   \n",
              "45220           0             3     4       1             0             0   \n",
              "45221           3             5     4       0             1             0   \n",
              "\n",
              "       hours-per-week  native-country  income  \n",
              "0                   0              38       0  \n",
              "1                   1              38       0  \n",
              "2                   0              38       1  \n",
              "3                   0              38       1  \n",
              "4                   0              38       0  \n",
              "...               ...             ...     ...  \n",
              "45217               0              38       0  \n",
              "45218               0              38       1  \n",
              "45219               0              38       0  \n",
              "45220               0              38       0  \n",
              "45221               0              38       1  \n",
              "\n",
              "[45222 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64eef508-0b11-4b9c-a256-43df2d9f4034\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>educational-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>226802</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>89814</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>336951</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>160323</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>198693</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45217</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>257302</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45218</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>154374</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45219</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>151910</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45220</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>201490</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45221</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>287927</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45222 rows × 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64eef508-0b11-4b9c-a256-43df2d9f4034')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-64eef508-0b11-4b9c-a256-43df2d9f4034 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-64eef508-0b11-4b9c-a256-43df2d9f4034');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e9de97bc-6cd1-4488-893d-fa2d014e6175\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e9de97bc-6cd1-4488-893d-fa2d014e6175')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e9de97bc-6cd1-4488-893d-fa2d014e6175 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 45222,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"num_unique_values\": 3,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"samples\": [\n          2,\n          1,\n          3\n        ],\n        \"num_unique_values\": 7,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fnlwgt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105639,\n        \"min\": 13492,\n        \"max\": 1490400,\n        \"samples\": [\n          196001,\n          177449,\n          125531\n        ],\n        \"num_unique_values\": 26741,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 15,\n        \"samples\": [\n          1,\n          11,\n          14\n        ],\n        \"num_unique_values\": 16,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"educational-num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 16,\n        \"samples\": [\n          7,\n          9,\n          15\n        ],\n        \"num_unique_values\": 16,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital-status\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"samples\": [\n          4,\n          2,\n          3\n        ],\n        \"num_unique_values\": 7,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 13,\n        \"samples\": [\n          11,\n          13,\n          6\n        ],\n        \"num_unique_values\": 14,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"samples\": [\n          3,\n          0,\n          2\n        ],\n        \"num_unique_values\": 6,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 4,\n        \"samples\": [\n          4,\n          1,\n          3\n        ],\n        \"num_unique_values\": 5,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital-gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital-loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours-per-week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"native-country\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 40,\n        \"samples\": [\n          1,\n          34\n        ],\n        \"num_unique_values\": 41,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "\n",
        "url = \"https://raw.githubusercontent.com/niceIrene/remedy/main/datasets/CleanAdult_numerical_cat.csv\"\n",
        "data = pd.read_csv(url)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NNSifBfwflg8"
      },
      "outputs": [],
      "source": [
        "# get training and testing set\n",
        "\n",
        "# protected attributes\n",
        "columns_compas = ['age', 'marital-status','relationship', 'race','gender',\n",
        "                                          'native-country']\n",
        "\n",
        "# all columns of dataset\n",
        "columns_all = ['age', 'workclass','education', 'educational-num', 'marital-status', 'occupation', 'relationship', 'race','gender', 'capital-gain', 'capital-loss','hours-per-week', 'native-country']\n",
        "\n",
        "compas_y = 'income'\n",
        "def split_train_test(data,test_ratio):\n",
        "    np.random.seed(42)\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices],data.iloc[test_indices]\n",
        "\n",
        "def get_train_test(data, split, list_cols, y_label):\n",
        "  all_list = copy.deepcopy(list_cols)\n",
        "  all_list.append(y_label)\n",
        "  data = pd.DataFrame(data, columns = all_list)\n",
        "  train_set,test_set = split_train_test(data,split)\n",
        "  print(len(train_set), \"train +\", len(test_set), \"test\")\n",
        "  train_x = pd.DataFrame(train_set, columns = list_cols)\n",
        "  train_label = train_set[y_label]\n",
        "  test_x = pd.DataFrame(test_set, columns = list_cols)\n",
        "  test_label = test_set[y_label]\n",
        "  return train_x, test_x, train_label, test_label, train_set, test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJQsq95bfpEH",
        "outputId": "7821d1af-83f1-497c-e149-08458b4c306c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31656 train + 13566 test\n"
          ]
        }
      ],
      "source": [
        "train_x, test_x, train_label, test_label, train_set, test_set  = get_train_test(data, 0.3, columns_all, compas_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f-rnfp9XfuKM"
      },
      "outputs": [],
      "source": [
        "def fpr_onegroup(true, predict):\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    for i in range(len(true)):\n",
        "        if (true[i] == 0 and predict[i] == 1):\n",
        "            fp += 1\n",
        "        if(true[i] == 0 and predict[i] == 0):\n",
        "            tn += 1\n",
        "    return fp/(fp+tn)\n",
        "\n",
        "\n",
        "def fnr_onegroup(true, predict):\n",
        "    fn = 0\n",
        "    tp = 0\n",
        "    for i in range(len(true)):\n",
        "        if (true[i] == 1 and predict[i] == 0):\n",
        "            fn += 1\n",
        "        if(true[i] == 1 and predict[i] == 1):\n",
        "            tp += 1\n",
        "    return fn/(fn+tp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize ML models of Choice"
      ],
      "metadata": {
        "id": "Xt_fu6CnRsqx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "asgU_pEhAOlK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, make_scorer\n",
        "\n",
        "\n",
        "filter_count = 30\n",
        "\n",
        "\n",
        "\n",
        "scoring = make_scorer(accuracy_score)\n",
        "\n",
        "\n",
        "# #####################\n",
        "param_gridlg = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "gridlg = GridSearchCV(logreg, param_grid=param_gridlg, scoring=scoring, cv=5)\n",
        "# #####################\n",
        "param_griddt = {\n",
        "    'max_depth': [2, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "griddt = GridSearchCV(dt, param_grid=param_griddt, scoring=scoring, cv=5)\n",
        "\n",
        "# #####################\n",
        "param_gridrf = {'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 100], 'random_state':[17]}\n",
        "# param_gridrf = {\n",
        "#     'max_depth': [10, 20, 30],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4],\n",
        "# }\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "gridrf = GridSearchCV(rf, param_grid=param_gridrf, scoring=scoring, cv=5)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmhcs6wcgGiZ"
      },
      "source": [
        "# Divexplorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVt4YIpUgKlo",
        "outputId": "13b2a2c6-aba3-4d2d-be24-3582aa6c7ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting DivExplorer==0.1.1\n",
            "  Downloading divexplorer-0.1.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: ipywidgets>=7.2.1 in /usr/local/lib/python3.10/dist-packages (from DivExplorer==0.1.1) (7.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from DivExplorer==0.1.1) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.10/dist-packages (from DivExplorer==0.1.1) (1.25.2)\n",
            "Requirement already satisfied: mlxtend>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from DivExplorer==0.1.1) (0.22.0)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from DivExplorer==0.1.1) (1.5.3)\n",
            "Requirement already satisfied: plotly>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from DivExplorer==0.1.1) (5.15.0)\n",
            "Collecting python-igraph>=0.8.3 (from DivExplorer==0.1.1)\n",
            "  Downloading python_igraph-0.11.4-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from DivExplorer==0.1.1) (1.2.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.2.1->DivExplorer==0.1.1) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.2.1->DivExplorer==0.1.1) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.2.1->DivExplorer==0.1.1) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.2.1->DivExplorer==0.1.1) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.2.1->DivExplorer==0.1.1) (3.0.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->DivExplorer==0.1.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->DivExplorer==0.1.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->DivExplorer==0.1.1) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->DivExplorer==0.1.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->DivExplorer==0.1.1) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->DivExplorer==0.1.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->DivExplorer==0.1.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->DivExplorer==0.1.1) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from mlxtend>=0.17.1->DivExplorer==0.1.1) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend>=0.17.1->DivExplorer==0.1.1) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from mlxtend>=0.17.1->DivExplorer==0.1.1) (67.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->DivExplorer==0.1.1) (2023.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.5.0->DivExplorer==0.1.1) (8.2.3)\n",
            "Collecting igraph==0.11.4 (from python-igraph>=0.8.3->DivExplorer==0.1.1)\n",
            "  Downloading igraph-0.11.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable>=1.6.2 (from igraph==0.11.4->python-igraph>=0.8.3->DivExplorer==0.1.1)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->DivExplorer==0.1.1) (3.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.2.1->DivExplorer==0.1.1) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.2.1->DivExplorer==0.1.1) (6.3.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets>=7.2.1->DivExplorer==0.1.1)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.1->DivExplorer==0.1.1) (1.16.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (3.1.3)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (5.7.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (4.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (4.19.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.17.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->DivExplorer==0.1.1) (2.21)\n",
            "Installing collected packages: texttable, jedi, igraph, python-igraph, DivExplorer\n",
            "Successfully installed DivExplorer-0.1.1 igraph-0.11.4 jedi-0.19.1 python-igraph-0.11.4 texttable-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install DivExplorer==0.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tb3zgDbUgXcV"
      },
      "outputs": [],
      "source": [
        "def fairness_score_computation(d, metrics):\n",
        "    sum_of_score = 0\n",
        "    for idx, row in d.iterrows():\n",
        "      sum_of_score += row['support'] * row[metrics]\n",
        "    return sum_of_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wq83r2kCMpr3"
      },
      "outputs": [],
      "source": [
        "def get_test_predict(gridalg, train_x, alg_name):\n",
        "  gridalg.fit(train_x, train_label)\n",
        "  print(\"best {}\".format(alg_name), gridalg.best_score_)\n",
        "  test_predict = gridalg.predict(test_x)\n",
        "  data_all = pd.concat([train_x,test_x])\n",
        "  data_predict = gridalg.predict(data_all)\n",
        "  test_predict = gridalg.predict(test_x)\n",
        "  data['predicted'] = data_predict\n",
        "  test_set['predicted'] = test_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yBfBWDzuMh3v"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # for SVC\n",
        "clf = SVC(kernel='rbf', C=6.0, gamma = 100, random_state =42)\n",
        "# clf.fit(train_x, train_label)\n",
        "# test_predict = clf.predict(test_x)\n",
        "# test_set['predicted'] = test_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1QotGAAo9Y7F"
      },
      "outputs": [],
      "source": [
        "with open('Adult_results.csv', 'w', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow([\"Dataset\",\"Remedy\", \"Algorithm\",\"d_fpr\",\"d_fnr\", \"d_acc\", \"model_acc\"])\n",
        "  # writer.writerow([\"Adult\", \"Original\", \"DT\", dfpr, dfnr, dacc, accuracy])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf1ffb1bggPp"
      },
      "source": [
        "# For entire dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aU9MirNCglkA"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "def get_unfair_group(list_parse, entire = 1):\n",
        "  unfair_group = []\n",
        "  unfair_dict = {}\n",
        "  names = []\n",
        "  for col in columns_compas:\n",
        "    found = False\n",
        "    for item in list_parse:\n",
        "      attr_given = item.split(\"=\")[0]\n",
        "      if col == attr_given:\n",
        "        unfair_group.append(int(item.split(\"=\")[1]))\n",
        "        names.append(attr_given)\n",
        "        unfair_dict[attr_given] = int(item.split(\"=\")[1])\n",
        "        found = True\n",
        "  # if use the entire dataset\n",
        "  if entire:\n",
        "    return unfair_group, names, columns_compas, unfair_dict\n",
        "        # break\n",
        "    # if found == False:\n",
        "    #   unfair_group.append(-1)\n",
        "  return unfair_group, names, list(set(columns_compas).symmetric_difference(set(names))), unfair_dict\n",
        "def candidate_groups(skew_candidates, unfair_dict, ordering, names):\n",
        "  candidate_combos = []\n",
        "  candidate_ind = {}\n",
        "  num = 0\n",
        "  for i in range(len(skew_candidates)+1):\n",
        "    temp_candidate = list(itertools.combinations(skew_candidates, i))\n",
        "    for tc in temp_candidate:\n",
        "      candidate_ind[num] = list(tc)\n",
        "      num += 1\n",
        "  return candidate_ind\n",
        "\n",
        "def name_val_dict(train_set,names):\n",
        "  names_values = {}\n",
        "  for n in names:\n",
        "    names_values[n] = list(train_set[n].unique())\n",
        "  return names_values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZgdhgqYZjTci",
        "outputId": "8ee193ed-e068-4181-d98b-d429e7b693b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age  marital-status  relationship  race  gender  native-country  income  \\\n",
              "0       0               0             1     0       0              38       0   \n",
              "1       0               0             1     0       1              38       0   \n",
              "2       0               0             1     0       1              38       1   \n",
              "3       0               0             1     1       1              18       1   \n",
              "4       0               0             1     1       1              29       0   \n",
              "...   ...             ...           ...   ...     ...             ...     ...   \n",
              "1743    2               6             4     4       0              38       1   \n",
              "1744    2               6             4     4       1               7       1   \n",
              "1745    2               6             4     4       1              25       1   \n",
              "1746    2               6             4     4       1              38       0   \n",
              "1747    2               6             4     4       1              38       1   \n",
              "\n",
              "      cnt  \n",
              "0       4  \n",
              "1       4  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  \n",
              "...   ...  \n",
              "1743    8  \n",
              "1744    1  \n",
              "1745    1  \n",
              "1746   17  \n",
              "1747   10  \n",
              "\n",
              "[1748 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98d2e293-c377-45b7-b6be-4d6b224c4965\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1743</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1745</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1746</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1747</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1748 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98d2e293-c377-45b7-b6be-4d6b224c4965')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98d2e293-c377-45b7-b6be-4d6b224c4965 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98d2e293-c377-45b7-b6be-4d6b224c4965');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f2f66fef-fa58-480b-8bb4-e876cd75b6ab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2f66fef-fa58-480b-8bb4-e876cd75b6ab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f2f66fef-fa58-480b-8bb4-e876cd75b6ab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "temp2",
              "summary": "{\n  \"name\": \"temp2\",\n  \"rows\": 1748,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"num_unique_values\": 3,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital-status\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"samples\": [\n          0,\n          1,\n          5\n        ],\n        \"num_unique_values\": 7,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"samples\": [\n          1,\n          2,\n          5\n        ],\n        \"num_unique_values\": 6,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"num_unique_values\": 5,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"native-country\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 0,\n        \"max\": 40,\n        \"samples\": [\n          6,\n          22\n        ],\n        \"num_unique_values\": 41,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cnt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 144,\n        \"min\": 1,\n        \"max\": 3416,\n        \"samples\": [\n          24,\n          173\n        ],\n        \"num_unique_values\": 105,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "def get_temp(train_set, names, y_label):\n",
        "  names2 = copy.deepcopy(names)\n",
        "  names2.append(y_label)\n",
        "  temp = train_set[names2]\n",
        "  temp['cnt'] = 0\n",
        "  temp2 = temp.groupby(names2)['cnt'].count().reset_index()\n",
        "  temp2['cnt'].sum()\n",
        "  return temp2, names\n",
        "temp2, names = get_temp(train_set, columns_compas, compas_y)\n",
        "temp2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uuEIYpHwjg_H"
      },
      "outputs": [],
      "source": [
        "def get_temp_g(train_set, names, y_label):\n",
        "  names2 = copy.deepcopy(names)\n",
        "  names2.append(y_label)\n",
        "  temp = train_set[names2]\n",
        "  temp['cnt'] = 0\n",
        "  temp_g = temp.groupby(names)['cnt'].count().reset_index()\n",
        "  return temp, temp_g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMrAfuoDtjAQ",
        "outputId": "7472eb99-2a05-4a78-d33a-a2f4f6ee40e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[] [] ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[63,\n",
              " 62,\n",
              " 61,\n",
              " 60,\n",
              " 59,\n",
              " 58,\n",
              " 57,\n",
              " 56,\n",
              " 55,\n",
              " 54,\n",
              " 53,\n",
              " 52,\n",
              " 51,\n",
              " 50,\n",
              " 49,\n",
              " 48,\n",
              " 47,\n",
              " 46,\n",
              " 45,\n",
              " 44,\n",
              " 43,\n",
              " 42,\n",
              " 41,\n",
              " 40,\n",
              " 39,\n",
              " 38,\n",
              " 37,\n",
              " 36,\n",
              " 35,\n",
              " 34,\n",
              " 33,\n",
              " 32,\n",
              " 31,\n",
              " 30,\n",
              " 29,\n",
              " 28,\n",
              " 27,\n",
              " 26,\n",
              " 25,\n",
              " 24,\n",
              " 23,\n",
              " 22,\n",
              " 21,\n",
              " 20,\n",
              " 19,\n",
              " 18,\n",
              " 17,\n",
              " 16,\n",
              " 15,\n",
              " 14,\n",
              " 13,\n",
              " 12,\n",
              " 11,\n",
              " 10,\n",
              " 9,\n",
              " 8,\n",
              " 7,\n",
              " 6,\n",
              " 5,\n",
              " 4,\n",
              " 3,\n",
              " 2,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "unfair_group, unfair_names, skew_candidates, unfair_dict = get_unfair_group([])\n",
        "print(unfair_group, unfair_names, skew_candidates, unfair_dict)\n",
        "all_names = candidate_groups(skew_candidates, unfair_dict, columns_compas, unfair_names)\n",
        "names_values = name_val_dict(train_set, names)\n",
        "\n",
        "all_names_lst = list(all_names.keys())[1:] # CHANGED HERE\n",
        "all_names_lst.reverse()\n",
        "all_names_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TttueBgvg53C"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4TwHPK4hd0A"
      },
      "source": [
        "## General Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wvC9RSgZkD80"
      },
      "outputs": [],
      "source": [
        "def get_one_degree_neighbors(temp2, names, group_lst):\n",
        "    result = []\n",
        "    for i in range(len(group_lst)):\n",
        "        d = copy.copy(temp2)\n",
        "        for k in range(len(group_lst)):\n",
        "            if k != i:\n",
        "                d = d[d[names[k]] == group_lst[k]]\n",
        "            else:\n",
        "                d = d[d[names[k]] != group_lst[k]]\n",
        "        # print(d)\n",
        "        result.append(d)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sGQalez0kLkE"
      },
      "outputs": [],
      "source": [
        "# compute the pos/neg ration of this neighbor\n",
        "def compute_neighbors(group_lst, result):\n",
        "    # compute the ratio of positive and negative records\n",
        "    start2 = time.time()\n",
        "    pos = 0\n",
        "    neg = 0\n",
        "    for r in result:\n",
        "        total  = r['cnt'].sum()\n",
        "        r = r[r[compas_y] == 1]\n",
        "        pos += r['cnt'].sum()\n",
        "        neg += total - r['cnt'].sum()\n",
        "    if(neg == 0):\n",
        "        return (pos, neg, -1)\n",
        "    end2 = time.time()\n",
        "    # print(\"The time to compute the neighbor counts for \" +  str(group_lst) +\" is \" + str(end2-start2))\n",
        "    return(pos, neg, pos/neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ijabVWcBjtCh"
      },
      "outputs": [],
      "source": [
        "def compute_diff_add_and_remove(group_lst, temp2, need_positive_or_negative, label, names):\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "        # print(len(d))\n",
        "    total =  d['cnt'].sum()\n",
        "    # Total here was 0: here, errors when this is commented out\n",
        "    if total == 0:\n",
        "      return -1\n",
        "    d = d[d[label] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    # print(d, group_lst)\n",
        "    neg = total - pos\n",
        "    result = get_one_degree_neighbors(temp2,names, group_lst)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(need_positive_or_negative == 1):\n",
        "        # need pos\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve((pos + x)/ (neg - x) - neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "\n",
        "    else:\n",
        "        #need negative\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve((pos - x)/ (neg + x) - neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "    return diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TH7YGCuh69D7"
      },
      "outputs": [],
      "source": [
        "def compute_diff_add(group_lst, temp2, names, label_y, need_positive_or_negative):\n",
        "    d = copy.copy(temp2)\n",
        "\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label_y] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    result = get_one_degree_neighbors(temp2, names, group_lst)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(need_positive_or_negative == 1):\n",
        "\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve((pos + x)/ neg -  neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "\n",
        "        print(neighbors[2], pos, neg, diff)\n",
        "    else:\n",
        "        #need negative\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve(pos/ (neg + x) -  neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "    print(neighbors[2], pos, neg, diff)\n",
        "    return diff\n",
        "\n",
        "def compute_diff_remove(group_lst, temp2, names, label_y, need_positive_or_negative):\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label_y] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    result = get_one_degree_neighbors(temp2, names, group_lst)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(need_positive_or_negative == 1):\n",
        "        # need pos, remove some neg\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve( pos/ (neg - x) -  neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "        print(neighbors[2], pos, neg, diff)\n",
        "    else:\n",
        "        #need negative\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve((pos -x )/ neg -  neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "        print(neighbors[2], pos, neg, diff)\n",
        "    return diff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZNtlejsp3sA_"
      },
      "outputs": [],
      "source": [
        "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "\n",
        "def div_results(db, remedy, algo):\n",
        "  columns_compas.extend([compas_y, \"predicted\"])\n",
        "\n",
        "  df = pd.DataFrame(test_set, columns = columns_compas)\n",
        "\n",
        "  columns_compas.remove(compas_y)\n",
        "  columns_compas.remove('predicted')\n",
        "  class_map={'N': 0, 'P': 1}\n",
        "\n",
        "  min_sup=0.1\n",
        "\n",
        "\n",
        "\n",
        "  fp_diver=FP_DivergenceExplorer(df,compas_y, \"predicted\", class_map=class_map)\n",
        "  FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "  from divexplorer.FP_Divergence import FP_Divergence\n",
        "  fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "  fp_divergence_fnr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "  fp_divergence_acc=FP_Divergence(FP_fm, \"d_accuracy\")\n",
        "\n",
        "  INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "  INFO_VIZ2=[\"support\", \"itemsets\",  fp_divergence_fnr.metric, fp_divergence_fnr.t_value_col]\n",
        "  INFO_VIZ3=[\"support\", \"itemsets\",  fp_divergence_acc.metric, fp_divergence_acc.t_value_col]\n",
        "\n",
        "  K=200\n",
        "  # summerization\n",
        "  eps=0.01\n",
        "\n",
        "\n",
        "\n",
        "  d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ]\n",
        "  d2 = fp_divergence_fnr.getDivergence(th_redundancy=eps)[INFO_VIZ2]\n",
        "  d3 = fp_divergence_acc.getDivergence(th_redundancy=eps)[INFO_VIZ3]\n",
        "\n",
        "\n",
        "  d= d[d['d_fpr'] > 0]\n",
        "  d2= d2[d2['d_fnr'] > 0]\n",
        "  d3= d3[d3['d_accuracy'] > 0]\n",
        "\n",
        "  dfpr = fairness_score_computation(d, 'd_fpr')\n",
        "  dfnr = fairness_score_computation(d2, 'd_fnr')\n",
        "  dacc = fairness_score_computation(d3, 'd_accuracy')\n",
        "  print(dfpr)\n",
        "  print(dfnr)\n",
        "  print(dacc)\n",
        "  accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "  print(\"accuracy is \" , accuracy)\n",
        "  writelist = [db,remedy,algo, dfpr, dfnr, dacc, accuracy]\n",
        "  with open('Adult_results.csv', 'a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(writelist)\n",
        "  print(writelist)\n",
        "  return d,d2,d3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iEQ83nxkQr4"
      },
      "source": [
        "## Optimized Helper Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuxfZHSlhXNR",
        "outputId": "ed7ecd51-c6c1-4686-e393-10fc42268705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# helper function for optimized\n",
        "def compute_neighbors_opt(group_lst,lst_of_counts, pos, neg):\n",
        "    #start2 = time.time()\n",
        "    times = len(group_lst)\n",
        "    pos_cnt = 0\n",
        "    neg_cnt = 0\n",
        "    for i in range(times):\n",
        "        df_groupby = lst_of_counts[i]\n",
        "        temp_group_lst_pos = copy.copy(group_lst)\n",
        "        temp_group_lst_neg = copy.copy(group_lst)\n",
        "        del temp_group_lst_pos[i]\n",
        "        del temp_group_lst_neg[i]\n",
        "        # count positive\n",
        "        temp_group_lst_pos.append(1)\n",
        "        group_tuple_pos = tuple(temp_group_lst_pos)\n",
        "        if group_tuple_pos in df_groupby.keys():\n",
        "            pos_cnt += df_groupby[group_tuple_pos]\n",
        "        else:\n",
        "            pos_cnt += 0\n",
        "        # count negative\n",
        "        temp_group_lst_neg.append(0)\n",
        "        group_tuple_neg = tuple(temp_group_lst_neg)\n",
        "        if group_tuple_neg in df_groupby.keys():\n",
        "            neg_cnt += df_groupby[group_tuple_neg]\n",
        "        else:\n",
        "            neg_cnt += 0\n",
        "    pos_val = pos_cnt - times* pos\n",
        "    neg_val = neg_cnt - times* neg\n",
        "    #end2 = time.time()\n",
        "    #print(\"The time to compute the neighbor counts for \" +  str(group_lst) +\" is \" + str(end2-start2))\n",
        "    if neg_val == -1 or (neg_val == 0 and pos_val == 0):\n",
        "        return (pos_val, neg_val, -1)\n",
        "    if pos_val == 0 or neg_val == 0:\n",
        "        return (pos_val, neg_val, 0)\n",
        "    # print(\"here\", pos_val, neg_val, pos_val/neg_val)\n",
        "\n",
        "    return (pos_val, neg_val, pos_val/neg_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Iny4kJhm4V",
        "outputId": "2c7f09bf-cfbf-4df6-eac8-118eb29d24bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# get the list of neighbors\n",
        "def get_one_degree_neighbors_opt(group_lst):\n",
        "    start1 = time.time()\n",
        "    result = []\n",
        "    for i in range(len(group_lst)):\n",
        "        d = copy.copy(group_lst)\n",
        "        d[i] = 'x'\n",
        "        result.append(d)\n",
        "    end1 = time.time()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MmwA0X5hofE",
        "outputId": "ddb9db5a-83d0-4503-bb5e-b2bc91d7930d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def determine_problematic_opt(group_lst, names, temp2, lst_of_counts, label, threshold= 0.3):\n",
        "    #0: ok group, 1: need negative records, 2: need positive records\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    neighbors = compute_neighbors_opt(group_lst,lst_of_counts, pos, neg)\n",
        "    if(neighbors[2] == -1):\n",
        "        # there is no neighbors\n",
        "        return 0\n",
        "    if(total > 30):\n",
        "        # need to be large enough, need to adjust with different datasets.\n",
        "        if neg == 0:\n",
        "            if (pos > neighbors[2]):\n",
        "                return 1\n",
        "            if(pos <= neighbors[2]):\n",
        "                return 0\n",
        "        if (pos/(neg) - neighbors[2] > threshold):\n",
        "            # too many positive records\n",
        "            return 1\n",
        "        if (neighbors[2] - pos/(neg) > threshold):\n",
        "            return 2\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A76VlG-bhqqS",
        "outputId": "953c5b1f-be2d-4a88-d543-42521dabba47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def compute_problematic_opt(temp2, temp_g, names, label, lst_of_counts):\n",
        "    need_pos = []\n",
        "    need_neg = []\n",
        "    for index, row in temp_g.iterrows():\n",
        "        group_lst = []\n",
        "        for n in names:\n",
        "            group_lst.append(row[n])\n",
        "        problematic = determine_problematic_opt(group_lst, names, temp2, lst_of_counts,label)\n",
        "#         #print(problematic)\n",
        "        if(problematic == 1):\n",
        "            if group_lst not in need_neg:\n",
        "                need_neg.append(group_lst)\n",
        "        if(problematic == 2):\n",
        "            if group_lst not in need_pos:\n",
        "                need_pos.append(group_lst)\n",
        "    return need_pos, need_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZd2c6PAhtTH",
        "outputId": "bf3cb532-6e43-4e18-c902-5be62432e2ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# build the list of X00\n",
        "def compute_lst_of_counts(temp, names, label):\n",
        "    # get the list of group-by attributes\n",
        "    lst_of_counts = []\n",
        "    for i in range(len(names)):\n",
        "        grp_names = copy.copy(names)\n",
        "        del grp_names[i]\n",
        "        grp_names.append(label)\n",
        "        temp_df = temp.groupby(grp_names)['cnt'].count()\n",
        "        lst_of_counts.append(temp_df)\n",
        "    return lst_of_counts\n",
        "\n",
        "def get_tuple(group_lst):\n",
        "    return tuple(group_lst)\n",
        "\n",
        "\n",
        "def get_temp_g(train_set, names, y_label):\n",
        "  names2 = copy.deepcopy(names)\n",
        "  names2.append(y_label)\n",
        "  temp = train_set[names2]\n",
        "  temp['cnt'] = 0\n",
        "  temp_g = temp.groupby(names)['cnt'].count().reset_index()\n",
        "  return temp, temp_g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnQ09ffAkalO"
      },
      "source": [
        "# Preferential Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCr5MK4oTmKI",
        "outputId": "fa8d48f2-bdc4-4839-b0cb-6678793652fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "def pref_sampling_opt(train_set, cols_given, label, need_pos, need_neg):\n",
        "    if len(need_pos)+ len(need_neg) > 0:\n",
        "        temp_train_x = pd.DataFrame(train_set, columns = columns_all)\n",
        "        temp_train_label = pd.DataFrame(train_set, columns = [label])\n",
        "        temp_train_label = temp_train_label[label]\n",
        "        temp_train_label = temp_train_label.astype('int')\n",
        "        mnb = MultinomialNB()\n",
        "        mnb = mnb.fit(temp_train_x, temp_train_label)\n",
        "        probs = mnb.predict_proba(temp_train_x)[:,0]\n",
        "        train_set[\"prob\"] = abs(probs - 0.5)\n",
        "        # get the set of\n",
        "    new_train_set = pd.DataFrame(columns = list(train_set.columns))\n",
        "    updated_pos = 0\n",
        "    for i in need_pos:\n",
        "        # needs to updated more positive records\n",
        "        # print(i)\n",
        "        temp_df = copy.deepcopy(train_set)\n",
        "        for n in range(len(i)):\n",
        "          temp_df = temp_df[temp_df[cols_given[n]] == i[n]]\n",
        "        # update the skew and diff\n",
        "        idx = list(temp_df.index)\n",
        "        train_set.loc[idx, 'skewed'] = 1\n",
        "        idx_pos = list(temp_df[(getattr(temp_df, label) == 1)].index)\n",
        "        if(len(idx_pos) == 0):\n",
        "          # if there is no positive\n",
        "          idx_neg = list(temp_df[(getattr(temp_df, label) == 0)].index)\n",
        "          neg_ranked = train_set.loc[idx_neg].sort_values(by=\"prob\", ascending=True)\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          continue\n",
        "        idx_neg = list(temp_df[(getattr(temp_df, label) == 0)].index)\n",
        "        pos_ranked = train_set.loc[idx_pos].sort_values(by=\"prob\", ascending=True)\n",
        "        neg_ranked = train_set.loc[idx_neg].sort_values(by=\"prob\", ascending=True)\n",
        "        diff = compute_diff_add_and_remove(i, temp2,  1, compas_y, names)\n",
        "        if diff == -1:\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          continue\n",
        "        train_set.loc[idx, 'diff'] = int(diff)\n",
        "        cnt = int(train_set.loc[idx_pos[0]][\"diff\"])\n",
        "        updated_pos += cnt * 2\n",
        "        # add more records when there are not enough available records\n",
        "        new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "        temp_cnt = cnt\n",
        "        if len(pos_ranked) >= temp_cnt:\n",
        "            new_train_set = pd.concat([new_train_set,pos_ranked[0:cnt]], ignore_index=True)\n",
        "        else:\n",
        "            while(temp_cnt > 0 ):\n",
        "                new_train_set = pd.concat([new_train_set,pos_ranked[0:temp_cnt]], ignore_index=True)\n",
        "            # duplicate the dataframe\n",
        "                temp_cnt = temp_cnt - len(pos_ranked)\n",
        "        # duplicate the top cnt records from the pos\n",
        "        # remove the top cnt records from the neg\n",
        "        if cnt == 0:\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          # print(\"+++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "          # print(i)\n",
        "          # print(len(pos_ranked)+cnt)\n",
        "          # print(len(neg_ranked))\n",
        "        else:\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked[cnt-1:-1]], ignore_index=True)\n",
        "          # print(\"+++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "          # print(i)\n",
        "          # print(len(pos_ranked)+cnt)\n",
        "          # print(len(neg_ranked[cnt-1:-1]))\n",
        "    print(\"updated {} positive records\".format(str(updated_pos)))\n",
        "    updated_neg = 0\n",
        "    # adding more records to the need_neg set\n",
        "    for i in need_neg:\n",
        "        # print(i)\n",
        "        # list of idx belongs to this group\n",
        "        temp_df = copy.deepcopy(train_set)\n",
        "        for n in range(len(i)):\n",
        "          temp_df = temp_df[temp_df[cols_given[n]] == i[n]]\n",
        "        # update the skew and diff\n",
        "        idx = list(temp_df.index)\n",
        "        train_set.loc[idx, 'skewed'] = 1\n",
        "        idx_pos = list(temp_df[(getattr(temp_df, label) == 1)].index)\n",
        "        idx_neg = list(temp_df[(getattr(temp_df, label) == 0)].index)\n",
        "        if(len(idx_neg) == 0):\n",
        "          pos_ranked = train_set.loc[idx_pos].sort_values(by=\"prob\", ascending=True)\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          continue\n",
        "        pos_ranked = train_set.loc[idx_pos].sort_values(by=\"prob\", ascending=True)\n",
        "        neg_ranked = train_set.loc[idx_neg].sort_values(by=\"prob\", ascending=True)\n",
        "        diff = compute_diff_add_and_remove(i, temp2, 0, compas_y, names)\n",
        "        if diff == -1:\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          continue\n",
        "        train_set.loc[idx, 'diff'] = int(diff)\n",
        "        cnt = int(train_set.loc[idx_pos[0]][\"diff\"])\n",
        "        updated_neg += cnt * 2\n",
        "        # add more records when there are not enough available records\n",
        "        new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "        temp_cnt = cnt\n",
        "        if len(neg_ranked) >= temp_cnt:\n",
        "            new_train_set = pd.concat([new_train_set,neg_ranked[0:cnt]], ignore_index=True)\n",
        "        else:\n",
        "            while(temp_cnt > 0 ):\n",
        "                new_train_set = pd.concat([new_train_set,neg_ranked[0:temp_cnt]], ignore_index=True)\n",
        "            # duplicate the dataframe\n",
        "                temp_cnt = temp_cnt - len(neg_ranked)\n",
        "        # duplicate the top cnt records from the pos\n",
        "        # remove the top cnt records from the neg\n",
        "        if cnt ==0:\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          # print(\"+++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "          # print(i)\n",
        "          # print(len(neg_ranked)+cnt)\n",
        "          # print(len(pos_ranked))\n",
        "        else:\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked[cnt-1:-1]], ignore_index=True)\n",
        "          # print(\"+++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "          # print(i)\n",
        "          # print(len(neg_ranked)+cnt)\n",
        "          # print(len(pos_ranked[cnt-1:-1]))\n",
        "        #print(len(new_train_set[new_train_set['income'] == 1]), len(new_train_set[new_train_set['income'] == 0]))\n",
        "        # print(train_set.loc[idx_neg])\n",
        "    print(\"updated {} negative records\".format(str(updated_neg)))\n",
        "    # add the other irrelavant items:\n",
        "    idx_irr = list(train_set[train_set['skewed'] == 0].index)\n",
        "    irr_df = train_set.loc[idx_irr]\n",
        "    new_train_set = pd.concat([new_train_set, irr_df], ignore_index=True)\n",
        "    print(\"The new dataset contains {} rows.\".format(str(len(new_train_set))))\n",
        "    new_train_set.reset_index()\n",
        "    return new_train_set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paqO9W2jeTMX",
        "outputId": "a5791ae7-fd99-46dd-ed4f-ac0ad1e09a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def find_top(all_names):\n",
        "  all_names_lst_top = []\n",
        "  for all in range(len(all_names)):\n",
        "    if len(all_names[all]) == 1: # CHANGED HERE\n",
        "      all_names_lst_top.append(all)\n",
        "  return all_names_lst_top"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGdoCnWLlkc4"
      },
      "source": [
        "## Run Algorithm Lattice\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfMMRp-S4vTL",
        "outputId": "ad921a45-f827-48b4-abd2-5cc10b774492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/////////////\n",
            "63\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 0, 4, 1, 38], [0, 2, 5, 4, 0, 38], [1, 2, 0, 0, 1, 38], [1, 2, 0, 4, 1, 25], [1, 2, 5, 2, 0, 38], [2, 2, 0, 4, 1, 25]]\n",
            "[[1, 2, 0, 1, 1, 29], [1, 2, 0, 1, 1, 38], [1, 2, 0, 4, 1, 38], [1, 2, 5, 4, 0, 38]]\n",
            "started pref sampling\n",
            "updated 1002 positive records\n",
            "updated 1728 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24137\n",
            "1     7519\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "62\n",
            "The sets of need pos and neg are\n",
            "[[2, 0, 1, 1, 2], [2, 0, 1, 1, 29], [2, 0, 3, 1, 38], [2, 2, 4, 0, 38], [2, 2, 4, 1, 38]]\n",
            "[[2, 0, 1, 1, 18], [2, 0, 1, 1, 38], [2, 0, 4, 1, 1], [6, 4, 4, 1, 38]]\n",
            "started pref sampling\n",
            "updated 60 positive records\n",
            "updated 68 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24141\n",
            "1     7515\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "61\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 2, 1, 38], [0, 0, 4, 1, 25], [1, 0, 1, 1, 18], [1, 3, 4, 1, 38], [2, 4, 4, 1, 38]]\n",
            "[[0, 0, 4, 1, 38], [0, 5, 4, 0, 38], [1, 0, 0, 1, 38], [1, 0, 1, 1, 29], [1, 0, 4, 1, 25], [1, 5, 2, 0, 38], [1, 5, 4, 0, 38], [2, 5, 4, 0, 38]]\n",
            "started pref sampling\n",
            "updated 298 positive records\n",
            "updated 1216 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24600\n",
            "1     7056\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "60\n",
            "The sets of need pos and neg are\n",
            "[[1, 5, 2, 1, 38], [2, 5, 4, 1, 38], [2, 6, 4, 1, 38]]\n",
            "[[2, 2, 4, 1, 38]]\n",
            "started pref sampling\n",
            "updated 74 positive records\n",
            "updated 634 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24880\n",
            "1     6776\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "59\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 3, 1, 38], [1, 5, 4, 1, 38], [2, 0, 4, 1, 38], [2, 6, 1, 1, 38]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 152 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24956\n",
            "1     6700\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "58\n",
            "The sets of need pos and neg are\n",
            "[[1, 2, 5, 4, 38]]\n",
            "[[0, 2, 0, 4, 25], [1, 2, 3, 4, 38]]\n",
            "started pref sampling\n",
            "updated 308 positive records\n",
            "updated 26 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24815\n",
            "1     6841\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "57\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 5, 4, 0]]\n",
            "[[1, 2, 2, 4, 1], [1, 2, 5, 4, 0]]\n",
            "started pref sampling\n",
            "updated 108 positive records\n",
            "updated 270 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24896\n",
            "1     6760\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "56\n",
            "The sets of need pos and neg are\n",
            "[[2, 4, 1, 38], [3, 4, 1, 38]]\n",
            "[[0, 1, 1, 18], [0, 4, 1, 38]]\n",
            "started pref sampling\n",
            "updated 1060 positive records\n",
            "updated 4980 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    26856\n",
            "1     4800\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "55\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 1, 1, 38], [2, 2, 1, 38], [2, 3, 1, 38], [2, 4, 1, 1], [2, 4, 1, 4], [2, 4, 1, 10], [2, 4, 1, 21], [2, 4, 1, 25], [3, 4, 1, 38]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 594 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27153\n",
            "1     4503\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "54\n",
            "The sets of need pos and neg are\n",
            "[[2, 0, 1, 38]]\n",
            "[[0, 3, 1, 38], [2, 0, 1, 2], [2, 0, 1, 18], [2, 0, 1, 29], [2, 2, 1, 38], [2, 3, 1, 38]]\n",
            "started pref sampling\n",
            "updated 5154 positive records\n",
            "updated 406 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24779\n",
            "1     6877\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "53\n",
            "The sets of need pos and neg are\n",
            "[[2, 0, 1, 29], [2, 0, 4, 1], [2, 0, 4, 4], [2, 0, 4, 10], [2, 0, 4, 21], [2, 0, 4, 25]]\n",
            "[[2, 0, 0, 38], [3, 3, 4, 38]]\n",
            "started pref sampling\n",
            "updated 174 positive records\n",
            "updated 76 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24730\n",
            "1     6926\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "52\n",
            "The sets of need pos and neg are\n",
            "[[2, 2, 4, 1], [2, 3, 2, 1]]\n",
            "[[0, 3, 4, 1], [2, 3, 4, 1], [2, 5, 1, 0]]\n",
            "started pref sampling\n",
            "updated 36 positive records\n",
            "updated 48 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24736\n",
            "1     6920\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "51\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24736\n",
            "1     6920\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "50\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 1, 2], [1, 0, 1, 18]]\n",
            "[[0, 5, 0, 38], [1, 3, 1, 38], [2, 0, 1, 25]]\n",
            "started pref sampling\n",
            "updated 30 positive records\n",
            "updated 492 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24967\n",
            "1     6689\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "49\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 0, 38]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 20 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24977\n",
            "1     6679\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "48\n",
            "The sets of need pos and neg are\n",
            "[[1, 3, 1, 1]]\n",
            "[[1, 2, 4, 1]]\n",
            "started pref sampling\n",
            "updated 20 positive records\n",
            "updated 30 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24982\n",
            "1     6674\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "47\n",
            "The sets of need pos and neg are\n",
            "[[1, 3, 1, 38]]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 40 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24962\n",
            "1     6694\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "46\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 0, 38], [2, 3, 4, 38], [2, 6, 4, 38]]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 294 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24815\n",
            "1     6841\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "45\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 3, 4, 0], [2, 6, 4, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 120 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24875\n",
            "1     6781\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "44\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 5, 38]]\n",
            "[[1, 2, 2, 38], [1, 3, 1, 38], [2, 6, 3, 38]]\n",
            "started pref sampling\n",
            "updated 120 positive records\n",
            "updated 114 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24872\n",
            "1     6784\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "43\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 2, 1]]\n",
            "[[1, 4, 3, 1], [2, 5, 1, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 254 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24999\n",
            "1     6657\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "42\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 2, 4]]\n",
            "[[1, 2, 2, 4]]\n",
            "started pref sampling\n",
            "updated 24 positive records\n",
            "updated 10 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24992\n",
            "1     6664\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "41\n",
            "The sets of need pos and neg are\n",
            "[[4, 1, 12]]\n",
            "[[4, 1, 8]]\n",
            "started pref sampling\n",
            "updated 16 positive records\n",
            "updated 18 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24993\n",
            "1     6663\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "40\n",
            "The sets of need pos and neg are\n",
            "[[3, 1, 38]]\n",
            "[[0, 1, 38]]\n",
            "started pref sampling\n",
            "updated 1030 positive records\n",
            "updated 5812 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27384\n",
            "1     4272\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "39\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 4, 1], [0, 4, 4], [0, 4, 10], [0, 4, 21], [0, 4, 25]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 178 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27473\n",
            "1     4183\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "38\n",
            "The sets of need pos and neg are\n",
            "[[3, 1, 1]]\n",
            "[[0, 1, 1]]\n",
            "started pref sampling\n",
            "updated 24 positive records\n",
            "updated 126 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27524\n",
            "1     4132\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "37\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[6, 1, 38]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 68 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27558\n",
            "1     4098\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "36\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27558\n",
            "1     4098\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "35\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27558\n",
            "1     4098\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "34\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 3, 38], [2, 3, 38], [3, 3, 38]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 176 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27646\n",
            "1     4010\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "33\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 2, 1], [0, 3, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 46 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27669\n",
            "1     3987\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "32\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27669\n",
            "1     3987\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "31\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 8]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 14 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27676\n",
            "1     3980\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "30\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27676\n",
            "1     3980\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "29\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27676\n",
            "1     3980\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "28\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 5, 38], [1, 0, 29], [2, 3, 38]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 182 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27767\n",
            "1     3889\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "27\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 3, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 246 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27890\n",
            "1     3766\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "26\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27890\n",
            "1     3766\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "25\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27890\n",
            "1     3766\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "24\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27890\n",
            "1     3766\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "23\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27890\n",
            "1     3766\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "22\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27890\n",
            "1     3766\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "21\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27890\n",
            "1     3766\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "20\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[4, 11]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 20 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "19\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "18\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "17\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "16\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "15\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "14\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "13\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "12\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "11\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "10\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "9\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "8\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "6\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "5\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "4\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "3\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "2\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "1\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    27900\n",
            "1     3756\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "# for a in [all_names_lst[0]]: # leaf\n",
        "# for a in [all_names_lst[-1:x]]: # top\n",
        "  print(\"/////////////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  # start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  # end = time.time()\n",
        "  # excute_time = end - start\n",
        "  # print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started pref sampling\")\n",
        "  new_train_data = pref_sampling_opt(new_train_data, names, compas_y, need_pos, need_neg)\n",
        "  # print(new_train_data)\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euVPjcb_lqe2"
      },
      "source": [
        "### Results Lattice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDvLtC3BlDpa",
        "outputId": "c86b6fbf-7e3d-43a6-e54b-263a6619e05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.0138671875\n",
            "0.9073962717979555\n",
            "accuracy\n",
            "0.7670647206250921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py:522: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  common = np.find_common_type([values.dtype, comps_array.dtype], [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py:522: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  common = np.find_common_type([values.dtype, comps_array.dtype], [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py:522: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  common = np.find_common_type([values.dtype, comps_array.dtype], [])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0.03992377631588995\n",
            "0.4287345702498045\n",
            "accuracy is  0.7670647206250921\n",
            "['Adult', 'Preferential Sampling-Lattice', 'SVM', 0, 0.03992377631588995, 0.4287345702498045, 0.7670647206250921]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n"
          ]
        }
      ],
      "source": [
        "test_set['predicted'] = test_predict\n",
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label,test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Preferential Sampling-Lattice\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label,test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Preferential Sampling-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label,test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Preferential Sampling-Lattice\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"Adult\",\"Preferential Sampling-Lattice\",\"SVM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaHdC0EaqzZz"
      },
      "source": [
        "## Run Algorithm Leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh523URuq7AD",
        "outputId": "ce3e72d7-b590-4f16-f043-813b2d06435f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/////////////\n",
            "63\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 0, 4, 1, 38], [0, 2, 5, 4, 0, 38], [1, 2, 0, 0, 1, 38], [1, 2, 0, 4, 1, 25], [1, 2, 5, 2, 0, 38], [2, 2, 0, 4, 1, 25]]\n",
            "[[1, 2, 0, 1, 1, 29], [1, 2, 0, 1, 1, 38], [1, 2, 0, 4, 1, 38], [1, 2, 5, 4, 0, 38]]\n",
            "started pref sampling\n",
            "updated 1002 positive records\n",
            "updated 1728 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    24137\n",
            "1     7519\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in [all_names_lst[0]]:\n",
        "  print(\"/////////////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started pref sampling\")\n",
        "  new_train_data = pref_sampling_opt(new_train_data, names, compas_y, need_pos, need_neg)\n",
        "\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27rcEGB9rhrf"
      },
      "source": [
        "### Results Leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "4-1zYQIWsDdn",
        "outputId": "2ddab8b6-60a6-4c53-e76b-13083f3a2f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.769244179763805\n",
            "fpr and fnr\n",
            "0.0447265625\n",
            "0.6337943475646423\n",
            "accuracy\n",
            "0.8108506560518944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18120808872062508\n",
            "0.5568230300005409\n",
            "0.31414292945465616\n",
            "accuracy is  0.8108506560518944\n",
            "['Adult', 'Preferential Sampling-Leaf', 'DT', 0.18120808872062508, 0.5568230300005409, 0.31414292945465616, 0.8108506560518944]\n",
            "\n",
            "rf\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-786b85f586f5>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgridrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_train_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "test_set['predicted'] = test_predict\n",
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Preferential Sampling-Leaf\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Preferential Sampling-Leaf\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Preferential Sampling-Leaf\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"Adult\",\"Preferential Sampling-Leaf\",\"SVM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM1zX7q-ruBj"
      },
      "source": [
        "## Run Algorithm Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzp7XkuksXyD",
        "outputId": "58d04892-650d-48c4-d760-13aac4f39500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/////////////\n",
            "1\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "2\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "3\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "4\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "5\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "/////////////\n",
            "6\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 31656 rows.\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "all_names_lst_top = find_top(all_names)\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst_top:\n",
        "  print(\"/////////////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started pref sampling\")\n",
        "  new_train_data = pref_sampling_opt(new_train_data, names, compas_y, need_pos, need_neg)\n",
        "\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVRTFfXmr2NG"
      },
      "source": [
        "### Results Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cjoGWE-sFf9"
      },
      "outputs": [],
      "source": [
        "test_set['predicted'] = test_predict\n",
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Preferential Sampling-Top\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Preferential Sampling-Top\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Preferential Sampling-Top\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"Adult\",\"Preferential Sampling-Top\",\"SVM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeNaCEQ26n7V"
      },
      "source": [
        "# Duplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "F-x05Dlbuc62"
      },
      "outputs": [],
      "source": [
        "def round_int(x):\n",
        "    if x in [float(\"-inf\"),float(\"inf\")]: return 0\n",
        "    return int(round(x))\n",
        "\n",
        "\n",
        "def make_duplicate(d, group_lst, diff, label_y, names, need_positive_or_negative):\n",
        "    selected = copy.deepcopy(d)\n",
        "    print(\"names \", names, group_lst)\n",
        "    for i in range(len(group_lst)):\n",
        "        att_name = names[i]\n",
        "        selected = selected[(selected[att_name] == group_lst[i])]\n",
        "    selected = selected[(selected[label_y] == need_positive_or_negative)]\n",
        "\n",
        "    if len(selected) == 0:\n",
        "        return pd.DataFrame()\n",
        "    while(len(selected) < diff):\n",
        "        # duplicate the dataframe\n",
        "        select_copy = selected.copy(deep=True)\n",
        "        selected = pd.concat([selected, select_copy])\n",
        "\n",
        "        # the number needed is more than the not needed numbers.\n",
        "\n",
        "    generated = selected.sample(n = diff, replace = False, axis = 0)\n",
        "\n",
        "    return generated\n",
        "\n",
        "\n",
        "def naive_duplicate(d, temp2, names, need_pos, need_neg, label_y):\n",
        "    # add more records for all groups\n",
        "    # The smote algorithm to boost the coverage\n",
        "    for r in need_pos:\n",
        "    # add more positive records\n",
        "        # determine how many points to add\n",
        "        print(\"pos_vals\", r)\n",
        "        diff = compute_diff_add(r, temp2, names, label_y, 1)\n",
        "        if diff == -1:\n",
        "          continue\n",
        "        diff = round_int(diff)\n",
        "        # add more records\n",
        "        print(\"Adding \" + str(diff) +\" positive records\")\n",
        "        samples_to_add = make_duplicate(d, r, diff, label_y, names, need_positive_or_negative = 1)\n",
        "        d = pd.concat([d, samples_to_add], ignore_index=True)\n",
        "    for k in need_neg:\n",
        "        print(\"neg_vals\", k)\n",
        "        diff = compute_diff_add(k, temp2, names, label_y, need_positive_or_negative = 0)\n",
        "        if diff == -1:\n",
        "          continue\n",
        "        diff = round_int(diff)\n",
        "        print(\"Adding \" + str(diff) +\" negative records\")\n",
        "        samples_to_add = make_duplicate(d, k, diff, label_y, names, need_positive_or_negative = 0)\n",
        "        d = pd.concat([d, samples_to_add], ignore_index=True)\n",
        "    return d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_HqjDkKtclY"
      },
      "source": [
        "## Run Algorithm Lattice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptgbqFIO8PDF",
        "outputId": "9eb8923a-f72f-426f-e6b5-717faf10f2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "63\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 0, 4, 1, 38], [0, 2, 5, 4, 0, 38], [1, 2, 0, 0, 1, 38], [1, 2, 0, 4, 1, 25], [1, 2, 5, 2, 0, 38], [2, 2, 0, 4, 1, 25]]\n",
            "[[1, 2, 0, 1, 1, 29], [1, 2, 0, 1, 1, 38], [1, 2, 0, 4, 1, 38], [1, 2, 5, 4, 0, 38]]\n",
            "started duplication\n",
            "pos_vals [0, 2, 0, 4, 1, 38]\n",
            "0.9786427145708583 366 1102 712.464271457086\n",
            "0.9786427145708583 366 1102 712.464271457086\n",
            "Adding 712 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [0, 2, 0, 4, 1, 38]\n",
            "pos_vals [0, 2, 5, 4, 0, 38]\n",
            "1.0848861283643891 77 154 90.0724637681159\n",
            "1.0848861283643891 77 154 90.0724637681159\n",
            "Adding 90 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [0, 2, 5, 4, 0, 38]\n",
            "pos_vals [1, 2, 0, 0, 1, 38]\n",
            "1.0353780313837375 14 44 31.5566333808844\n",
            "1.0353780313837375 14 44 31.5566333808844\n",
            "Adding 32 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 0, 0, 1, 38]\n",
            "pos_vals [1, 2, 0, 4, 1, 25]\n",
            "1.014265335235378 17 137 121.954350927247\n",
            "1.014265335235378 17 137 121.954350927247\n",
            "Adding 122 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 0, 4, 1, 25]\n",
            "pos_vals [1, 2, 5, 2, 0, 38]\n",
            "1.3063063063063063 31 47 30.3963963963964\n",
            "1.3063063063063063 31 47 30.3963963963964\n",
            "Adding 30 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 5, 2, 0, 38]\n",
            "pos_vals [2, 2, 0, 4, 1, 25]\n",
            "0.8496659242761693 6 29 18.6403118040089\n",
            "0.8496659242761693 6 29 18.6403118040089\n",
            "Adding 19 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [2, 2, 0, 4, 1, 25]\n",
            "neg_vals [1, 2, 0, 1, 1, 29]\n",
            "1.0 30 16 14.0000000000000\n",
            "Adding 14 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 0, 1, 1, 29]\n",
            "neg_vals [1, 2, 0, 1, 1, 38]\n",
            "1.037211885587337 29 17 10.9595716198125\n",
            "Adding 11 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 0, 1, 1, 38]\n",
            "neg_vals [1, 2, 0, 4, 1, 38]\n",
            "0.6795545932570368 3416 3241 1785.82203004096\n",
            "Adding 1786 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 0, 4, 1, 38]\n",
            "neg_vals [1, 2, 5, 4, 0, 38]\n",
            "0.6730769230769231 408 281 325.171428571429\n",
            "Adding 325 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 5, 4, 0, 38]\n",
            "label y  0    25910\n",
            "1     8887\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "62\n",
            "The sets of need pos and neg are\n",
            "[[2, 0, 1, 1, 2], [2, 0, 1, 1, 29], [2, 0, 3, 1, 38], [2, 2, 4, 0, 38], [2, 2, 4, 1, 38]]\n",
            "[[2, 0, 1, 1, 18], [2, 0, 1, 1, 38], [2, 0, 4, 1, 1], [6, 4, 4, 1, 38]]\n",
            "started duplication\n",
            "pos_vals [2, 0, 1, 1, 2]\n",
            "1.0294117647058822 16 25 9.73529411764705\n",
            "1.0294117647058822 16 25 9.73529411764705\n",
            "Adding 10 positive records\n",
            "names  ['marital-status', 'relationship', 'race', 'gender', 'native-country'] [2, 0, 1, 1, 2]\n",
            "pos_vals [2, 0, 1, 1, 29]\n",
            "1.06 36 48 14.8800000000000\n",
            "1.06 36 48 14.8800000000000\n",
            "Adding 15 positive records\n",
            "names  ['marital-status', 'relationship', 'race', 'gender', 'native-country'] [2, 0, 1, 1, 29]\n",
            "pos_vals [2, 0, 3, 1, 38]\n",
            "0.7719534598897734 9 22 7.98297611757501\n",
            "0.7719534598897734 9 22 7.98297611757501\n",
            "Adding 8 positive records\n",
            "names  ['marital-status', 'relationship', 'race', 'gender', 'native-country'] [2, 0, 3, 1, 38]\n",
            "pos_vals [2, 2, 4, 0, 38]\n",
            "0.5866780529461998 6 27 9.84030742954741\n",
            "0.5866780529461998 6 27 9.84030742954741\n",
            "Adding 10 positive records\n",
            "names  ['marital-status', 'relationship', 'race', 'gender', 'native-country'] [2, 2, 4, 0, 38]\n",
            "pos_vals [2, 2, 4, 1, 38]\n",
            "0.7476822851415685 6 32 17.9258331245302\n",
            "0.7476822851415685 6 32 17.9258331245302\n",
            "Adding 18 positive records\n",
            "names  ['marital-status', 'relationship', 'race', 'gender', 'native-country'] [2, 2, 4, 1, 38]\n",
            "neg_vals [2, 0, 1, 1, 18]\n",
            "0.8918918918918919 30 17 16.6363636363636\n",
            "Adding 17 negative records\n",
            "names  ['marital-status', 'relationship', 'race', 'gender', 'native-country'] [2, 0, 1, 1, 18]\n",
            "neg_vals [2, 0, 1, 1, 38]\n",
            "0.7716563972453787 52 36 31.3875058713011\n",
            "Adding 31 negative records\n",
            "names  ['marital-status', 'relationship', 'race', 'gender', 'native-country'] [2, 0, 1, 1, 38]\n",
            "neg_vals [2, 0, 4, 1, 1]\n",
            "0.7712145400957878 29 22 15.6030254777070\n",
            "Adding 16 negative records\n",
            "names  ['marital-status', 'relationship', 'race', 'gender', 'native-country'] [2, 0, 4, 1, 1]\n",
            "neg_vals [6, 4, 4, 1, 38]\n",
            "0.1478494623655914 14 28 66.6909090909091\n",
            "Adding 67 negative records\n",
            "names  ['marital-status', 'relationship', 'race', 'gender', 'native-country'] [6, 4, 4, 1, 38]\n",
            "label y  0    26041\n",
            "1     8948\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "61\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 2, 1, 38], [0, 0, 4, 1, 25], [1, 3, 4, 1, 38], [1, 4, 4, 1, 38], [2, 4, 4, 1, 38]]\n",
            "[[0, 0, 4, 1, 38], [0, 5, 4, 0, 38], [1, 0, 0, 1, 38], [1, 0, 1, 1, 29], [1, 0, 4, 1, 25], [1, 5, 2, 0, 38], [1, 5, 4, 0, 38], [2, 0, 1, 1, 38], [2, 5, 4, 0, 38]]\n",
            "started duplication\n",
            "pos_vals [0, 0, 2, 1, 38]\n",
            "0.7309392265193371 8 61 36.5872928176795\n",
            "0.7309392265193371 8 61 36.5872928176795\n",
            "Adding 37 positive records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [0, 0, 2, 1, 38]\n",
            "pos_vals [0, 0, 4, 1, 25]\n",
            "0.8555858310626703 2 57 46.7683923705722\n",
            "0.8555858310626703 2 57 46.7683923705722\n",
            "Adding 47 positive records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [0, 0, 4, 1, 25]\n",
            "pos_vals [1, 3, 4, 1, 38]\n",
            "0.4358740301232314 25 358 131.042902784117\n",
            "0.4358740301232314 25 358 131.042902784117\n",
            "Adding 131 positive records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [1, 3, 4, 1, 38]\n",
            "pos_vals [1, 4, 4, 1, 38]\n",
            "0.47178302116273413 47 279 84.6274629044028\n",
            "0.47178302116273413 47 279 84.6274629044028\n",
            "Adding 85 positive records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [1, 4, 4, 1, 38]\n",
            "pos_vals [2, 4, 4, 1, 38]\n",
            "0.6140480591497227 32 129 47.2121996303143\n",
            "0.6140480591497227 32 129 47.2121996303143\n",
            "Adding 47 positive records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [2, 4, 4, 1, 38]\n",
            "neg_vals [0, 0, 4, 1, 38]\n",
            "0.4987997599519904 1079 1104 1059.19270102266\n",
            "Adding 1059 negative records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [0, 0, 4, 1, 38]\n",
            "neg_vals [0, 5, 4, 0, 38]\n",
            "0.15715467328370555 169 160 915.373684210523\n",
            "Adding 915 negative records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [0, 5, 4, 0, 38]\n",
            "neg_vals [1, 0, 0, 1, 38]\n",
            "0.6785381316427372 46 44 23.7928002198406\n",
            "Adding 24 negative records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [1, 0, 0, 1, 38]\n",
            "neg_vals [1, 0, 1, 1, 29]\n",
            "0.7034883720930233 42 30 29.7024793388430\n",
            "Adding 30 negative records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [1, 0, 1, 1, 29]\n",
            "neg_vals [1, 0, 4, 1, 25]\n",
            "0.6701629518636448 139 137 70.4122414756847\n",
            "Adding 70 negative records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [1, 0, 4, 1, 25]\n",
            "neg_vals [1, 5, 2, 0, 38]\n",
            "0.3740031897926635 61 47 116.100213219616\n",
            "Adding 116 negative records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [1, 5, 2, 0, 38]\n",
            "neg_vals [1, 5, 4, 0, 38]\n",
            "0.22070240295748614 411 608 1254.23618090452\n",
            "Adding 1254 negative records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [1, 5, 4, 0, 38]\n",
            "neg_vals [2, 0, 1, 1, 38]\n",
            "0.9121699196326062 19 13 7.82945248584016\n",
            "Adding 8 negative records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [2, 0, 1, 1, 38]\n",
            "neg_vals [2, 5, 4, 0, 38]\n",
            "0.3761225567881669 96 116 139.235955056180\n",
            "Adding 139 negative records\n",
            "names  ['age', 'relationship', 'race', 'gender', 'native-country'] [2, 5, 4, 0, 38]\n",
            "label y  0    29656\n",
            "1     9295\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "60\n",
            "The sets of need pos and neg are\n",
            "[[1, 5, 2, 1, 38], [2, 5, 4, 1, 38], [2, 6, 4, 1, 38]]\n",
            "[[2, 2, 4, 1, 38]]\n",
            "started duplication\n",
            "pos_vals [1, 5, 2, 1, 38]\n",
            "0.3314840499306519 1 48 14.9112343966713\n",
            "0.3314840499306519 1 48 14.9112343966713\n",
            "Adding 15 positive records\n",
            "names  ['age', 'marital-status', 'race', 'gender', 'native-country'] [1, 5, 2, 1, 38]\n",
            "pos_vals [2, 5, 4, 1, 38]\n",
            "0.7407407407407407 8 29 13.4814814814815\n",
            "0.7407407407407407 8 29 13.4814814814815\n",
            "Adding 13 positive records\n",
            "names  ['age', 'marital-status', 'race', 'gender', 'native-country'] [2, 5, 4, 1, 38]\n",
            "pos_vals [2, 6, 4, 1, 38]\n",
            "0.6737443854634545 46 124 37.5443037974684\n",
            "0.6737443854634545 46 124 37.5443037974684\n",
            "Adding 38 positive records\n",
            "names  ['age', 'marital-status', 'race', 'gender', 'native-country'] [2, 6, 4, 1, 38]\n",
            "neg_vals [2, 2, 4, 1, 38]\n",
            "0.6065256797583082 1452 1540 853.962940824866\n",
            "Adding 854 negative records\n",
            "names  ['age', 'marital-status', 'race', 'gender', 'native-country'] [2, 2, 4, 1, 38]\n",
            "label y  0    30510\n",
            "1     9361\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "59\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 4, 1, 38], [1, 2, 2, 1, 38], [1, 2, 3, 1, 38], [1, 5, 4, 1, 38], [2, 0, 4, 1, 38], [2, 5, 1, 1, 38], [2, 6, 1, 1, 38], [2, 6, 4, 1, 38]]\n",
            "started duplication\n",
            "neg_vals [1, 0, 4, 1, 38]\n",
            "0.17768147345612134 94 181 348.036585365854\n",
            "Adding 348 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'gender', 'native-country'] [1, 0, 4, 1, 38]\n",
            "neg_vals [1, 2, 2, 1, 38]\n",
            "0.6708883662022798 24 9 26.7734627831715\n",
            "Adding 27 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'gender', 'native-country'] [1, 2, 2, 1, 38]\n",
            "neg_vals [1, 2, 3, 1, 38]\n",
            "0.6604810996563574 22 9 24.3090530697191\n",
            "Adding 24 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'gender', 'native-country'] [1, 2, 3, 1, 38]\n",
            "neg_vals [1, 5, 4, 1, 38]\n",
            "0.23947750362844702 29 34 87.0969696969697\n",
            "Adding 87 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'gender', 'native-country'] [1, 5, 4, 1, 38]\n",
            "neg_vals [2, 0, 4, 1, 38]\n",
            "0.33848314606741575 46 48 87.9004149377592\n",
            "Adding 88 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'gender', 'native-country'] [2, 0, 4, 1, 38]\n",
            "neg_vals [2, 5, 1, 1, 38]\n",
            "0.2898550724637681 19 29 36.5500000000000\n",
            "Adding 37 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'gender', 'native-country'] [2, 5, 1, 1, 38]\n",
            "neg_vals [2, 6, 1, 1, 38]\n",
            "0.246684350132626 38 66 88.0430107526882\n",
            "Adding 88 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'gender', 'native-country'] [2, 6, 1, 1, 38]\n",
            "neg_vals [2, 6, 4, 1, 38]\n",
            "0.3446327683615819 46 64 69.4754098360656\n",
            "Adding 69 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'gender', 'native-country'] [2, 6, 4, 1, 38]\n",
            "label y  0    31278\n",
            "1     9361\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "58\n",
            "The sets of need pos and neg are\n",
            "[[1, 2, 5, 4, 38]]\n",
            "[[0, 2, 0, 4, 25]]\n",
            "started duplication\n",
            "pos_vals [1, 2, 5, 4, 38]\n",
            "0.5811446789130105 408 1855 670.023379383635\n",
            "0.5811446789130105 408 1855 670.023379383635\n",
            "Adding 670 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'native-country'] [1, 2, 5, 4, 38]\n",
            "neg_vals [0, 2, 0, 4, 25]\n",
            "0.5072756669361358 49 57 39.5944223107569\n",
            "Adding 40 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'native-country'] [0, 2, 0, 4, 25]\n",
            "label y  0    31318\n",
            "1    10031\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "57\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 5, 4, 0]]\n",
            "[[1, 2, 5, 1, 0], [1, 2, 5, 4, 0], [1, 5, 4, 2, 1]]\n",
            "started duplication\n",
            "pos_vals [0, 2, 5, 4, 0]\n",
            "0.5438829787234043 172 1054 401.252659574468\n",
            "0.5438829787234043 172 1054 401.252659574468\n",
            "Adding 401 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender'] [0, 2, 5, 4, 0]\n",
            "neg_vals [1, 2, 5, 1, 0]\n",
            "0.5706705258080077 17 19 10.7895181741335\n",
            "Adding 11 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender'] [1, 2, 5, 1, 0]\n",
            "neg_vals [1, 2, 5, 4, 0]\n",
            "0.24153645833333334 1102 1878 2684.45822102427\n",
            "Adding 2684 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender'] [1, 2, 5, 4, 0]\n",
            "neg_vals [1, 5, 4, 2, 1]\n",
            "0.06643356643356643 16 36 204.842105263158\n",
            "Adding 205 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender'] [1, 5, 4, 2, 1]\n",
            "label y  0    34218\n",
            "1    10432\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "56\n",
            "The sets of need pos and neg are\n",
            "[[2, 4, 1, 38], [3, 4, 1, 38]]\n",
            "[[0, 1, 1, 2], [0, 4, 1, 38]]\n",
            "started duplication\n",
            "pos_vals [2, 4, 1, 38]\n",
            "0.42295202499846823 29 295 95.7708473745483\n",
            "0.42295202499846823 29 295 95.7708473745483\n",
            "Adding 96 positive records\n",
            "names  ['relationship', 'race', 'gender', 'native-country'] [2, 4, 1, 38]\n",
            "pos_vals [3, 4, 1, 38]\n",
            "0.4181301014098442 172 2048 684.330447687361\n",
            "0.4181301014098442 172 2048 684.330447687361\n",
            "Adding 684 positive records\n",
            "names  ['relationship', 'race', 'gender', 'native-country'] [3, 4, 1, 38]\n",
            "neg_vals [0, 1, 1, 2]\n",
            "0.7022058823529411 26 25 12.0261780104712\n",
            "Adding 12 negative records\n",
            "names  ['relationship', 'race', 'gender', 'native-country'] [0, 1, 1, 2]\n",
            "neg_vals [0, 4, 1, 38]\n",
            "0.22780569514237856 5947 9578 16527.5808823529\n",
            "Adding 16528 negative records\n",
            "names  ['relationship', 'race', 'gender', 'native-country'] [0, 4, 1, 38]\n",
            "label y  0    50758\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "55\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 1, 1, 38], [2, 2, 1, 38], [2, 3, 1, 38], [2, 4, 1, 1], [2, 4, 1, 4], [2, 4, 1, 10], [2, 4, 1, 21], [2, 4, 1, 25], [3, 4, 1, 38]]\n",
            "started duplication\n",
            "neg_vals [2, 1, 1, 38]\n",
            "0.24822301199466903 53 75 138.517673378076\n",
            "Adding 139 negative records\n",
            "names  ['marital-status', 'race', 'gender', 'native-country'] [2, 1, 1, 38]\n",
            "neg_vals [2, 2, 1, 38]\n",
            "0.23277918323093602 278 382 812.264865704083\n",
            "Adding 812 negative records\n",
            "names  ['marital-status', 'race', 'gender', 'native-country'] [2, 2, 1, 38]\n",
            "neg_vals [2, 3, 1, 38]\n",
            "0.24496644295302014 18 24 49.4794520547945\n",
            "Adding 49 negative records\n",
            "names  ['marital-status', 'race', 'gender', 'native-country'] [2, 3, 1, 38]\n",
            "neg_vals [2, 4, 1, 1]\n",
            "0.24489415623136554 29 38 80.4185055547099\n",
            "Adding 80 negative records\n",
            "names  ['marital-status', 'race', 'gender', 'native-country'] [2, 4, 1, 1]\n",
            "neg_vals [2, 4, 1, 4]\n",
            "0.24505310229178312 16 20 45.2919708029197\n",
            "Adding 45 negative records\n",
            "names  ['marital-status', 'race', 'gender', 'native-country'] [2, 4, 1, 4]\n",
            "neg_vals [2, 4, 1, 10]\n",
            "0.2447466467958271 22 27 62.8888719744254\n",
            "Adding 63 negative records\n",
            "names  ['marital-status', 'race', 'gender', 'native-country'] [2, 4, 1, 10]\n",
            "neg_vals [2, 4, 1, 21]\n",
            "0.2449877021688902 15 26 35.2275631274719\n",
            "Adding 35 negative records\n",
            "names  ['marital-status', 'race', 'gender', 'native-country'] [2, 4, 1, 21]\n",
            "neg_vals [2, 4, 1, 25]\n",
            "0.2388601812326818 213 350 541.735068192506\n",
            "Adding 542 negative records\n",
            "names  ['marital-status', 'race', 'gender', 'native-country'] [2, 4, 1, 25]\n",
            "neg_vals [3, 4, 1, 38]\n",
            "0.23340556047242653 54 76 155.356956066945\n",
            "Adding 155 negative records\n",
            "names  ['marital-status', 'race', 'gender', 'native-country'] [3, 4, 1, 38]\n",
            "label y  0    52678\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "54\n",
            "The sets of need pos and neg are\n",
            "[[2, 2, 1, 25], [5, 3, 1, 38]]\n",
            "[[0, 3, 1, 38], [2, 0, 1, 2], [2, 0, 1, 18], [2, 0, 1, 29], [2, 2, 1, 38], [2, 3, 1, 38], [3, 3, 1, 38]]\n",
            "started duplication\n",
            "pos_vals [2, 2, 1, 25]\n",
            "0.30739673390970224 0 32 9.83669548511046\n",
            "0.30739673390970224 0 32 9.83669548511046\n",
            "Adding 10 positive records\n",
            "names  ['marital-status', 'relationship', 'gender', 'native-country'] [2, 2, 1, 25]\n",
            "pos_vals [5, 3, 1, 38]\n",
            "0.3159478435305918 0 43 13.5857572718155\n",
            "0.3159478435305918 0 43 13.5857572718155\n",
            "Adding 14 positive records\n",
            "names  ['marital-status', 'relationship', 'gender', 'native-country'] [5, 3, 1, 38]\n",
            "neg_vals [0, 3, 1, 38]\n",
            "0.24963574550752793 189 146 611.103112840467\n",
            "Adding 611 negative records\n",
            "names  ['marital-status', 'relationship', 'gender', 'native-country'] [0, 3, 1, 38]\n",
            "neg_vals [2, 0, 1, 2]\n",
            "0.23705479452054795 26 37 72.6792834440913\n",
            "Adding 73 negative records\n",
            "names  ['marital-status', 'relationship', 'gender', 'native-country'] [2, 0, 1, 2]\n",
            "neg_vals [2, 0, 1, 18]\n",
            "0.23678082191780822 34 39 104.592710442580\n",
            "Adding 105 negative records\n",
            "names  ['marital-status', 'relationship', 'gender', 'native-country'] [2, 0, 1, 18]\n",
            "neg_vals [2, 0, 1, 29]\n",
            "0.23641975308641974 55 79 153.637075718015\n",
            "Adding 154 negative records\n",
            "names  ['marital-status', 'relationship', 'gender', 'native-country'] [2, 0, 1, 29]\n",
            "neg_vals [2, 2, 1, 38]\n",
            "0.23164223708552725 104 82 366.968207648595\n",
            "Adding 367 negative records\n",
            "names  ['marital-status', 'relationship', 'gender', 'native-country'] [2, 2, 1, 38]\n",
            "neg_vals [2, 3, 1, 38]\n",
            "0.23957119552551853 121 91 414.069066147859\n",
            "Adding 414 negative records\n",
            "names  ['marital-status', 'relationship', 'gender', 'native-country'] [2, 3, 1, 38]\n",
            "neg_vals [3, 3, 1, 38]\n",
            "0.31582924064979223 40 18 108.650717703349\n",
            "Adding 109 negative records\n",
            "names  ['marital-status', 'relationship', 'gender', 'native-country'] [3, 3, 1, 38]\n",
            "label y  0    54511\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "53\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 0, 0, 38]]\n",
            "started duplication\n",
            "neg_vals [2, 0, 0, 38]\n",
            "0.22871355433717003 51 95 127.986347039213\n",
            "Adding 128 negative records\n",
            "names  ['marital-status', 'relationship', 'race', 'native-country'] [2, 0, 0, 38]\n",
            "label y  0    54639\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "52\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    54639\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "51\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    54639\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "50\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 5, 0, 38], [1, 0, 1, 4], [1, 3, 1, 38]]\n",
            "started duplication\n",
            "neg_vals [0, 5, 0, 38]\n",
            "0.15818464854508443 574 1106 2522.67070401212\n",
            "Adding 2523 negative records\n",
            "names  ['age', 'relationship', 'gender', 'native-country'] [0, 5, 0, 38]\n",
            "neg_vals [1, 0, 1, 4]\n",
            "0.25533785481034915 16 20 42.6620757501230\n",
            "Adding 43 negative records\n",
            "names  ['age', 'relationship', 'gender', 'native-country'] [1, 0, 1, 4]\n",
            "neg_vals [1, 3, 1, 38]\n",
            "0.213925476178818 778 1169 2467.78049897002\n",
            "Adding 2468 negative records\n",
            "names  ['age', 'relationship', 'gender', 'native-country'] [1, 3, 1, 38]\n",
            "label y  0    59673\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "49\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    59673\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "48\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 5, 1, 0]]\n",
            "started duplication\n",
            "neg_vals [1, 5, 1, 0]\n",
            "0.2462012320328542 17 30 39.0492076730609\n",
            "Adding 39 negative records\n",
            "names  ['age', 'relationship', 'race', 'gender'] [1, 5, 1, 0]\n",
            "label y  0    59712\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "47\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    59712\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "46\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    59712\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "45\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    59712\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "44\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 4, 3, 38]]\n",
            "started duplication\n",
            "neg_vals [1, 4, 3, 38]\n",
            "0.08243192838493099 465 1072 4569.01809954751\n",
            "Adding 4569 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'native-country'] [1, 4, 3, 38]\n",
            "label y  0    64281\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "43\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64281\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "42\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 2, 2, 4]]\n",
            "started duplication\n",
            "neg_vals [1, 2, 2, 4]\n",
            "0.2447743408966784 107 170 267.137322515214\n",
            "Adding 267 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race'] [1, 2, 2, 4]\n",
            "label y  0    64548\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "41\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[4, 1, 8]]\n",
            "started duplication\n",
            "neg_vals [4, 1, 8]\n",
            "0.19558989913579355 22 23 89.4802461538459\n",
            "Adding 89 negative records\n",
            "names  ['race', 'gender', 'native-country'] [4, 1, 8]\n",
            "label y  0    64637\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "40\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64637\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "39\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64637\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "38\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64637\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "37\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64637\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "36\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64637\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "35\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64637\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "34\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64637\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "33\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64637\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "32\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64637\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "31\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 23]]\n",
            "started duplication\n",
            "neg_vals [1, 1, 23]\n",
            "0.2027671932225963 17 16 67.8399927020618\n",
            "Adding 68 negative records\n",
            "names  ['age', 'gender', 'native-country'] [1, 1, 23]\n",
            "label y  0    64705\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "30\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64705\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "29\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64705\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "28\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64705\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "27\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64705\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "26\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64705\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "25\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64705\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "24\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64705\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "23\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64705\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "22\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64705\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "21\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64705\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "20\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 35], [4, 11]]\n",
            "started duplication\n",
            "neg_vals [1, 35]\n",
            "0.19644128113879003 17 19 67.5398550724638\n",
            "Adding 68 negative records\n",
            "names  ['race', 'native-country'] [1, 35]\n",
            "neg_vals [4, 11]\n",
            "0.18024260406667247 13 20 52.1250121041931\n",
            "Adding 52 negative records\n",
            "names  ['race', 'native-country'] [4, 11]\n",
            "label y  0    64825\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "19\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64825\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "18\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 35]]\n",
            "started duplication\n",
            "neg_vals [0, 35]\n",
            "0.23190344043598918 16 22 46.9942329873126\n",
            "Adding 47 negative records\n",
            "names  ['relationship', 'native-country'] [0, 35]\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "17\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "16\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "15\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "14\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "13\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "12\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "11\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "10\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "9\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "8\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "6\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "5\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "4\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "3\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "2\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "1\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "label y  0    64872\n",
            "1    11212\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started duplication\")\n",
        "  new_train_data = naive_duplicate(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  print(\"label y \", new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuQ3lc7aU9NG"
      },
      "source": [
        "### Results Lattice\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTqA6ic3sHXO"
      },
      "outputs": [],
      "source": [
        "test_set['predicted'] = test_predict\n",
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "d,d1,d2 = div_results(\"Adult\",\"Duplication-Lattice\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Duplication-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Duplication-Lattice\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"Adult\",\"Duplication-Lattice\",\"SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7whA1nLnvev0"
      },
      "outputs": [],
      "source": [
        "def fairness_score_computation(d, metrics):\n",
        "    sum_of_score = 0\n",
        "    for idx, row in d.iterrows():\n",
        "      sum_of_score += row['support'] * row[metrics]\n",
        "    return sum_of_score\n",
        "\n",
        "print(fairness_score_computation(d, 'd_fpr'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ4Kag3MuFuf"
      },
      "source": [
        "## Run Algorithm Leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWAzykiouMXt",
        "outputId": "21117ae0-f0fd-4a1e-e324-9b235a0cbb73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "63\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 0, 4, 1, 38], [0, 2, 5, 4, 0, 38], [1, 2, 0, 0, 1, 38], [1, 2, 0, 4, 1, 25], [1, 2, 5, 2, 0, 38], [2, 2, 0, 4, 1, 25]]\n",
            "[[1, 2, 0, 1, 1, 29], [1, 2, 0, 1, 1, 38], [1, 2, 0, 4, 1, 38], [1, 2, 5, 4, 0, 38]]\n",
            "started duplication\n",
            "pos_vals [0, 2, 0, 4, 1, 38]\n",
            "0.9786427145708583 366 1102 712.464271457086\n",
            "0.9786427145708583 366 1102 712.464271457086\n",
            "Adding 712 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [0, 2, 0, 4, 1, 38]\n",
            "pos_vals [0, 2, 5, 4, 0, 38]\n",
            "1.0848861283643891 77 154 90.0724637681159\n",
            "1.0848861283643891 77 154 90.0724637681159\n",
            "Adding 90 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [0, 2, 5, 4, 0, 38]\n",
            "pos_vals [1, 2, 0, 0, 1, 38]\n",
            "1.0353780313837375 14 44 31.5566333808844\n",
            "1.0353780313837375 14 44 31.5566333808844\n",
            "Adding 32 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 0, 0, 1, 38]\n",
            "pos_vals [1, 2, 0, 4, 1, 25]\n",
            "1.014265335235378 17 137 121.954350927247\n",
            "1.014265335235378 17 137 121.954350927247\n",
            "Adding 122 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 0, 4, 1, 25]\n",
            "pos_vals [1, 2, 5, 2, 0, 38]\n",
            "1.3063063063063063 31 47 30.3963963963964\n",
            "1.3063063063063063 31 47 30.3963963963964\n",
            "Adding 30 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 5, 2, 0, 38]\n",
            "pos_vals [2, 2, 0, 4, 1, 25]\n",
            "0.8496659242761693 6 29 18.6403118040089\n",
            "0.8496659242761693 6 29 18.6403118040089\n",
            "Adding 19 positive records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [2, 2, 0, 4, 1, 25]\n",
            "neg_vals [1, 2, 0, 1, 1, 29]\n",
            "1.0 30 16 14.0000000000000\n",
            "Adding 14 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 0, 1, 1, 29]\n",
            "neg_vals [1, 2, 0, 1, 1, 38]\n",
            "1.037211885587337 29 17 10.9595716198125\n",
            "Adding 11 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 0, 1, 1, 38]\n",
            "neg_vals [1, 2, 0, 4, 1, 38]\n",
            "0.6795545932570368 3416 3241 1785.82203004096\n",
            "Adding 1786 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 0, 4, 1, 38]\n",
            "neg_vals [1, 2, 5, 4, 0, 38]\n",
            "0.6730769230769231 408 281 325.171428571429\n",
            "Adding 325 negative records\n",
            "names  ['age', 'marital-status', 'relationship', 'race', 'gender', 'native-country'] [1, 2, 5, 4, 0, 38]\n",
            "label y 0    25910\n",
            "1     8887\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in [all_names_lst[0]]:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started duplication\")\n",
        "  new_train_data = naive_duplicate(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  print(\"label y\", new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyiaC-BPuT-N"
      },
      "source": [
        "### Results Leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVCnBjPxsJgg"
      },
      "outputs": [],
      "source": [
        "test_set['predicted'] = test_predict\n",
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "d,d1,d2 = div_results(\"Adult\",\"Duplication-Leaf\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Duplication-Leaf\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Duplication-Leaf\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"Adult\",\"Duplication-Leaf\",\"SVM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ud6LiPvubLz"
      },
      "source": [
        "## Run Algorithm Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itgAs3JCuj6B",
        "outputId": "c800536b-29b5-49f4-c8f5-79f22056b01f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "1\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "Label y 0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "2\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "Label y 0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "3\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "Label y 0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "4\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "Label y 0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "5\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "Label y 0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "6\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "Label y 0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "all_names_lst_top = find_top(all_names)\n",
        "for a in all_names_lst_top:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started duplication\")\n",
        "  new_train_data = naive_duplicate(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "\n",
        "  print(\"Label y\", new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtQcykniuqUC"
      },
      "source": [
        "### Results Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PXEjrEDsOEl"
      },
      "outputs": [],
      "source": [
        "test_set['predicted'] = test_predict\n",
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "d,d1,d2 = div_results(\"Adult\",\"Duplication-Top\",\"DT\")\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Duplication-Top\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Duplication-Top\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"Adult\",\"Duplication-Top\",\"SVM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SfzogxQ-Q5d"
      },
      "source": [
        "#Down-sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "h9m0e5GbVL-d"
      },
      "outputs": [],
      "source": [
        "def round_int(x):\n",
        "    if x in [float(\"-inf\"),float(\"inf\")]: return 0\n",
        "    return int(round(x))\n",
        "\n",
        "\n",
        "def make_remove(d, group_lst, diff, names, label_y, need_positive_or_negative):\n",
        "    temp = copy.deepcopy(d)\n",
        "    for i in range(len(group_lst)):\n",
        "        att_name = names[i]\n",
        "        temp = temp[(temp[att_name] == group_lst[i])]\n",
        "    temp = temp[(temp[label_y] == need_positive_or_negative)]\n",
        "    # randomly generated diff samples\n",
        "    # the number needed is more than the not needed numbers.\n",
        "    if(diff>len(temp)):\n",
        "        diff = len(temp)\n",
        "    generated = temp.sample(n = diff, replace = False, axis = 0)\n",
        "    return generated.index\n",
        "\n",
        "\n",
        "def naive_downsampling(d, temp2, names, need_pos, need_neg, label_y):\n",
        "    # add more records for all groups\n",
        "    # The smote algorithm to boost the coverage\n",
        "    for r in need_pos:\n",
        "        print(\"removing more negative\")\n",
        "    # add more positive records\n",
        "        # determine how many points to add\n",
        "        print(r)\n",
        "        diff = compute_diff_remove(r, temp2, names, label_y, need_positive_or_negative = 1)\n",
        "        if diff == -1:\n",
        "          continue\n",
        "        diff = round_int(diff)\n",
        "        # add more records\n",
        "        print(\"Removed \" + str(diff) +\" negative records\")\n",
        "        samples_to_remove = make_remove(d, r, diff, names, label_y, need_positive_or_negative = 0)\n",
        "        d.drop(index  = samples_to_remove, inplace = True)\n",
        "    for k in need_neg:\n",
        "        print(k)\n",
        "        diff = compute_diff_remove(k, temp2, names, label_y, need_positive_or_negative = 0)\n",
        "        if diff == -1:\n",
        "          continue\n",
        "        diff = round_int(diff)\n",
        "        print(\"Removed \" + str(diff) +\" positive records\")\n",
        "        samples_to_remove = make_remove(d, k, diff, names, label_y, need_positive_or_negative = 1)\n",
        "        d.drop(index  = samples_to_remove, inplace = True)\n",
        "    return d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcUYj8wJwrHK"
      },
      "source": [
        "## Run Algorithm Lattice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTfYbyt4pcRq",
        "outputId": "0ba331cf-787e-4e9e-ddb7-978d086125e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "63\n",
            "The time to compute unfair group is 0.6379449367523193\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 0, 4, 1, 38], [0, 2, 5, 4, 0, 38], [1, 2, 0, 0, 1, 38], [1, 2, 0, 4, 1, 25], [1, 2, 5, 2, 0, 38], [2, 2, 0, 4, 1, 25]]\n",
            "[[1, 2, 0, 1, 1, 29], [1, 2, 0, 1, 1, 38], [1, 2, 0, 4, 1, 38], [1, 2, 5, 4, 0, 38]]\n",
            "removing more negative\n",
            "[0, 2, 0, 4, 1, 38]\n",
            "0.9786427145708583 366 1102 728.012645319192\n",
            "Removed 728 negative records\n",
            "removing more negative\n",
            "[0, 2, 5, 4, 0, 38]\n",
            "1.0848861283643891 77 154 83.0248091603054\n",
            "Removed 83 negative records\n",
            "removing more negative\n",
            "[1, 2, 0, 0, 1, 38]\n",
            "1.0353780313837375 14 44 30.4783686966107\n",
            "Removed 30 negative records\n",
            "removing more negative\n",
            "[1, 2, 0, 4, 1, 25]\n",
            "1.014265335235378 17 137 120.239099859353\n",
            "Removed 120 negative records\n",
            "removing more negative\n",
            "[1, 2, 5, 2, 0, 38]\n",
            "1.3063063063063063 31 47 23.2689655172414\n",
            "Removed 23 negative records\n",
            "removing more negative\n",
            "[2, 2, 0, 4, 1, 25]\n",
            "0.8496659242761693 6 29 21.9384010484928\n",
            "Removed 22 negative records\n",
            "[1, 2, 0, 1, 1, 29]\n",
            "1.0 30 16 14.0000000000000\n",
            "Removed 14 positive records\n",
            "[1, 2, 0, 1, 1, 38]\n",
            "1.037211885587337 29 17 11.3673979450153\n",
            "Removed 11 positive records\n",
            "[1, 2, 0, 4, 1, 38]\n",
            "0.6795545932570368 3416 3241 1213.56356325395\n",
            "Removed 1214 positive records\n",
            "[1, 2, 5, 4, 0, 38]\n",
            "0.6730769230769231 408 281 218.865384615384\n",
            "Removed 219 positive records\n",
            "0    22768\n",
            "1     6424\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "62\n",
            "The time to compute unfair group is 0.47623467445373535\n",
            "The sets of need pos and neg are\n",
            "[[2, 0, 0, 1, 38], [2, 0, 1, 1, 2], [2, 0, 1, 1, 29], [2, 0, 3, 1, 38], [2, 0, 4, 1, 25], [2, 2, 4, 1, 38]]\n",
            "[[2, 0, 1, 1, 18], [2, 0, 1, 1, 38], [2, 0, 4, 1, 1], [6, 4, 4, 1, 38]]\n",
            "removing more negative\n",
            "[2, 0, 0, 1, 38]\n",
            "0.774941578285098 19 41 16.4820227325447\n",
            "Removed 16 negative records\n",
            "removing more negative\n",
            "[2, 0, 1, 1, 2]\n",
            "1.0344827586206897 16 25 9.53333333333333\n",
            "Removed 10 negative records\n",
            "removing more negative\n",
            "[2, 0, 1, 1, 29]\n",
            "1.064748201438849 22 34 13.3378378378378\n",
            "Removed 13 negative records\n",
            "removing more negative\n",
            "[2, 0, 3, 1, 38]\n",
            "0.7725490196078432 9 22 10.3502538071066\n",
            "Removed 10 negative records\n",
            "removing more negative\n",
            "[2, 0, 4, 1, 25]\n",
            "0.7727106227106227 25 81 48.6463616970846\n",
            "Removed 49 negative records\n",
            "removing more negative\n",
            "[2, 2, 4, 1, 38]\n",
            "0.7392099487929773 6 32 23.8832261256804\n",
            "Removed 24 negative records\n",
            "[2, 0, 1, 1, 18]\n",
            "0.875 30 17 15.1250000000000\n",
            "Removed 15 positive records\n",
            "[2, 0, 1, 1, 38]\n",
            "0.7719881098094072 41 25 21.7002972547648\n",
            "Removed 22 positive records\n",
            "[2, 0, 4, 1, 1]\n",
            "0.7678148350646984 29 22 12.1080736285766\n",
            "Removed 12 positive records\n",
            "[6, 4, 4, 1, 38]\n",
            "0.1478494623655914 14 28 9.86021505376345\n",
            "Removed 10 positive records\n",
            "0    22646\n",
            "1     6365\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "61\n",
            "The time to compute unfair group is 0.35141849517822266\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 2, 1, 38], [1, 2, 4, 1, 38], [1, 3, 4, 1, 38], [2, 4, 4, 1, 38]]\n",
            "[[0, 0, 4, 1, 38], [0, 5, 4, 0, 38], [1, 5, 2, 0, 38], [1, 5, 4, 0, 38], [2, 5, 4, 0, 38]]\n",
            "removing more negative\n",
            "[0, 0, 2, 1, 38]\n",
            "0.5690298507462687 8 61 46.9409836065574\n",
            "Removed 47 negative records\n",
            "removing more negative\n",
            "[1, 2, 4, 1, 38]\n",
            "0.4619662719770362 10 67 45.3533980582524\n",
            "Removed 45 negative records\n",
            "removing more negative\n",
            "[1, 3, 4, 1, 38]\n",
            "0.3720328010358222 25 358 290.801624129930\n",
            "Removed 291 negative records\n",
            "removing more negative\n",
            "[2, 4, 4, 1, 38]\n",
            "0.6197235711617483 24 86 47.2730560578662\n",
            "Removed 47 negative records\n",
            "[0, 0, 4, 1, 38]\n",
            "0.46293568973981347 367 376 192.936180657830\n",
            "Removed 193 positive records\n",
            "[0, 5, 4, 0, 38]\n",
            "0.10478497880072683 79 77 70.9315566323440\n",
            "Removed 71 positive records\n",
            "[1, 5, 2, 0, 38]\n",
            "0.2691065662002153 31 24 24.5414424111948\n",
            "Removed 25 positive records\n",
            "[1, 5, 4, 0, 38]\n",
            "0.1831473643709119 192 283 140.169295883032\n",
            "Removed 140 positive records\n",
            "[2, 5, 4, 0, 38]\n",
            "0.2686868686868687 96 116 64.8323232323232\n",
            "Removed 65 positive records\n",
            "0    22216\n",
            "1     5871\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "60\n",
            "The time to compute unfair group is 0.6968436241149902\n",
            "The sets of need pos and neg are\n",
            "[[1, 3, 4, 1, 38], [1, 5, 2, 1, 38], [2, 5, 4, 1, 38], [2, 6, 4, 1, 38]]\n",
            "[[1, 2, 4, 1, 25], [2, 2, 4, 1, 38]]\n",
            "removing more negative\n",
            "[1, 3, 4, 1, 38]\n",
            "0.508551208964026 7 36 22.2354078082721\n",
            "Removed 22 negative records\n",
            "removing more negative\n",
            "[1, 5, 2, 1, 38]\n",
            "0.3271954674220963 1 48 44.9437229437229\n",
            "Removed 45 negative records\n",
            "removing more negative\n",
            "[2, 5, 4, 1, 38]\n",
            "0.7486288848263254 7 27 17.6495726495726\n",
            "Removed 18 negative records\n",
            "removing more negative\n",
            "[2, 6, 4, 1, 38]\n",
            "0.6747694886839899 22 68 35.3962732919255\n",
            "Removed 35 negative records\n",
            "[1, 2, 4, 1, 25]\n",
            "0.6719107551487414 17 15 6.92133867276888\n",
            "Removed 7 positive records\n",
            "[2, 2, 4, 1, 38]\n",
            "0.6155070486584812 1452 1536 506.581173260573\n",
            "Removed 507 positive records\n",
            "0    22096\n",
            "1     5357\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "59\n",
            "The time to compute unfair group is 0.41927480697631836\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 0, 1, 25]]\n",
            "[[2, 0, 4, 1, 38], [2, 6, 1, 1, 38]]\n",
            "removing more negative\n",
            "[0, 2, 0, 1, 25]\n",
            "0.45490981963927857 2 29 24.6035242290749\n",
            "Removed 25 negative records\n",
            "[2, 0, 4, 1, 38]\n",
            "0.2046875 20 25 14.8828125000000\n",
            "Removed 15 positive records\n",
            "[2, 6, 1, 1, 38]\n",
            "0.1903367496339678 21 33 14.7188872620791\n",
            "Removed 15 positive records\n",
            "0    22071\n",
            "1     5327\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "58\n",
            "The time to compute unfair group is 0.4488358497619629\n",
            "The sets of need pos and neg are\n",
            "[[1, 2, 5, 4, 38]]\n",
            "[]\n",
            "removing more negative\n",
            "[1, 2, 5, 4, 38]\n",
            "0.655625356938892 52 281 201.686411149826\n",
            "Removed 202 negative records\n",
            "0    21869\n",
            "1     5327\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "57\n",
            "The time to compute unfair group is 0.807880163192749\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 2, 5, 4, 0]]\n",
            "[1, 2, 5, 4, 0]\n",
            "0.3044982698961938 76 102 44.9411764705883\n",
            "Removed 45 positive records\n",
            "0    21869\n",
            "1     5282\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "56\n",
            "The time to compute unfair group is 0.37333202362060547\n",
            "The sets of need pos and neg are\n",
            "[[2, 4, 1, 38], [3, 4, 1, 38]]\n",
            "[[0, 1, 1, 29], [0, 4, 1, 25], [0, 4, 1, 38]]\n",
            "removing more negative\n",
            "[2, 4, 1, 38]\n",
            "0.36367858801672087 11 201 170.753512132822\n",
            "Removed 171 negative records\n",
            "removing more negative\n",
            "[3, 4, 1, 38]\n",
            "0.3596272718885506 40 1736 1624.77373011801\n",
            "Removed 1625 negative records\n",
            "[0, 1, 1, 29]\n",
            "0.7037037037037037 22 21 7.22222222222222\n",
            "Removed 7 positive records\n",
            "[0, 4, 1, 25]\n",
            "0.6236463696076691 18 13 9.89259719510031\n",
            "Removed 10 positive records\n",
            "[0, 4, 1, 38]\n",
            "0.179210875331565 3321 5154 2397.34714854112\n",
            "Removed 2397 positive records\n",
            "0    20073\n",
            "1     2868\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "55\n",
            "The time to compute unfair group is 0.34520959854125977\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 0, 1, 38], [2, 1, 1, 38], [2, 2, 1, 38], [2, 4, 1, 1], [2, 4, 1, 4], [2, 4, 1, 10], [2, 4, 1, 21]]\n",
            "[2, 0, 1, 38]\n",
            "0.21825962910128388 19 27 13.1069900142653\n",
            "Removed 13 positive records\n",
            "[2, 1, 1, 38]\n",
            "0.23260680034873582 20 25 14.1848299912816\n",
            "Removed 14 positive records\n",
            "[2, 2, 1, 38]\n",
            "0.17640225688682376 241 326 183.492864254895\n",
            "Removed 183 positive records\n",
            "[2, 4, 1, 1]\n",
            "0.20646811620683356 17 22 12.4577014434497\n",
            "Removed 12 positive records\n",
            "[2, 4, 1, 4]\n",
            "0.20586080586080585 16 20 11.8827838827839\n",
            "Removed 12 positive records\n",
            "[2, 4, 1, 10]\n",
            "0.20461200585651537 22 27 16.4754758418741\n",
            "Removed 16 positive records\n",
            "[2, 4, 1, 21]\n",
            "0.20586617781851513 15 26 9.64747937671861\n",
            "Removed 10 positive records\n",
            "0    20073\n",
            "1     2608\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "54\n",
            "The time to compute unfair group is 0.1830739974975586\n",
            "The sets of need pos and neg are\n",
            "[[2, 0, 1, 38]]\n",
            "[[2, 0, 1, 2], [2, 0, 1, 18], [2, 0, 1, 29]]\n",
            "removing more negative\n",
            "[2, 0, 1, 38]\n",
            "0.6016427104722792 1003 5528 3860.89761092150\n",
            "Removed 3861 negative records\n",
            "[2, 0, 1, 2]\n",
            "0.21116870088613945 16 15 12.8324694867079\n",
            "Removed 13 positive records\n",
            "[2, 0, 1, 18]\n",
            "0.21084337349397592 19 22 14.3614457831325\n",
            "Removed 14 positive records\n",
            "[2, 0, 1, 29]\n",
            "0.2110107095046854 19 22 14.3577643908969\n",
            "Removed 14 positive records\n",
            "0    16212\n",
            "1     2567\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "53\n",
            "The time to compute unfair group is 0.32848072052001953\n",
            "The sets of need pos and neg are\n",
            "[[2, 0, 4, 10], [2, 5, 4, 38]]\n",
            "[]\n",
            "removing more negative\n",
            "[2, 0, 4, 10]\n",
            "0.5837927232635061 6 27 16.7223796033994\n",
            "Removed 17 negative records\n",
            "removing more negative\n",
            "[2, 5, 4, 38]\n",
            "0.5791284403669725 58 266 165.849504950495\n",
            "Removed 166 negative records\n",
            "0    16029\n",
            "1     2567\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "52\n",
            "The time to compute unfair group is 0.361574649810791\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     2567\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "51\n",
            "The time to compute unfair group is 0.20524811744689941\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     2567\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "50\n",
            "The time to compute unfair group is 0.12733864784240723\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 5, 0, 38], [2, 5, 0, 38]]\n",
            "[1, 5, 0, 38]\n",
            "0.11263223397635345 37 62 30.0168014934661\n",
            "Removed 30 positive records\n",
            "[2, 5, 0, 38]\n",
            "0.12669376693766937 40 63 32.0182926829269\n",
            "Removed 32 positive records\n",
            "0    16029\n",
            "1     2505\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "49\n",
            "The time to compute unfair group is 0.15298819541931152\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 4, 38]]\n",
            "[1, 0, 4, 38]\n",
            "0.2238252267106348 589 985 368.532151690024\n",
            "Removed 369 positive records\n",
            "0    16029\n",
            "1     2136\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "48\n",
            "The time to compute unfair group is 0.3623361587524414\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 1, 1], [1, 0, 3, 1], [1, 3, 4, 1], [1, 5, 1, 0], [2, 0, 4, 1]]\n",
            "[1, 0, 1, 1]\n",
            "0.29390420899854863 52 81 28.1937590711176\n",
            "Removed 28 positive records\n",
            "[1, 0, 3, 1]\n",
            "0.3078055964653903 14 20 7.84388807069220\n",
            "Removed 8 positive records\n",
            "[1, 3, 4, 1]\n",
            "0.20847953216374268 25 25 19.7880116959064\n",
            "Removed 20 positive records\n",
            "[1, 5, 1, 0]\n",
            "0.1848341232227488 16 19 12.4881516587678\n",
            "Removed 12 positive records\n",
            "[2, 0, 4, 1]\n",
            "0.2971014492753623 334 510 182.478260869565\n",
            "Removed 182 positive records\n",
            "0    16029\n",
            "1     1886\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "47\n",
            "The time to compute unfair group is 0.1529233455657959\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1886\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "46\n",
            "The time to compute unfair group is 0.20208215713500977\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1886\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "45\n",
            "The time to compute unfair group is 0.4681384563446045\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 2, 2, 1]]\n",
            "[2, 2, 2, 1]\n",
            "0.31266490765171506 24 35 13.0567282321900\n",
            "Removed 13 positive records\n",
            "0    16029\n",
            "1     1873\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "44\n",
            "The time to compute unfair group is 0.47875022888183594\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1873\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "43\n",
            "The time to compute unfair group is 0.6837406158447266\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1873\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "42\n",
            "The time to compute unfair group is 0.6257457733154297\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1873\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "41\n",
            "The time to compute unfair group is 0.3642098903656006\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[4, 1, 8]]\n",
            "[4, 1, 8]\n",
            "0.18901920788713242 16 23 11.6525582185960\n",
            "Removed 12 positive records\n",
            "0    16029\n",
            "1     1861\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "40\n",
            "The time to compute unfair group is 0.13124871253967285\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1861\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "39\n",
            "The time to compute unfair group is 0.13856983184814453\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 2, 38]]\n",
            "[0, 2, 38]\n",
            "0.14309576837416482 48 97 34.1197104677060\n",
            "Removed 34 positive records\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "38\n",
            "The time to compute unfair group is 0.22602605819702148\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "37\n",
            "The time to compute unfair group is 0.10533857345581055\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "36\n",
            "The time to compute unfair group is 0.12038969993591309\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "35\n",
            "The time to compute unfair group is 0.19218826293945312\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "34\n",
            "The time to compute unfair group is 0.10126018524169922\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "33\n",
            "The time to compute unfair group is 0.20772933959960938\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "32\n",
            "The time to compute unfair group is 0.2062849998474121\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "31\n",
            "The time to compute unfair group is 0.10039973258972168\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "30\n",
            "The time to compute unfair group is 0.13657164573669434\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "29\n",
            "The time to compute unfair group is 0.16521978378295898\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "28\n",
            "The time to compute unfair group is 0.10265350341796875\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "27\n",
            "The time to compute unfair group is 0.15000438690185547\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "26\n",
            "The time to compute unfair group is 0.2783026695251465\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "25\n",
            "The time to compute unfair group is 0.20580124855041504\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "24\n",
            "The time to compute unfair group is 0.3582608699798584\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "23\n",
            "The time to compute unfair group is 0.40867161750793457\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "22\n",
            "The time to compute unfair group is 0.37836551666259766\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "21\n",
            "The time to compute unfair group is 0.2393958568572998\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1827\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "20\n",
            "The time to compute unfair group is 0.1887209415435791\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 23]]\n",
            "[1, 23]\n",
            "0.15960912052117263 11 20 7.80781758957654\n",
            "Removed 8 positive records\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "19\n",
            "The time to compute unfair group is 0.09865283966064453\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "18\n",
            "The time to compute unfair group is 0.10138821601867676\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "17\n",
            "The time to compute unfair group is 0.06594252586364746\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "16\n",
            "The time to compute unfair group is 0.1619422435760498\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "15\n",
            "The time to compute unfair group is 0.07156157493591309\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "14\n",
            "The time to compute unfair group is 0.08391022682189941\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "13\n",
            "The time to compute unfair group is 0.09973478317260742\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "12\n",
            "The time to compute unfair group is 0.11369037628173828\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "11\n",
            "The time to compute unfair group is 0.11159682273864746\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "10\n",
            "The time to compute unfair group is 0.030238628387451172\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "9\n",
            "The time to compute unfair group is 0.05314373970031738\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "8\n",
            "The time to compute unfair group is 0.10113263130187988\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "7\n",
            "The time to compute unfair group is 0.052839040756225586\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "6\n",
            "The time to compute unfair group is 0.10479140281677246\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "5\n",
            "The time to compute unfair group is 0.011256933212280273\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "4\n",
            "The time to compute unfair group is 0.00857996940612793\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "3\n",
            "The time to compute unfair group is 0.010582447052001953\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "2\n",
            "The time to compute unfair group is 0.013072013854980469\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "1\n",
            "The time to compute unfair group is 0.027023792266845703\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    16029\n",
            "1     1819\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  new_train_data = naive_downsampling(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhS42vuGsI2q"
      },
      "source": [
        "### Results Lattice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbzCpafMsVko"
      },
      "outputs": [],
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Down Sampling-Lattice\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Down Sampling-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Down Sampling-Lattice\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"Adult\",\"Down Sampling-Lattice\",\"SVM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqfnIjDrwk9i"
      },
      "source": [
        "## Run Algorithm Leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvmlKdUqwl_1",
        "outputId": "5b81c07f-3b3a-47db-f247-4d99848a4c67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "63\n",
            "The time to compute unfair group is 0.9208121299743652\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 0, 4, 1, 38], [0, 2, 5, 4, 0, 38], [1, 2, 0, 0, 1, 38], [1, 2, 0, 4, 1, 25], [1, 2, 5, 2, 0, 38], [2, 2, 0, 4, 1, 25]]\n",
            "[[1, 2, 0, 1, 1, 29], [1, 2, 0, 1, 1, 38], [1, 2, 0, 4, 1, 38], [1, 2, 5, 4, 0, 38]]\n",
            "removing more negative\n",
            "[0, 2, 0, 4, 1, 38]\n",
            "0.9786427145708583 366 1102 728.012645319192\n",
            "Removed 728 negative records\n",
            "removing more negative\n",
            "[0, 2, 5, 4, 0, 38]\n",
            "1.0848861283643891 77 154 83.0248091603054\n",
            "Removed 83 negative records\n",
            "removing more negative\n",
            "[1, 2, 0, 0, 1, 38]\n",
            "1.0353780313837375 14 44 30.4783686966107\n",
            "Removed 30 negative records\n",
            "removing more negative\n",
            "[1, 2, 0, 4, 1, 25]\n",
            "1.014265335235378 17 137 120.239099859353\n",
            "Removed 120 negative records\n",
            "removing more negative\n",
            "[1, 2, 5, 2, 0, 38]\n",
            "1.3063063063063063 31 47 23.2689655172414\n",
            "Removed 23 negative records\n",
            "removing more negative\n",
            "[2, 2, 0, 4, 1, 25]\n",
            "0.8496659242761693 6 29 21.9384010484928\n",
            "Removed 22 negative records\n",
            "[1, 2, 0, 1, 1, 29]\n",
            "1.0 30 16 14.0000000000000\n",
            "Removed 14 positive records\n",
            "[1, 2, 0, 1, 1, 38]\n",
            "1.037211885587337 29 17 11.3673979450153\n",
            "Removed 11 positive records\n",
            "[1, 2, 0, 4, 1, 38]\n",
            "0.6795545932570368 3416 3241 1213.56356325395\n",
            "Removed 1214 positive records\n",
            "[1, 2, 5, 4, 0, 38]\n",
            "0.6730769230769231 408 281 218.865384615384\n",
            "Removed 219 positive records\n",
            "0    22768\n",
            "1     6424\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in [all_names_lst[0]]:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "\n",
        "  new_train_data = naive_downsampling(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-O26rF9xYc-"
      },
      "source": [
        "### Results Leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HWsJpa-sgzZ"
      },
      "outputs": [],
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Down Sampling-Leaf\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Down Sampling-Leaf\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Down Sampling-Leaf\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"Adult\",\"Down Sampling-Leaf\",\"SVM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEjc2orXxeJU"
      },
      "source": [
        "## Run Algorithm Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1ttSPisxj-R",
        "outputId": "d295214e-d60a-4d0a-cbe3-7111c8b47f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "1\n",
            "The time to compute unfair group is 0.017656564712524414\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "2\n",
            "The time to compute unfair group is 0.043984413146972656\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "3\n",
            "The time to compute unfair group is 0.026145458221435547\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "4\n",
            "The time to compute unfair group is 0.03699064254760742\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "5\n",
            "The time to compute unfair group is 0.011373043060302734\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "6\n",
            "The time to compute unfair group is 0.15406370162963867\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "all_names_lst_top = find_top(all_names)\n",
        "for a in all_names_lst_top:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  new_train_data = naive_downsampling(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQOAJrGyxrsr"
      },
      "source": [
        "### Results Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyrmV-7cshtA"
      },
      "outputs": [],
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Down Sampling-Top\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Down Sampling-Top\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Down Sampling-Top\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"Adult\",\"Down Sampling-Top\",\"SVM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWbCzMkrnT-0"
      },
      "source": [
        "# Massaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tINoeYnSnWn4"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "def round_int(x):\n",
        "    if x in [float(\"-inf\"),float(\"inf\")]: return 0\n",
        "    return int(round(x))\n",
        "\n",
        "def get_depromotion(d, diff, group_lst, names, label_y, flag_depro):\n",
        "    input_test = pd.DataFrame(d, columns = columns_compas)\n",
        "\n",
        "    clf = MultinomialNB()\n",
        "    temp_train_label = pd.DataFrame(d, columns = [label_y])\n",
        "    temp_train_label = temp_train_label[label_y]\n",
        "    temp_train_label = temp_train_label.astype('int')\n",
        "    clf = clf.fit(input_test, temp_train_label)\n",
        "    prob  = clf.predict_proba(input_test)[:,0]\n",
        "    select = copy.deepcopy(d)\n",
        "    select['prob'] = prob # the higher the probablity is, the more likely for it to be 0\n",
        "    # filter out those belongs to this group\n",
        "    for i in range(len(group_lst)):\n",
        "        att_name = names[i]\n",
        "        select = select[(select[att_name] == group_lst[i])]\n",
        "    select = select[(select[label_y] == flag_depro)]\n",
        "    # rank them according to the probability\n",
        "    # filp the records and remove the records from d\n",
        "    if (flag_depro == 0):\n",
        "        select.sort_values(by=\"prob\", ascending=True, inplace=True)\n",
        "        select[label_y] = 1\n",
        "    else:\n",
        "        select.sort_values(by=\"prob\", ascending=False, inplace=True)\n",
        "        select[label_y] = 0\n",
        "    head = select.head(diff)\n",
        "    index_list = []\n",
        "    index_list = list(head.index)\n",
        "    d.drop(index_list,inplace = True)\n",
        "    head.drop(columns = ['prob'],inplace = True)\n",
        "    return head\n",
        "\n",
        "\n",
        "\n",
        "def naive_massaging(d, temp2, names, need_pos, need_neg,label_y):\n",
        "    # add more records for all groups\n",
        "    # The smote algorithm to boost the coverage\n",
        "    for r in need_pos:\n",
        "        print(\"adding more positive\")\n",
        "    # add more positive records\n",
        "        # determine how many points to add\n",
        "        print(r)\n",
        "        diff = compute_diff_add_and_remove(r, temp2, 1, label_y, names)\n",
        "        diff =  round_int(diff)\n",
        "        # add more records\n",
        "        #0 for promotion\n",
        "        samples_to_add = get_depromotion(d, diff, r, names, label_y, flag_depro = 0)\n",
        "        print(\"Changed \" + str(len(samples_to_add)) +\" records\")\n",
        "        d = pd.concat([d, samples_to_add])\n",
        "        print(len(d))\n",
        "    for k in need_neg:\n",
        "        print(k)\n",
        "        print(\"adding more negative\")\n",
        "        diff = compute_diff_add_and_remove(k, temp2, 0, label_y, names)\n",
        "        diff =  round_int(diff)\n",
        "        #1 for demotion\n",
        "        samples_to_add = get_depromotion(d, diff, k, names, label_y, flag_depro = 1)\n",
        "        print(\"Changed \" + str(len(samples_to_add)) +\" records\")\n",
        "        d = pd.concat([d, samples_to_add])\n",
        "        print(len(d))\n",
        "    return d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6JgxVuTx8cj"
      },
      "source": [
        "## Run Algorithm Lattice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CvRKxY6ne5o",
        "outputId": "99f4a395-5382-408b-8110-1b084e5e7494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "63\n",
            "The time to compute unfair group is 0.7699806690216064\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 0, 4, 1, 38], [0, 2, 5, 4, 0, 38], [1, 2, 0, 0, 1, 38], [1, 2, 0, 4, 1, 25], [1, 2, 5, 2, 0, 38], [2, 2, 0, 4, 1, 25]]\n",
            "[[1, 2, 0, 1, 1, 29], [1, 2, 0, 1, 1, 38], [1, 2, 0, 4, 1, 38], [1, 2, 5, 4, 0, 38]]\n",
            "adding more positive\n",
            "[0, 2, 0, 4, 1, 38]\n",
            "Changed 360 records\n",
            "31656\n",
            "adding more positive\n",
            "[0, 2, 5, 4, 0, 38]\n",
            "Changed 43 records\n",
            "31656\n",
            "adding more positive\n",
            "[1, 2, 0, 0, 1, 38]\n",
            "Changed 16 records\n",
            "31656\n",
            "adding more positive\n",
            "[1, 2, 0, 4, 1, 25]\n",
            "Changed 61 records\n",
            "31656\n",
            "adding more positive\n",
            "[1, 2, 5, 2, 0, 38]\n",
            "Changed 13 records\n",
            "31656\n",
            "adding more positive\n",
            "[2, 2, 0, 4, 1, 25]\n",
            "Changed 10 records\n",
            "31656\n",
            "[1, 2, 0, 1, 1, 29]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "31656\n",
            "[1, 2, 0, 1, 1, 38]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "31656\n",
            "[1, 2, 0, 4, 1, 38]\n",
            "adding more negative\n",
            "Changed 723 records\n",
            "31656\n",
            "[1, 2, 5, 4, 0, 38]\n",
            "adding more negative\n",
            "Changed 131 records\n",
            "31656\n",
            "0    24138\n",
            "1     7518\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "62\n",
            "The time to compute unfair group is 0.6647822856903076\n",
            "The sets of need pos and neg are\n",
            "[[2, 0, 1, 1, 2], [2, 0, 1, 1, 29], [2, 0, 3, 1, 38], [2, 2, 4, 0, 38], [2, 2, 4, 1, 38]]\n",
            "[[2, 0, 1, 1, 18], [2, 0, 1, 1, 38], [2, 0, 4, 1, 1], [6, 4, 4, 1, 38]]\n",
            "adding more positive\n",
            "[2, 0, 1, 1, 2]\n",
            "Changed 5 records\n",
            "31656\n",
            "adding more positive\n",
            "[2, 0, 1, 1, 29]\n",
            "Changed 7 records\n",
            "31656\n",
            "adding more positive\n",
            "[2, 0, 3, 1, 38]\n",
            "Changed 5 records\n",
            "31656\n",
            "adding more positive\n",
            "[2, 2, 4, 0, 38]\n",
            "Changed 6 records\n",
            "31656\n",
            "adding more positive\n",
            "[2, 2, 4, 1, 38]\n",
            "Changed 10 records\n",
            "31656\n",
            "[2, 0, 1, 1, 18]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "31656\n",
            "[2, 0, 1, 1, 38]\n",
            "adding more negative\n",
            "Changed 12 records\n",
            "31656\n",
            "[2, 0, 4, 1, 1]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "31656\n",
            "[6, 4, 4, 1, 38]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "31656\n",
            "0    24141\n",
            "1     7515\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "61\n",
            "The time to compute unfair group is 0.5540807247161865\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 2, 1, 38], [0, 0, 4, 1, 25], [1, 3, 4, 1, 38], [2, 4, 4, 1, 38]]\n",
            "[[0, 0, 4, 1, 38], [0, 5, 4, 0, 38], [1, 0, 0, 1, 38], [1, 0, 4, 1, 25], [1, 5, 2, 0, 38], [1, 5, 4, 0, 38], [2, 5, 4, 0, 38]]\n",
            "adding more positive\n",
            "[0, 0, 2, 1, 38]\n",
            "Changed 20 records\n",
            "31656\n",
            "adding more positive\n",
            "[0, 0, 4, 1, 25]\n",
            "Changed 24 records\n",
            "31656\n",
            "adding more positive\n",
            "[1, 3, 4, 1, 38]\n",
            "Changed 85 records\n",
            "31656\n",
            "adding more positive\n",
            "[2, 4, 4, 1, 38]\n",
            "Changed 18 records\n",
            "31656\n",
            "[0, 0, 4, 1, 38]\n",
            "adding more negative\n",
            "Changed 252 records\n",
            "31656\n",
            "[0, 5, 4, 0, 38]\n",
            "adding more negative\n",
            "Changed 95 records\n",
            "31656\n",
            "[1, 0, 0, 1, 38]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "31656\n",
            "[1, 0, 4, 1, 25]\n",
            "adding more negative\n",
            "Changed 16 records\n",
            "31656\n",
            "[1, 5, 2, 0, 38]\n",
            "adding more negative\n",
            "Changed 25 records\n",
            "31656\n",
            "[1, 5, 4, 0, 38]\n",
            "adding more negative\n",
            "Changed 164 records\n",
            "31656\n",
            "[2, 5, 4, 0, 38]\n",
            "adding more negative\n",
            "Changed 44 records\n",
            "31656\n",
            "0    24597\n",
            "1     7059\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "60\n",
            "The time to compute unfair group is 0.40816235542297363\n",
            "The sets of need pos and neg are\n",
            "[[1, 2, 1, 1, 18], [1, 3, 4, 1, 38], [2, 5, 4, 1, 38], [2, 6, 4, 1, 38]]\n",
            "[[2, 2, 4, 1, 38]]\n",
            "adding more positive\n",
            "[1, 2, 1, 1, 18]\n",
            "Changed 4 records\n",
            "31656\n",
            "adding more positive\n",
            "[1, 3, 4, 1, 38]\n",
            "Changed 10 records\n",
            "31656\n",
            "adding more positive\n",
            "[2, 5, 4, 1, 38]\n",
            "Changed 8 records\n",
            "31656\n",
            "adding more positive\n",
            "[2, 6, 4, 1, 38]\n",
            "Changed 20 records\n",
            "31656\n",
            "[2, 2, 4, 1, 38]\n",
            "adding more negative\n",
            "Changed 322 records\n",
            "31656\n",
            "0    24877\n",
            "1     6779\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "59\n",
            "The time to compute unfair group is 0.46364331245422363\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 3, 1, 38], [1, 2, 0, 1, 29], [1, 3, 1, 1, 38], [2, 0, 4, 1, 38], [2, 5, 1, 1, 38], [2, 6, 1, 1, 38]]\n",
            "[1, 0, 3, 1, 38]\n",
            "adding more negative\n",
            "Changed 78 records\n",
            "31656\n",
            "[1, 2, 0, 1, 29]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "31656\n",
            "[1, 3, 1, 1, 38]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "31656\n",
            "[2, 0, 4, 1, 38]\n",
            "adding more negative\n",
            "Changed 27 records\n",
            "31656\n",
            "[2, 5, 1, 1, 38]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "31656\n",
            "[2, 6, 1, 1, 38]\n",
            "adding more negative\n",
            "Changed 27 records\n",
            "31656\n",
            "0    25030\n",
            "1     6626\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "58\n",
            "The time to compute unfair group is 0.65183424949646\n",
            "The sets of need pos and neg are\n",
            "[[1, 2, 5, 4, 38]]\n",
            "[[0, 2, 0, 4, 25]]\n",
            "adding more positive\n",
            "[1, 2, 5, 4, 38]\n",
            "Changed 156 records\n",
            "31656\n",
            "[0, 2, 0, 4, 25]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "31656\n",
            "0    24881\n",
            "1     6775\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "57\n",
            "The time to compute unfair group is 0.7502586841583252\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 5, 4, 0]]\n",
            "[[1, 2, 5, 4, 0], [2, 2, 0, 1, 1]]\n",
            "adding more positive\n",
            "[0, 2, 5, 4, 0]\n",
            "Changed 59 records\n",
            "31656\n",
            "[1, 2, 5, 4, 0]\n",
            "adding more negative\n",
            "Changed 130 records\n",
            "31656\n",
            "[2, 2, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 23 records\n",
            "31656\n",
            "0    24975\n",
            "1     6681\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "56\n",
            "The time to compute unfair group is 0.26870083808898926\n",
            "The sets of need pos and neg are\n",
            "[[2, 4, 1, 38], [3, 4, 1, 38]]\n",
            "[[0, 4, 1, 38]]\n",
            "adding more positive\n",
            "[2, 4, 1, 38]\n",
            "Changed 62 records\n",
            "31656\n",
            "adding more positive\n",
            "[3, 4, 1, 38]\n",
            "Changed 529 records\n",
            "31656\n",
            "[0, 4, 1, 38]\n",
            "adding more negative\n",
            "Changed 2566 records\n",
            "31656\n",
            "0    26950\n",
            "1     4706\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "55\n",
            "The time to compute unfair group is 0.3737962245941162\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 1, 1, 38], [2, 2, 1, 38], [2, 3, 1, 38], [2, 4, 1, 1], [2, 4, 1, 4], [2, 4, 1, 10], [2, 4, 1, 21], [2, 4, 1, 25]]\n",
            "[2, 1, 1, 38]\n",
            "adding more negative\n",
            "Changed 21 records\n",
            "31656\n",
            "[2, 2, 1, 38]\n",
            "adding more negative\n",
            "Changed 164 records\n",
            "31656\n",
            "[2, 3, 1, 38]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "31656\n",
            "[2, 4, 1, 1]\n",
            "adding more negative\n",
            "Changed 13 records\n",
            "31656\n",
            "[2, 4, 1, 4]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "31656\n",
            "[2, 4, 1, 10]\n",
            "adding more negative\n",
            "Changed 13 records\n",
            "31656\n",
            "[2, 4, 1, 21]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "31656\n",
            "[2, 4, 1, 25]\n",
            "adding more negative\n",
            "Changed 52 records\n",
            "31656\n",
            "0    27240\n",
            "1     4416\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "54\n",
            "The time to compute unfair group is 0.48392534255981445\n",
            "The sets of need pos and neg are\n",
            "[[2, 0, 1, 38]]\n",
            "[[0, 2, 1, 38], [0, 3, 1, 38], [2, 0, 1, 18], [2, 0, 1, 29], [2, 2, 1, 38], [2, 3, 1, 38]]\n",
            "adding more positive\n",
            "[2, 0, 1, 38]\n",
            "Changed 2084 records\n",
            "31656\n",
            "[0, 2, 1, 38]\n",
            "adding more negative\n",
            "Changed 24 records\n",
            "31656\n",
            "[0, 3, 1, 38]\n",
            "adding more negative\n",
            "Changed 114 records\n",
            "31656\n",
            "[2, 0, 1, 18]\n",
            "adding more negative\n",
            "Changed 11 records\n",
            "31656\n",
            "[2, 0, 1, 29]\n",
            "adding more negative\n",
            "Changed 17 records\n",
            "31656\n",
            "[2, 2, 1, 38]\n",
            "adding more negative\n",
            "Changed 24 records\n",
            "31656\n",
            "[2, 3, 1, 38]\n",
            "adding more negative\n",
            "Changed 23 records\n",
            "31656\n",
            "0    25369\n",
            "1     6287\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "53\n",
            "The time to compute unfair group is 0.3353724479675293\n",
            "The sets of need pos and neg are\n",
            "[[2, 0, 1, 18], [2, 0, 1, 29]]\n",
            "[[2, 0, 0, 38]]\n",
            "adding more positive\n",
            "[2, 0, 1, 18]\n",
            "Changed 11 records\n",
            "31656\n",
            "adding more positive\n",
            "[2, 0, 1, 29]\n",
            "Changed 15 records\n",
            "31656\n",
            "[2, 0, 0, 38]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "31656\n",
            "0    25353\n",
            "1     6303\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "52\n",
            "The time to compute unfair group is 0.35451698303222656\n",
            "The sets of need pos and neg are\n",
            "[[2, 2, 4, 1]]\n",
            "[[2, 5, 1, 0], [5, 3, 4, 1]]\n",
            "adding more positive\n",
            "[2, 2, 4, 1]\n",
            "Changed 11 records\n",
            "31656\n",
            "[2, 5, 1, 0]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "31656\n",
            "[5, 3, 4, 1]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "31656\n",
            "0    25358\n",
            "1     6298\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "51\n",
            "The time to compute unfair group is 0.29700183868408203\n",
            "The sets of need pos and neg are\n",
            "[[0, 4, 1, 38], [1, 1, 1, 29], [2, 4, 0, 38], [2, 4, 1, 25]]\n",
            "[[2, 4, 1, 38]]\n",
            "adding more positive\n",
            "[0, 4, 1, 38]\n",
            "Changed 1136 records\n",
            "31656\n",
            "adding more positive\n",
            "[1, 1, 1, 29]\n",
            "Changed 15 records\n",
            "31656\n",
            "adding more positive\n",
            "[2, 4, 0, 38]\n",
            "Changed 338 records\n",
            "31656\n",
            "adding more positive\n",
            "[2, 4, 1, 25]\n",
            "Changed 16 records\n",
            "31656\n",
            "[2, 4, 1, 38]\n",
            "adding more negative\n",
            "Changed 2708 records\n",
            "31656\n",
            "0    26561\n",
            "1     5095\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "50\n",
            "The time to compute unfair group is 0.1873304843902588\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 25], [0, 2, 1, 38], [0, 3, 1, 38], [1, 0, 1, 38]]\n",
            "[[0, 0, 1, 38], [0, 5, 0, 38], [1, 0, 1, 29], [1, 3, 1, 38], [2, 0, 1, 25], [2, 1, 0, 38]]\n",
            "adding more positive\n",
            "[0, 0, 1, 25]\n",
            "Changed 39 records\n",
            "31656\n",
            "adding more positive\n",
            "[0, 2, 1, 38]\n",
            "Changed 56 records\n",
            "31656\n",
            "adding more positive\n",
            "[0, 3, 1, 38]\n",
            "Changed 395 records\n",
            "31656\n",
            "adding more positive\n",
            "[1, 0, 1, 38]\n",
            "Changed 1544 records\n",
            "31656\n",
            "[0, 0, 1, 38]\n",
            "adding more negative\n",
            "Changed 955 records\n",
            "31656\n",
            "[0, 5, 0, 38]\n",
            "adding more negative\n",
            "Changed 75 records\n",
            "31656\n",
            "[1, 0, 1, 29]\n",
            "adding more negative\n",
            "Changed 16 records\n",
            "31656\n",
            "[1, 3, 1, 38]\n",
            "adding more negative\n",
            "Changed 243 records\n",
            "31656\n",
            "[2, 0, 1, 25]\n",
            "adding more negative\n",
            "Changed 24 records\n",
            "31656\n",
            "[2, 1, 0, 38]\n",
            "adding more negative\n",
            "Changed 341 records\n",
            "31656\n",
            "0    26181\n",
            "1     5475\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "49\n",
            "The time to compute unfair group is 0.3520536422729492\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 1, 29], [1, 0, 1, 38], [1, 0, 2, 38]]\n",
            "[[0, 0, 4, 25], [1, 0, 4, 38], [2, 0, 2, 38]]\n",
            "adding more positive\n",
            "[1, 0, 1, 29]\n",
            "Changed 13 records\n",
            "31656\n",
            "adding more positive\n",
            "[1, 0, 1, 38]\n",
            "Changed 15 records\n",
            "31656\n",
            "adding more positive\n",
            "[1, 0, 2, 38]\n",
            "Changed 81 records\n",
            "31656\n",
            "[0, 0, 4, 25]\n",
            "adding more negative\n",
            "Changed 32 records\n",
            "31656\n",
            "[1, 0, 4, 38]\n",
            "adding more negative\n",
            "Changed 1288 records\n",
            "31656\n",
            "[2, 0, 2, 38]\n",
            "adding more negative\n",
            "Changed 132 records\n",
            "31656\n",
            "0    27524\n",
            "1     4132\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "48\n",
            "The time to compute unfair group is 0.43474650382995605\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 3, 4, 1], [1, 0, 1, 1], [2, 0, 1, 1], [2, 2, 4, 0]]\n",
            "[0, 3, 4, 1]\n",
            "adding more negative\n",
            "Changed 375 records\n",
            "31656\n",
            "[1, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 50 records\n",
            "31656\n",
            "[2, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 49 records\n",
            "31656\n",
            "[2, 2, 4, 0]\n",
            "adding more negative\n",
            "Changed 16 records\n",
            "31656\n",
            "0    28014\n",
            "1     3642\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "47\n",
            "The time to compute unfair group is 0.3018937110900879\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28014\n",
            "1     3642\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "46\n",
            "The time to compute unfair group is 0.37236762046813965\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 2, 1, 38]]\n",
            "[1, 2, 1, 38]\n",
            "adding more negative\n",
            "Changed 11 records\n",
            "31656\n",
            "0    28025\n",
            "1     3631\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "45\n",
            "The time to compute unfair group is 0.5685608386993408\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28025\n",
            "1     3631\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "44\n",
            "The time to compute unfair group is 0.6803081035614014\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 3, 38], [0, 2, 2, 38], [0, 2, 3, 38]]\n",
            "[0, 0, 3, 38]\n",
            "adding more negative\n",
            "Changed 32 records\n",
            "31656\n",
            "[0, 2, 2, 38]\n",
            "adding more negative\n",
            "Changed 21 records\n",
            "31656\n",
            "[0, 2, 3, 38]\n",
            "adding more negative\n",
            "Changed 26 records\n",
            "31656\n",
            "0    28104\n",
            "1     3552\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "43\n",
            "The time to compute unfair group is 0.6751770973205566\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 2, 2, 1]]\n",
            "[1, 2, 2, 1]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "31656\n",
            "0    28113\n",
            "1     3543\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "42\n",
            "The time to compute unfair group is 0.5049469470977783\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28113\n",
            "1     3543\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "41\n",
            "The time to compute unfair group is 0.20006346702575684\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[4, 1, 8]]\n",
            "[4, 1, 8]\n",
            "adding more negative\n",
            "Changed 16 records\n",
            "31656\n",
            "0    28129\n",
            "1     3527\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "40\n",
            "The time to compute unfair group is 0.0963284969329834\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28129\n",
            "1     3527\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "39\n",
            "The time to compute unfair group is 0.2520439624786377\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 38], [0, 1, 38]]\n",
            "[0, 0, 38]\n",
            "adding more negative\n",
            "Changed 16 records\n",
            "31656\n",
            "[0, 1, 38]\n",
            "adding more negative\n",
            "Changed 14 records\n",
            "31656\n",
            "0    28159\n",
            "1     3497\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "38\n",
            "The time to compute unfair group is 0.13490676879882812\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28159\n",
            "1     3497\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "37\n",
            "The time to compute unfair group is 0.09105324745178223\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28159\n",
            "1     3497\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "36\n",
            "The time to compute unfair group is 0.14282608032226562\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28159\n",
            "1     3497\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "35\n",
            "The time to compute unfair group is 0.23917460441589355\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28159\n",
            "1     3497\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "34\n",
            "The time to compute unfair group is 0.11980175971984863\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[3, 3, 38]]\n",
            "[3, 3, 38]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "31656\n",
            "0    28167\n",
            "1     3489\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "33\n",
            "The time to compute unfair group is 0.17208218574523926\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28167\n",
            "1     3489\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "32\n",
            "The time to compute unfair group is 0.16727232933044434\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28167\n",
            "1     3489\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "31\n",
            "The time to compute unfair group is 0.06477689743041992\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28167\n",
            "1     3489\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "30\n",
            "The time to compute unfair group is 0.2001938819885254\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 0, 38], [2, 1, 38], [2, 4, 1]]\n",
            "[2, 0, 38]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "31656\n",
            "[2, 1, 38]\n",
            "adding more negative\n",
            "Changed 13 records\n",
            "31656\n",
            "[2, 4, 1]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "31656\n",
            "0    28199\n",
            "1     3457\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "29\n",
            "The time to compute unfair group is 0.11355376243591309\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28199\n",
            "1     3457\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "28\n",
            "The time to compute unfair group is 0.09039950370788574\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28199\n",
            "1     3457\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "27\n",
            "The time to compute unfair group is 0.14273381233215332\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28199\n",
            "1     3457\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "26\n",
            "The time to compute unfair group is 0.1849818229675293\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28199\n",
            "1     3457\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "25\n",
            "The time to compute unfair group is 0.23552966117858887\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28199\n",
            "1     3457\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "24\n",
            "The time to compute unfair group is 0.16204500198364258\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28199\n",
            "1     3457\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "23\n",
            "The time to compute unfair group is 0.3015615940093994\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28199\n",
            "1     3457\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "22\n",
            "The time to compute unfair group is 0.1947770118713379\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28199\n",
            "1     3457\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "21\n",
            "The time to compute unfair group is 0.19608449935913086\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28199\n",
            "1     3457\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "20\n",
            "The time to compute unfair group is 0.1170814037322998\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 35], [4, 11]]\n",
            "[1, 35]\n",
            "adding more negative\n",
            "Changed 11 records\n",
            "31656\n",
            "[4, 11]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "31656\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "19\n",
            "The time to compute unfair group is 0.0555722713470459\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "18\n",
            "The time to compute unfair group is 0.14464902877807617\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "17\n",
            "The time to compute unfair group is 0.05453610420227051\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "16\n",
            "The time to compute unfair group is 0.12049651145935059\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "15\n",
            "The time to compute unfair group is 0.0886998176574707\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "14\n",
            "The time to compute unfair group is 0.07140564918518066\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "13\n",
            "The time to compute unfair group is 0.07516169548034668\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "12\n",
            "The time to compute unfair group is 0.11233901977539062\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "11\n",
            "The time to compute unfair group is 0.17136931419372559\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "10\n",
            "The time to compute unfair group is 0.021049022674560547\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "9\n",
            "The time to compute unfair group is 0.09610486030578613\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "8\n",
            "The time to compute unfair group is 0.09663987159729004\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "7\n",
            "The time to compute unfair group is 0.0569767951965332\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "6\n",
            "The time to compute unfair group is 0.04702448844909668\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "5\n",
            "The time to compute unfair group is 0.0043070316314697266\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "4\n",
            "The time to compute unfair group is 0.03443264961242676\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "3\n",
            "The time to compute unfair group is 0.012094259262084961\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "2\n",
            "The time to compute unfair group is 0.014467954635620117\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "1\n",
            "The time to compute unfair group is 0.005597352981567383\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    28220\n",
            "1     3436\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  new_train_data = naive_massaging(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6hqSHlurjGO"
      },
      "source": [
        "### Results Lattice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvXIDnsDsiz4"
      },
      "outputs": [],
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Massage-Lattice\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label,test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Massage-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Massage-Lattice\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"Adult\",\"Massage-Lattice\",\"SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4r6mFOV43PzI"
      },
      "outputs": [],
      "source": [
        "r3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWTUWZzVDWZo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfBfO1hhytVS"
      },
      "source": [
        "## Run Algorithm Leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6oMxp2hzVXD",
        "outputId": "93054b2d-fc1f-4a22-d5b6-f30e4a557ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "63\n",
            "The time to compute unfair group is 1.2597715854644775\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 0, 4, 1, 38], [0, 2, 5, 4, 0, 38], [1, 2, 0, 0, 1, 38], [1, 2, 0, 4, 1, 25], [1, 2, 5, 2, 0, 38], [2, 2, 0, 4, 1, 25]]\n",
            "[[1, 2, 0, 1, 1, 29], [1, 2, 0, 1, 1, 38], [1, 2, 0, 4, 1, 38], [1, 2, 5, 4, 0, 38]]\n",
            "adding more positive\n",
            "[0, 2, 0, 4, 1, 38]\n",
            "Changed 360 records\n",
            "31656\n",
            "adding more positive\n",
            "[0, 2, 5, 4, 0, 38]\n",
            "Changed 43 records\n",
            "31656\n",
            "adding more positive\n",
            "[1, 2, 0, 0, 1, 38]\n",
            "Changed 16 records\n",
            "31656\n",
            "adding more positive\n",
            "[1, 2, 0, 4, 1, 25]\n",
            "Changed 61 records\n",
            "31656\n",
            "adding more positive\n",
            "[1, 2, 5, 2, 0, 38]\n",
            "Changed 13 records\n",
            "31656\n",
            "adding more positive\n",
            "[2, 2, 0, 4, 1, 25]\n",
            "Changed 10 records\n",
            "31656\n",
            "[1, 2, 0, 1, 1, 29]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "31656\n",
            "[1, 2, 0, 1, 1, 38]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "31656\n",
            "[1, 2, 0, 4, 1, 38]\n",
            "adding more negative\n",
            "Changed 723 records\n",
            "31656\n",
            "[1, 2, 5, 4, 0, 38]\n",
            "adding more negative\n",
            "Changed 131 records\n",
            "31656\n",
            "0    24138\n",
            "1     7518\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in [all_names_lst[0]]:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  new_train_data = naive_massaging(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM-vpguwyt2H"
      },
      "source": [
        "### Results Leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0N6uIH9slwL"
      },
      "outputs": [],
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Massage-Leaf\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Massage-Leaf\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Massage-Leaf\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"Adult\",\"Massage-Leaf\",\"SVM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6oj1yzvyuNv"
      },
      "source": [
        "## Run Algorithm Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXWlcnvmzaef",
        "outputId": "842d8f30-dec1-4e28-f9b9-534a7507c523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "1\n",
            "The time to compute unfair group is 0.013807058334350586\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "2\n",
            "The time to compute unfair group is 0.01045083999633789\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "3\n",
            "The time to compute unfair group is 0.028435468673706055\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "4\n",
            "The time to compute unfair group is 0.0140228271484375\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "5\n",
            "The time to compute unfair group is 0.010902166366577148\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n",
            "?????/////\n",
            "6\n",
            "The time to compute unfair group is 0.07302522659301758\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    23774\n",
            "1     7882\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "all_names_lst_top = find_top(all_names)\n",
        "for a in all_names_lst_top:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  new_train_data = naive_massaging(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YylnNCsvyuuU"
      },
      "source": [
        "### Results Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWUjzEK5smxi"
      },
      "outputs": [],
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Massage-Top\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Massage-Top\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"Adult\",\"Massage-Top\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"Adult\",\"Massage-Top\",\"SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJzCNT06Jj3Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Kf1ffb1bggPp",
        "TttueBgvg53C"
      ],
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}