{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oMgFj8Ve2Oq"
      },
      "source": [
        "# DecisionTreeClassifer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "772S9aKIfv-9"
      },
      "source": [
        "#Imports and Dataset processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Evnn9BbOfEme"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "import copy\n",
        "from sympy import Symbol\n",
        "from sympy.solvers import solve\n",
        "pd.options.mode.chained_assignment = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_vP0FN3vfgjA",
        "outputId": "d6563e9d-e230-4b16-cc9b-9b6aaca4e5f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
              "0        0          2  226802          1                7               4   \n",
              "1        1          2   89814         11                9               2   \n",
              "2        0          1  336951          7               12               2   \n",
              "3        1          2  160323         15               10               2   \n",
              "4        1          2  198693          0                6               4   \n",
              "...    ...        ...     ...        ...              ...             ...   \n",
              "45217    0          2  257302          7               12               2   \n",
              "45218    1          2  154374         11                9               2   \n",
              "45219    2          2  151910         11                9               6   \n",
              "45220    0          2  201490         11                9               4   \n",
              "45221    2          3  287927         11                9               2   \n",
              "\n",
              "       occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
              "0               6             3     2       1             0             0   \n",
              "1               4             0     4       1             0             0   \n",
              "2              10             0     4       1             0             0   \n",
              "3               6             0     2       1             1             0   \n",
              "4               7             1     4       1             0             0   \n",
              "...           ...           ...   ...     ...           ...           ...   \n",
              "45217          12             5     4       0             0             0   \n",
              "45218           6             0     4       1             0             0   \n",
              "45219           0             4     4       0             0             0   \n",
              "45220           0             3     4       1             0             0   \n",
              "45221           3             5     4       0             1             0   \n",
              "\n",
              "       hours-per-week  native-country  income  \n",
              "0                   0              38       0  \n",
              "1                   1              38       0  \n",
              "2                   0              38       1  \n",
              "3                   0              38       1  \n",
              "4                   0              38       0  \n",
              "...               ...             ...     ...  \n",
              "45217               0              38       0  \n",
              "45218               0              38       1  \n",
              "45219               0              38       0  \n",
              "45220               0              38       0  \n",
              "45221               0              38       1  \n",
              "\n",
              "[45222 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e5f88ea-5a93-48c6-bcbc-b13163cb1584\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>educational-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>226802</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>89814</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>336951</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>160323</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>198693</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45217</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>257302</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45218</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>154374</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45219</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>151910</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45220</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>201490</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45221</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>287927</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45222 rows × 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e5f88ea-5a93-48c6-bcbc-b13163cb1584')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e5f88ea-5a93-48c6-bcbc-b13163cb1584 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e5f88ea-5a93-48c6-bcbc-b13163cb1584');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f6888e6b-f3e2-4453-97b5-1d5203cbac6f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6888e6b-f3e2-4453-97b5-1d5203cbac6f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f6888e6b-f3e2-4453-97b5-1d5203cbac6f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "url = \"https://raw.githubusercontent.com/niceIrene/remedy/main/datasets/CleanAdult_numerical_cat.csv\"\n",
        "data = pd.read_csv(url)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3K records\n",
        "data = data.sample(3000)\n",
        "\n",
        "# # 6K records\n",
        "# data = data.sample(6000)\n",
        "\n",
        "# # 12K records\n",
        "# data = data.sample(12000)\n",
        "\n",
        "# # 24K records\n",
        "# data = data.sample(24000)\n",
        "# # 48K records\n",
        "# data2 = data.sample(3000)\n",
        "# data = pd.concat([data, data2], ignore_index=True)\n",
        "# data"
      ],
      "metadata": {
        "id": "F4tkFxtAAmY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNSifBfwflg8"
      },
      "outputs": [],
      "source": [
        "# get training and testing set\n",
        "\n",
        "\n",
        "columns_all = ['age', 'workclass', 'education', 'educational-num', 'marital-status',\n",
        "                                            'occupation', 'relationship', 'race','gender', 'capital-gain', 'capital-loss',\n",
        "                                            'hours-per-week', 'native-country']\n",
        "columns_compas = ['age', 'education',  'marital-status', 'occupation',\n",
        "                  'relationship', 'race','gender', 'native-country']\n",
        "compas_y = 'income'\n",
        "def split_train_test(data,test_ratio):\n",
        "    np.random.seed(42)\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices],data.iloc[test_indices]\n",
        "\n",
        "def get_train_test(data, split, list_cols, y_label):\n",
        "  all_list = copy.deepcopy(list_cols)\n",
        "  all_list.append(y_label)\n",
        "  data = pd.DataFrame(data, columns = all_list)\n",
        "  train_set,test_set = split_train_test(data,split)\n",
        "  print(len(train_set), \"train +\", len(test_set), \"test\")\n",
        "  train_x = pd.DataFrame(train_set, columns = list_cols)\n",
        "  train_label = train_set[y_label]\n",
        "  test_x = pd.DataFrame(test_set, columns = list_cols)\n",
        "  test_label = test_set[y_label]\n",
        "  return train_x, test_x, train_label, test_label, train_set, test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJQsq95bfpEH",
        "outputId": "8a0ce8df-5d25-4543-c62a-1ef528cec25b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2100 train + 900 test\n"
          ]
        }
      ],
      "source": [
        "train_x, test_x, train_label, test_label, train_set, test_set  = get_train_test(data, 0.3, columns_all, compas_y)\n",
        "\n",
        "###################\n",
        "\n",
        "### about decision tree\n",
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param = {'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 100], 'random_state':[17]}\n",
        "\n",
        "grid = DecisionTreeClassifier(criterion=\"entropy\",max_depth=6, random_state=17)\n",
        "grid.fit(train_x, train_label)\n",
        "\n",
        "data_all = pd.concat([train_x,test_x])\n",
        "data_predict = grid.predict(data_all)\n",
        "test_predict = grid.predict(test_x)\n",
        "data['predicted'] = data_predict\n",
        "test_set['predicted'] = test_predict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-rnfp9XfuKM"
      },
      "outputs": [],
      "source": [
        "def fpr_onegroup(true, predict):\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    for i in range(len(true)):\n",
        "        if (true[i] == 0 and predict[i] == 1):\n",
        "            fp += 1\n",
        "        if(true[i] == 0 and predict[i] == 0):\n",
        "            tn += 1\n",
        "    return fp/(fp+tn)\n",
        "\n",
        "def fnr_onegroup(true, predict):\n",
        "    fn = 0\n",
        "    tp = 0\n",
        "    for i in range(len(true)):\n",
        "        if (true[i] == 1 and predict[i] == 0):\n",
        "            fn += 1\n",
        "        if(true[i] == 1 and predict[i] == 1):\n",
        "            tp += 1\n",
        "    return fn/(fn+tp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmhcs6wcgGiZ"
      },
      "source": [
        "# Divexplorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVt4YIpUgKlo",
        "outputId": "917ca5b8-0a9e-42cd-e6b9-94b94370a492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting divexplorer\n",
            "  Downloading DivExplorer-0.2.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from divexplorer) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.10/dist-packages (from divexplorer) (1.23.5)\n",
            "Requirement already satisfied: mlxtend>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from divexplorer) (0.22.0)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from divexplorer) (1.5.3)\n",
            "Requirement already satisfied: plotly>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from divexplorer) (5.15.0)\n",
            "Collecting python-igraph>=0.8.3 (from divexplorer)\n",
            "  Downloading python_igraph-0.11.3-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from mlxtend>=0.17.1->divexplorer) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend>=0.17.1->divexplorer) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend>=0.17.1->divexplorer) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from mlxtend>=0.17.1->divexplorer) (67.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->divexplorer) (2023.3.post1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.5.0->divexplorer) (8.2.3)\n",
            "Collecting igraph==0.11.3 (from python-igraph>=0.8.3->divexplorer)\n",
            "  Downloading igraph-0.11.3-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable>=1.6.2 (from igraph==0.11.3->python-igraph>=0.8.3->divexplorer)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.1->divexplorer) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->mlxtend>=0.17.1->divexplorer) (3.2.0)\n",
            "Installing collected packages: texttable, igraph, python-igraph, divexplorer\n",
            "Successfully installed divexplorer-0.2.1 igraph-0.11.3 python-igraph-0.11.3 texttable-1.7.0\n"
          ]
        }
      ],
      "source": [
        "pip install divexplorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT6Kmu35gRYe"
      },
      "outputs": [],
      "source": [
        "# # run divexplorer to find unfair groups\n",
        "# class_map={'N': 0, 'P': 1}\n",
        "# from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "\n",
        "# min_sup=0.1\n",
        "\n",
        "\n",
        "# fp_diver=FP_DivergenceExplorer(test_set,compas_y, \"predicted\", class_map=class_map)\n",
        "# FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "# from divexplorer.FP_Divergence import FP_Divergence\n",
        "# fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "\n",
        "# INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "\n",
        "# K=10\n",
        "# pd.options.display.max_rows = 200\n",
        "# d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "# # summerization\n",
        "# eps=0.01\n",
        "\n",
        "# d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ].head(K)\n",
        "\n",
        "# d, list(d[\"itemsets\"].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb3zgDbUgXcV"
      },
      "outputs": [],
      "source": [
        "# def fairness_score_computation(d, metrics):\n",
        "#     sum_of_score = 0\n",
        "#     for idx, row in d.iterrows():\n",
        "#       sum_of_score += row['support'] * row[metrics]\n",
        "#     return sum_of_score\n",
        "\n",
        "# print(fairness_score_computation(d, 'd_fpr'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf1ffb1bggPp"
      },
      "source": [
        "# For entire dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aU9MirNCglkA"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "def get_unfair_group(list_parse, entire = 1):\n",
        "  unfair_group = []\n",
        "  unfair_dict = {}\n",
        "  names = []\n",
        "  for col in columns_compas:\n",
        "    found = False\n",
        "    for item in list_parse:\n",
        "      attr_given = item.split(\"=\")[0]\n",
        "      if col == attr_given:\n",
        "        unfair_group.append(int(item.split(\"=\")[1]))\n",
        "        names.append(attr_given)\n",
        "        unfair_dict[attr_given] = int(item.split(\"=\")[1])\n",
        "        found = True\n",
        "  # if use the entire dataset\n",
        "  if entire:\n",
        "    return unfair_group, names, columns_compas, unfair_dict\n",
        "  return unfair_group, names, list(set(columns_compas).symmetric_difference(set(names))), unfair_dict\n",
        "def candidate_groups(skew_candidates, unfair_dict, ordering, names):\n",
        "  candidate_combos = []\n",
        "  candidate_ind = {}\n",
        "  num = 0\n",
        "  for i in range(len(skew_candidates)+1):\n",
        "    temp_candidate = list(itertools.combinations(skew_candidates, i))\n",
        "    for tc in temp_candidate:\n",
        "      candidate_ind[num] = list(tc)\n",
        "      num += 1\n",
        "  return candidate_ind\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ZgdhgqYZjTci",
        "outputId": "2982a7e0-7b93-4f16-9afd-29b5674a251f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age  education  marital-status  occupation  relationship  race  gender  \\\n",
              "0       0          0               0           6             2     4       0   \n",
              "1       0          0               2           5             0     4       1   \n",
              "2       0          0               3           7             2     4       1   \n",
              "3       0          0               4           0             3     4       0   \n",
              "4       0          0               4           2             3     4       1   \n",
              "...   ...        ...             ...         ...           ...   ...     ...   \n",
              "1265    2         15               6           0             4     4       0   \n",
              "1266    2         15               6           3             2     4       1   \n",
              "1267    2         15               6          11             1     4       1   \n",
              "1268    2         15               6          11             4     4       0   \n",
              "1269    2         15               6          13             1     4       0   \n",
              "\n",
              "      native-country  income  cnt  \n",
              "0                 38       0    1  \n",
              "1                 38       0    2  \n",
              "2                 38       0    1  \n",
              "3                 38       0    1  \n",
              "4                 38       0    2  \n",
              "...              ...     ...  ...  \n",
              "1265              38       0    1  \n",
              "1266              38       0    1  \n",
              "1267              38       1    1  \n",
              "1268              38       0    1  \n",
              "1269              38       0    1  \n",
              "\n",
              "[1270 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06c2b698-cbaf-4871-ab23-2ea1b1af6033\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>education</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1265</th>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1266</th>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1267</th>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1268</th>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1269</th>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1270 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06c2b698-cbaf-4871-ab23-2ea1b1af6033')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06c2b698-cbaf-4871-ab23-2ea1b1af6033 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06c2b698-cbaf-4871-ab23-2ea1b1af6033');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6028098a-09f6-4ad5-912d-eba883611d96\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6028098a-09f6-4ad5-912d-eba883611d96')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6028098a-09f6-4ad5-912d-eba883611d96 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "def get_temp(train_set, names, y_label):\n",
        "  names2 = copy.deepcopy(names)\n",
        "  names2.append(y_label)\n",
        "  temp = train_set[names2]\n",
        "  temp['cnt'] = 0\n",
        "  temp2 = temp.groupby(names2)['cnt'].count().reset_index()\n",
        "  temp2['cnt'].sum()\n",
        "  return temp2, names\n",
        "temp2, names = get_temp(train_set, columns_compas, compas_y)\n",
        "temp2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuEIYpHwjg_H"
      },
      "outputs": [],
      "source": [
        "def get_temp_g(train_set, names, y_label):\n",
        "  names2 = copy.deepcopy(names)\n",
        "  names2.append(y_label)\n",
        "  temp = train_set[names2]\n",
        "  temp['cnt'] = 0\n",
        "  temp_g = temp.groupby(names)['cnt'].count().reset_index()\n",
        "  return temp, temp_g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMrAfuoDtjAQ"
      },
      "outputs": [],
      "source": [
        "unfair_group, unfair_names, skew_candidates, unfair_dict = get_unfair_group([])\n",
        "all_names = candidate_groups(skew_candidates, unfair_dict, columns_compas, unfair_names)\n",
        "all_names_lst = list(all_names.keys())[len(columns_compas)+1:]\n",
        "all_names_lst.reverse()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TttueBgvg53C"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4TwHPK4hd0A"
      },
      "source": [
        "## General Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvC9RSgZkD80"
      },
      "outputs": [],
      "source": [
        "def get_one_degree_neighbors(temp2, names, group_lst):\n",
        "    result = []\n",
        "    for i in range(len(group_lst)):\n",
        "        d = copy.copy(temp2)\n",
        "        for k in range(len(group_lst)):\n",
        "            if k != i:\n",
        "                d = d[d[names[k]] == group_lst[k]]\n",
        "            else:\n",
        "                d = d[d[names[k]] != group_lst[k]]\n",
        "        # print(d)\n",
        "        result.append(d)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGQalez0kLkE"
      },
      "outputs": [],
      "source": [
        "# compute the pos/neg ration of this neighbor\n",
        "def compute_neighbors(group_lst, result):\n",
        "    # compute the ratio of positive and negative records\n",
        "    start2 = time.time()\n",
        "    pos = 0\n",
        "    neg = 0\n",
        "    for r in result:\n",
        "        total  = r['cnt'].sum()\n",
        "        r = r[r[compas_y] == 1]\n",
        "        pos += r['cnt'].sum()\n",
        "        neg += total - r['cnt'].sum()\n",
        "    if(neg == 0):\n",
        "        return (pos, neg, -1)\n",
        "    end2 = time.time()\n",
        "    return(pos, neg, pos/neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijabVWcBjtCh"
      },
      "outputs": [],
      "source": [
        "def compute_diff_add_and_remove(group_lst, temp2, need_positive_or_negative, label, names):\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "        # print(len(d))\n",
        "    total =  d['cnt'].sum()\n",
        "    # Total here was 0: here, errors when this is commented out\n",
        "    if total == 0:\n",
        "      return -1\n",
        "    d = d[d[label] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    # print(d, group_lst)\n",
        "    neg = total - pos\n",
        "    result = get_one_degree_neighbors(temp2,names, group_lst)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(need_positive_or_negative == 1):\n",
        "        # need pos\n",
        "        x = Symbol('x')\n",
        "\n",
        "        try:\n",
        "          diff = solve((pos + x)/ (neg - x) - neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "\n",
        "    else:\n",
        "        #need negative\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve((pos - x)/ (neg + x) - neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "\n",
        "    return diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH7YGCuh69D7"
      },
      "outputs": [],
      "source": [
        "def compute_diff_add(group_lst, temp2, names, label_y, need_positive_or_negative):\n",
        "\n",
        "    d = copy.copy(temp2)\n",
        "\n",
        "    for i in range(len(group_lst)):\n",
        "\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label_y] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    result = get_one_degree_neighbors(temp2, names, group_lst)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(need_positive_or_negative == 1):\n",
        "        # need pos\n",
        "\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve((pos + x)/ neg -  neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "    else:\n",
        "        #need negative\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve(pos/ (neg + x) -  neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "    return diff\n",
        "\n",
        "def compute_diff_remove(group_lst, temp2, names, label_y, need_positive_or_negative):\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        # print(d, group_lst[i])\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label_y] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    result = get_one_degree_neighbors(temp2, names, group_lst)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(need_positive_or_negative == 1):\n",
        "        # need pos, remove some neg\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve( pos/ (neg - x) -  neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "        # enough = neighbors[2] * neg\n",
        "        # diff = round_int(enough - pos)\n",
        "        # print(neighbors[2], pos, neg, diff)\n",
        "    else:\n",
        "        #need negative\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve((pos -x )/ neg -  neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "        # print(neighbors[2], pos, neg, diff)\n",
        "    return diff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3J0EcLGqrH0-"
      },
      "outputs": [],
      "source": [
        "# def div_results():\n",
        "#   class_map={'N': 0, 'P': 1}\n",
        "#   from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "\n",
        "#   min_sup=0.1\n",
        "\n",
        "#   # min_sup = 0.05\n",
        "\n",
        "#   fp_diver=FP_DivergenceExplorer(test_set,compas_y, \"predicted\", class_map=class_map)\n",
        "#   FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "#   from divexplorer.FP_Divergence import FP_Divergence\n",
        "#   fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "#   fp_divergence_fnr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "#   fp_divergence_acc=FP_Divergence(FP_fm, \"d_accuracy\")\n",
        "#   # fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "#   INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "#   INFO_VIZ2=[\"support\", \"itemsets\",  fp_divergence_fnr.metric, fp_divergence_fnr.t_value_col]\n",
        "#   INFO_VIZ3=[\"support\", \"itemsets\",  fp_divergence_acc.metric, fp_divergence_acc.t_value_col]\n",
        "\n",
        "#   K=10\n",
        "#   pd.options.display.max_rows = 200\n",
        "#   d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "#   # summerization\n",
        "#   eps=0.01\n",
        "\n",
        "#   d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ].head(K)\n",
        "  # d2 = fp_divergence_fnr.getDivergence(th_redundancy=eps)[INFO_VIZ2].head(K)\n",
        "  # d3 = fp_divergence_acc.getDivergence(th_redundancy=eps)[INFO_VIZ3].head(K)\n",
        "\n",
        "  # print(fairness_score_computation(d, 'd_fpr'))\n",
        "  # print(fairness_score_computation(d2, 'd_fnr'))\n",
        "  # print(fairness_score_computation(d3, 'd_accuracy'))\n",
        "  # accuracy = accuracy_score(test_label, test_predict)\n",
        "  # print(\"accuracy is \" , accuracy)\n",
        "  # return d,d2,d3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iEQ83nxkQr4"
      },
      "source": [
        "## Optimized Helper Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuxfZHSlhXNR"
      },
      "outputs": [],
      "source": [
        "# helper function for optimized\n",
        "def compute_neighbors_opt(group_lst,lst_of_counts, pos, neg):\n",
        "\n",
        "    times = len(group_lst)\n",
        "    pos_cnt = 0\n",
        "    neg_cnt = 0\n",
        "    for i in range(times):\n",
        "        df_groupby = lst_of_counts[i]\n",
        "        temp_group_lst_pos = copy.copy(group_lst)\n",
        "        temp_group_lst_neg = copy.copy(group_lst)\n",
        "        del temp_group_lst_pos[i]\n",
        "        del temp_group_lst_neg[i]\n",
        "        # count positive\n",
        "        temp_group_lst_pos.append(1)\n",
        "        group_tuple_pos = tuple(temp_group_lst_pos)\n",
        "        if group_tuple_pos in df_groupby.keys():\n",
        "            pos_cnt += df_groupby[group_tuple_pos]\n",
        "        else:\n",
        "            pos_cnt += 0\n",
        "        # count negative\n",
        "        temp_group_lst_neg.append(0)\n",
        "        group_tuple_neg = tuple(temp_group_lst_neg)\n",
        "        if group_tuple_neg in df_groupby.keys():\n",
        "            neg_cnt += df_groupby[group_tuple_neg]\n",
        "        else:\n",
        "            neg_cnt += 0\n",
        "    pos_val = pos_cnt - times* pos\n",
        "    neg_val = neg_cnt - times* neg\n",
        "\n",
        "    if neg_val == -1 or (neg_val == 0 and pos_val == 0):\n",
        "        return (pos_val, neg_val, -1)\n",
        "    if pos_val == 0 or neg_val == 0:\n",
        "        return (pos_val, neg_val, 0)\n",
        "\n",
        "    return (pos_val, neg_val, pos_val/neg_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8Iny4kJhm4V"
      },
      "outputs": [],
      "source": [
        "# get the list of neighbors\n",
        "def get_one_degree_neighbors_opt(group_lst):\n",
        "    start1 = time.time()\n",
        "    result = []\n",
        "    for i in range(len(group_lst)):\n",
        "        d = copy.copy(group_lst)\n",
        "        d[i] = 'x'\n",
        "        result.append(d)\n",
        "    end1 = time.time()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MmwA0X5hofE"
      },
      "outputs": [],
      "source": [
        "def determine_problematic_opt(group_lst, names, temp2, lst_of_counts, label, threshold= 0.3):\n",
        "    #0: ok group, 1: need negative records, 2: need positive records\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    neighbors = compute_neighbors_opt(group_lst,lst_of_counts, pos, neg)\n",
        "    if(neighbors[2] == -1):\n",
        "        # there is no neighbors\n",
        "        return 0\n",
        "    if(total > 30):\n",
        "        # need to be large enough, need to adjust with different datasets.\n",
        "        if neg == 0:\n",
        "            if (pos > neighbors[2]):\n",
        "                return 1\n",
        "            if(pos <= neighbors[2]):\n",
        "                return 0\n",
        "        if (pos/(neg) - neighbors[2] > threshold):\n",
        "            # too many positive records\n",
        "            return 1\n",
        "        if (neighbors[2] - pos/(neg) > threshold):\n",
        "            return 2\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A76VlG-bhqqS"
      },
      "outputs": [],
      "source": [
        "def compute_problematic_opt(temp2, temp_g, names, label, lst_of_counts):\n",
        "    need_pos = []\n",
        "    need_neg = []\n",
        "    for index, row in temp_g.iterrows():\n",
        "        group_lst = []\n",
        "        for n in names:\n",
        "            group_lst.append(row[n])\n",
        "        problematic = determine_problematic_opt(group_lst, names, temp2, lst_of_counts,label)\n",
        "\n",
        "        if(problematic == 1):\n",
        "            if group_lst not in need_neg:\n",
        "                need_neg.append(group_lst)\n",
        "        if(problematic == 2):\n",
        "            if group_lst not in need_pos:\n",
        "                need_pos.append(group_lst)\n",
        "    return need_pos, need_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZd2c6PAhtTH"
      },
      "outputs": [],
      "source": [
        "# build the list of X00\n",
        "def compute_lst_of_counts(temp, names, label):\n",
        "    # get the list of group-by attributes\n",
        "    lst_of_counts = []\n",
        "    for i in range(len(names)):\n",
        "        grp_names = copy.copy(names)\n",
        "        del grp_names[i]\n",
        "        grp_names.append(label)\n",
        "        temp_df = temp.groupby(grp_names)['cnt'].count()\n",
        "        lst_of_counts.append(temp_df)\n",
        "    return lst_of_counts\n",
        "\n",
        "def get_tuple(group_lst):\n",
        "    return tuple(group_lst)\n",
        "\n",
        "\n",
        "def get_temp_g(train_set, names, y_label):\n",
        "  names2 = copy.deepcopy(names)\n",
        "  names2.append(y_label)\n",
        "  temp = train_set[names2]\n",
        "  temp['cnt'] = 0\n",
        "  temp_g = temp.groupby(names)['cnt'].count().reset_index()\n",
        "  return temp, temp_g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnQ09ffAkalO"
      },
      "source": [
        "# Preferential Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMrjlEciiv--"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "def pref_sampling_opt(train_set, cols_given, label, need_pos, need_neg):\n",
        "    if len(need_pos)+ len(need_neg) > 0:\n",
        "        temp_train_x = pd.DataFrame(train_set, columns = columns_all)\n",
        "        temp_train_label = pd.DataFrame(train_set, columns = [label])\n",
        "        temp_train_label = temp_train_label[label]\n",
        "        temp_train_label = temp_train_label.astype('int')\n",
        "        mnb = MultinomialNB()\n",
        "        mnb = mnb.fit(temp_train_x, temp_train_label)\n",
        "        probs = mnb.predict_proba(temp_train_x)[:,0]\n",
        "        train_set[\"prob\"] = abs(probs - 0.5)\n",
        "\n",
        "    new_train_set = pd.DataFrame(columns = list(train_set.columns))\n",
        "    updated_pos = 0\n",
        "    for i in need_pos:\n",
        "        # needs to updated more positive records\n",
        "\n",
        "        temp_df = copy.deepcopy(train_set)\n",
        "        for n in range(len(i)):\n",
        "          temp_df = temp_df[temp_df[cols_given[n]] == i[n]]\n",
        "        # update the skew and diff\n",
        "        idx = list(temp_df.index)\n",
        "        train_set.loc[idx, 'skewed'] = 1\n",
        "        idx_pos = list(temp_df[(getattr(temp_df, label) == 1)].index)\n",
        "        if(len(idx_pos) == 0):\n",
        "          # if there is no positive\n",
        "          idx_neg = list(temp_df[(getattr(temp_df, label) == 0)].index)\n",
        "          neg_ranked = train_set.loc[idx_neg].sort_values(by=\"prob\", ascending=True)\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          continue\n",
        "        idx_neg = list(temp_df[(getattr(temp_df, label) == 0)].index)\n",
        "        pos_ranked = train_set.loc[idx_pos].sort_values(by=\"prob\", ascending=True)\n",
        "        neg_ranked = train_set.loc[idx_neg].sort_values(by=\"prob\", ascending=True)\n",
        "        diff = compute_diff_add_and_remove(i, temp2,  1, compas_y, names)\n",
        "        if diff == -1:\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          continue\n",
        "        train_set.loc[idx, 'diff'] = int(diff)\n",
        "        cnt = int(train_set.loc[idx_pos[0]][\"diff\"])\n",
        "        updated_pos += cnt * 2\n",
        "        # add more records when there are not enough available records\n",
        "        new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "        temp_cnt = cnt\n",
        "        if len(pos_ranked) >= temp_cnt:\n",
        "            new_train_set = pd.concat([new_train_set,pos_ranked[0:cnt]], ignore_index=True)\n",
        "        else:\n",
        "            while(temp_cnt > 0 ):\n",
        "                new_train_set = pd.concat([new_train_set,pos_ranked[0:temp_cnt]], ignore_index=True)\n",
        "            # duplicate the dataframe\n",
        "                temp_cnt = temp_cnt - len(pos_ranked)\n",
        "        # duplicate the top cnt records from the pos\n",
        "        # remove the top cnt records from the neg\n",
        "        if cnt == 0:\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "\n",
        "        else:\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked[cnt-1:-1]], ignore_index=True)\n",
        "\n",
        "    updated_neg = 0\n",
        "    # adding more records to the need_neg set\n",
        "    for i in need_neg:\n",
        "        # list of idx belongs to this group\n",
        "        temp_df = copy.deepcopy(train_set)\n",
        "        for n in range(len(i)):\n",
        "          temp_df = temp_df[temp_df[cols_given[n]] == i[n]]\n",
        "        # update the skew and diff\n",
        "        idx = list(temp_df.index)\n",
        "        train_set.loc[idx, 'skewed'] = 1\n",
        "        idx_pos = list(temp_df[(getattr(temp_df, label) == 1)].index)\n",
        "        idx_neg = list(temp_df[(getattr(temp_df, label) == 0)].index)\n",
        "        if(len(idx_neg) == 0):\n",
        "          pos_ranked = train_set.loc[idx_pos].sort_values(by=\"prob\", ascending=True)\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          continue\n",
        "        pos_ranked = train_set.loc[idx_pos].sort_values(by=\"prob\", ascending=True)\n",
        "        neg_ranked = train_set.loc[idx_neg].sort_values(by=\"prob\", ascending=True)\n",
        "        diff = compute_diff_add_and_remove(i, temp2, 0, compas_y, names)\n",
        "        if diff == -1:\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          continue\n",
        "        train_set.loc[idx, 'diff'] = int(diff)\n",
        "        cnt = int(train_set.loc[idx_pos[0]][\"diff\"])\n",
        "        updated_neg += cnt * 2\n",
        "        # add more records when there are not enough available records\n",
        "        new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "        temp_cnt = cnt\n",
        "        if len(neg_ranked) >= temp_cnt:\n",
        "            new_train_set = pd.concat([new_train_set,neg_ranked[0:cnt]], ignore_index=True)\n",
        "        else:\n",
        "            while(temp_cnt > 0 ):\n",
        "                new_train_set = pd.concat([new_train_set,neg_ranked[0:temp_cnt]], ignore_index=True)\n",
        "            # duplicate the dataframe\n",
        "                temp_cnt = temp_cnt - len(neg_ranked)\n",
        "        # duplicate the top cnt records from the pos\n",
        "        # remove the top cnt records from the neg\n",
        "        if cnt ==0:\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "\n",
        "        else:\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked[cnt-1:-1]], ignore_index=True)\n",
        "\n",
        "    # add the other irrelavant items:\n",
        "    idx_irr = list(train_set[train_set['skewed'] == 0].index)\n",
        "    irr_df = train_set.loc[idx_irr]\n",
        "    new_train_set = pd.concat([new_train_set, irr_df], ignore_index=True)\n",
        "\n",
        "    new_train_set.reset_index()\n",
        "    return new_train_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paqO9W2jeTMX"
      },
      "outputs": [],
      "source": [
        "\n",
        "def find_top(all_names):\n",
        "  all_names_lst_top = []\n",
        "  for all in range(len(all_names)):\n",
        "    if len(all_names[all]) == 2:\n",
        "      all_names_lst_top.append(all)\n",
        "  return all_names_lst_top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-x05Dlbuc62"
      },
      "outputs": [],
      "source": [
        "def round_int(x):\n",
        "    if x in [float(\"-inf\"),float(\"inf\")]: return 0\n",
        "    return int(round(x))\n",
        "\n",
        "\n",
        "def make_duplicate(d, group_lst, diff, label_y, names, need_positive_or_negative):\n",
        "\n",
        "    selected = copy.deepcopy(d)\n",
        "\n",
        "    for i in range(len(group_lst)):\n",
        "        att_name = names[i]\n",
        "        selected = selected[(selected[att_name] == group_lst[i])]\n",
        "    selected = selected[(selected[label_y] == need_positive_or_negative)]\n",
        "\n",
        "    if len(selected) == 0:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # randomly generated diff samples:\n",
        "\n",
        "    while(len(selected) < diff):\n",
        "        # duplicate the dataframe\n",
        "        select_copy = selected.copy(deep=True)\n",
        "        selected = pd.concat([selected, select_copy])\n",
        "\n",
        "        # the number needed is more than the not needed numbers.\n",
        "\n",
        "    generated = selected.sample(n = diff, replace = False, axis = 0)\n",
        "\n",
        "    return generated\n",
        "\n",
        "\n",
        "def naive_duplicate(d, temp2, names, need_pos, need_neg, label_y):\n",
        "    # add more records for all groups\n",
        "    # The smote algorithm to boost the coverage\n",
        "    for r in need_pos:\n",
        "\n",
        "    # add more positive records\n",
        "        # determine how many points to add\n",
        "\n",
        "        diff = compute_diff_add(r, temp2, names, label_y, 1)\n",
        "        if diff == -1:\n",
        "          continue\n",
        "        diff = round_int(diff)\n",
        "        # add more time_data_allding \" + str(diff) +\" positive records\")\n",
        "        samples_to_add = make_duplicate(d, r, diff, label_y, names, need_positive_or_negative = 1)\n",
        "        d = pd.concat([d, samples_to_add], ignore_index=True)\n",
        "    for k in need_neg:\n",
        "        diff = compute_diff_add(k, temp2, names, label_y, need_positive_or_negative = 0)\n",
        "        if diff == -1:\n",
        "          continue\n",
        "        diff = round_int(diff)\n",
        "        samples_to_add = make_duplicate(d, k, diff, label_y, names, need_positive_or_negative = 0)\n",
        "        d = pd.concat([d, samples_to_add], ignore_index=True)\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9m0e5GbVL-d"
      },
      "outputs": [],
      "source": [
        "def round_int(x):\n",
        "    if x in [float(\"-inf\"),float(\"inf\")]: return 0\n",
        "    return int(round(x))\n",
        "\n",
        "\n",
        "def make_remove(d, group_lst, diff, names, label_y, need_positive_or_negative):\n",
        "\n",
        "    temp = copy.deepcopy(d)\n",
        "    for i in range(len(group_lst)):\n",
        "        att_name = names[i]\n",
        "        temp = temp[(temp[att_name] == group_lst[i])]\n",
        "    temp = temp[(temp[label_y] == need_positive_or_negative)]\n",
        "    # randomly generated diff samples\n",
        "        #generated = temp\n",
        "        # the number needed is more than the not needed numbers.\n",
        "\n",
        "    if(diff>len(temp)):\n",
        "        diff = len(temp)\n",
        "    generated = temp.sample(n = diff, replace = False, axis = 0)\n",
        "\n",
        "    return generated.index\n",
        "\n",
        "\n",
        "def naive_downsampling(d, temp2, names, need_pos, need_neg, label_y):\n",
        "    # add more records for all groups\n",
        "    # The smote algorithm to boost the coverage\n",
        "    for r in need_pos:\n",
        "\n",
        "    # add more positive records\n",
        "        # determine how many points to add\n",
        "\n",
        "        diff = compute_diff_remove(r, temp2, names, label_y, need_positive_or_negative = 1)\n",
        "        if diff == -1:\n",
        "          continue\n",
        "        diff = round_int(diff)\n",
        "        # add more records\n",
        "        samples_to_remove = make_remove(d, r, diff, names, label_y, need_positive_or_negative = 0)\n",
        "        d.drop(index  = samples_to_remove, inplace = True)\n",
        "\n",
        "    for k in need_neg:\n",
        "\n",
        "        diff = compute_diff_remove(k, temp2, names, label_y, need_positive_or_negative = 0)\n",
        "        if diff == -1:\n",
        "          continue\n",
        "        diff = round_int(diff)\n",
        "\n",
        "        samples_to_remove = make_remove(d, k, diff, names, label_y, need_positive_or_negative = 1)\n",
        "        d.drop(index  = samples_to_remove, inplace = True)\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tINoeYnSnWn4"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "def round_int(x):\n",
        "    if x in [float(\"-inf\"),float(\"inf\")]: return 0\n",
        "    return int(round(x))\n",
        "\n",
        "def get_depromotion(d, diff, group_lst, names, label_y, flag_depro):\n",
        "\n",
        "    input_test = pd.DataFrame(d, columns = columns_compas)\n",
        "    clf = MultinomialNB()\n",
        "    temp_train_label = pd.DataFrame(d, columns = [label_y])\n",
        "    temp_train_label = temp_train_label[label_y]\n",
        "    temp_train_label = temp_train_label.astype('int')\n",
        "    clf = clf.fit(input_test, temp_train_label)\n",
        "    prob  = clf.predict_proba(input_test)[:,0]\n",
        "    select = copy.deepcopy(d)\n",
        "    select['prob'] = prob # the higher the probablity is, the more likely for it to be 0\n",
        "    # filter out those belongs to this group\n",
        "    for i in range(len(group_lst)):\n",
        "        att_name = names[i]\n",
        "        select = select[(select[att_name] == group_lst[i])]\n",
        "    select = select[(select[label_y] == flag_depro)]\n",
        "    # rank them according to the probability\n",
        "    # filp the records and remove the records from d\n",
        "    if (flag_depro == 0):\n",
        "        select.sort_values(by=\"prob\", ascending=True, inplace=True)\n",
        "        select[label_y] = 1\n",
        "    else:\n",
        "        select.sort_values(by=\"prob\", ascending=False, inplace=True)\n",
        "        select[label_y] = 0\n",
        "    head = select.head(diff)\n",
        "    index_list = []\n",
        "    index_list = list(head.index)\n",
        "    d.drop(index_list,inplace = True)\n",
        "    head.drop(columns = ['prob'],inplace = True)\n",
        "    return head\n",
        "\n",
        "\n",
        "\n",
        "def naive_massaging(d, temp2, names, need_pos, need_neg,label_y):\n",
        "    # add more records for all groups\n",
        "    # The smote algorithm to boost the coverage\n",
        "    for r in need_pos:\n",
        "\n",
        "    # add more positive records\n",
        "        # determine how many points to add\n",
        "\n",
        "        diff = compute_diff_add_and_remove(r, temp2, 1, label_y, names)\n",
        "        diff =  round_int(diff)\n",
        "        # add more records\n",
        "        #0 for promotion\n",
        "        samples_to_add = get_depromotion(d, diff, r, names, label_y, flag_depro = 0)\n",
        "\n",
        "        d = pd.concat([d, samples_to_add])\n",
        "    for k in need_neg:\n",
        "\n",
        "        diff = compute_diff_add_and_remove(k, temp2, 0, label_y, names)\n",
        "        diff =  round_int(diff)\n",
        "        #1 for demotion\n",
        "        samples_to_add = get_depromotion(d, diff, k, names, label_y, flag_depro = 1)\n",
        "        d = pd.concat([d, samples_to_add])\n",
        "\n",
        "    return d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGdoCnWLlkc4"
      },
      "source": [
        "## Run Algorithm Lattice\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def candidate_groups(skew_candidates):\n",
        "  candidate_combos = []\n",
        "  candidate_ind = {}\n",
        "  num = 0\n",
        "  for i in range(len(skew_candidates)+1):\n",
        "    temp_candidate = list(itertools.combinations(skew_candidates, i))\n",
        "    for tc in temp_candidate:\n",
        "      candidate_ind[num] = list(tc)\n",
        "      num += 1\n",
        "  return candidate_ind"
      ],
      "metadata": {
        "id": "YABr1WysUiVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_count = 30"
      ],
      "metadata": {
        "id": "rrShsLQLV3-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "import csv\n",
        "\n",
        "with open('local_samika.csv', 'w', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow([\"Dataset\",\"Algorithm\",\"Total Records\", \"Train Records\",\"Attribute_names\",\"NumAttr\",\"IdTime\",\"AlgoTime\"])\n",
        "  minus = 0\n",
        "  for i in range(len(columns_compas)-1):\n",
        "    minus = i\n",
        "    all_names = candidate_groups(columns_compas[:len(columns_compas)- minus])\n",
        "    all_names_lst = list(all_names.keys())[len(columns_compas)-minus+1:]\n",
        "    all_names_lst.reverse()\n",
        "    list_write = []\n",
        "    list_write.append(\"Adult\")\n",
        "    list_write.append(\"Pref_opt\")\n",
        "    list_write.append(data.shape[0])\n",
        "    list_write.append(train_set.shape[0])\n",
        "    list_write.append(columns_compas[:len(columns_compas)-minus])\n",
        "    list_write.append(len(columns_compas[:len(columns_compas)-minus]))\n",
        "    excute_time = 0\n",
        "    excute_time1 = 0\n",
        "    # print(len(all_names_lst))\n",
        "    for a in all_names_lst:\n",
        "\n",
        "        temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "        temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "        temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "        lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "        start = time.time()\n",
        "        need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "        end = time.time()\n",
        "        excute_time += end - start\n",
        "        # print(\"id time\", excute_time)\n",
        "\n",
        "        new_train_data['skewed'] = 0\n",
        "        new_train_data[\"diff\"] = 0\n",
        "        # print(\"started pref sampling\")\n",
        "        start1 = time.time()\n",
        "        new_train_data = pref_sampling_opt(new_train_data, names, compas_y, need_pos, need_neg)\n",
        "        end1 = time.time()\n",
        "        excute_time1 += end1 - start1\n",
        "        # print(\"pref_sample time\", excute_time1)\n",
        "    list_write.append(excute_time)\n",
        "    list_write.append(excute_time1)\n",
        "    writer.writerow(list_write)\n",
        "    print(\"done\")\n",
        "\n",
        "    new_train_data = copy.deepcopy(train_set)\n",
        "    list_write = []\n",
        "    list_write.append(\"Adult\")\n",
        "    list_write.append(\"Downsampling_opt\")\n",
        "    list_write.append(data.shape[0])\n",
        "    list_write.append(train_set.shape[0])\n",
        "    list_write.append(columns_compas[:len(columns_compas)-minus])\n",
        "    list_write.append(len(columns_compas[:len(columns_compas)-minus]))\n",
        "    excute_time = 0\n",
        "    excute_time1 = 0\n",
        "    for a in all_names_lst:\n",
        "      temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "      temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "      temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "      lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "      start = time.time()\n",
        "      need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "      end = time.time()\n",
        "      excute_time += end - start\n",
        "      new_train_data['skewed'] = 0\n",
        "      new_train_data[\"diff\"] = 0\n",
        "\n",
        "      start1 = time.time()\n",
        "      new_train_data = naive_downsampling(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "      end1 = time.time()\n",
        "      excute_time1 += end1 - start1\n",
        "    list_write.append(excute_time)\n",
        "    list_write.append(excute_time1)\n",
        "    writer.writerow(list_write)\n",
        "\n",
        "    new_train_data = copy.deepcopy(train_set)\n",
        "    list_write = []\n",
        "    list_write.append(\"Adult\")\n",
        "    list_write.append(\"Massaging_opt\")\n",
        "    list_write.append(data.shape[0])\n",
        "    list_write.append(train_set.shape[0])\n",
        "    list_write.append(columns_compas[:len(columns_compas)-minus])\n",
        "    list_write.append(len(columns_compas[:len(columns_compas)-minus]))\n",
        "    excute_time = 0\n",
        "    excute_time1 = 0\n",
        "    for a in all_names_lst:\n",
        "      temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "      temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "      temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "      lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "      start = time.time()\n",
        "      need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "      end = time.time()\n",
        "      excute_time += end - start\n",
        "\n",
        "      new_train_data['skewed'] = 0\n",
        "      new_train_data[\"diff\"] = 0\n",
        "      start1 = time.time()\n",
        "      new_train_data = naive_massaging(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "      end1 = time.time()\n",
        "      excute_time1 += end1 - start1\n",
        "    list_write.append(excute_time)\n",
        "    list_write.append(excute_time1)\n",
        "    writer.writerow(list_write)"
      ],
      "metadata": {
        "id": "4BZb2fmjl74h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "cd56342f-3f69-4abf-9b9c-394f590d0924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-4b661854f2b3>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# print(\"started pref sampling\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mstart1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mnew_train_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpref_sampling_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompas_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mend1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mexcute_time1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mend1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-cd24850b2676>\u001b[0m in \u001b[0;36mpref_sampling_opt\u001b[0;34m(train_set, cols_given, label, need_pos, need_neg)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prob\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mnew_train_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mupdated_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneed_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0;31m# GH10856\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# raise ValueError if only scalars in dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mnew_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetitem_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mgetitem_mgr\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   2032\u001b[0m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2034\u001b[0;31m         \u001b[0mnew_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2035\u001b[0m         \u001b[0;31m# TODO(CoW) in theory only need to track reference if new_array is a view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5352\u001b[0m         \u001b[0;31m# NB: Using _constructor._simple_new would break if MultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5353\u001b[0m         \u001b[0;31m#  didn't override __getitem__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_IndexT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_IndexT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_constructor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_IndexT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_IndexT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "import csv\n",
        "\n",
        "# get the list of numbers of the given group\n",
        "def get_one_degree_neighbors(temp2, names, group_lst):\n",
        "    result = []\n",
        "    for i in range(len(group_lst)):\n",
        "        d = copy.copy(temp2)\n",
        "        for k in range(len(group_lst)):\n",
        "            if k != i:\n",
        "                d = d[d[names[k]] == group_lst[k]]\n",
        "            else:\n",
        "                d = d[d[names[k]] != group_lst[k]]\n",
        "        #print(d)\n",
        "        result.append(d)\n",
        "    return result\n",
        "\n",
        "def determine_problematic(group_lst, temp2, result, label, threshold= 0.3):\n",
        "    # return a value for a given group about whether it is a problematic group\n",
        "    #0: ok group, 1: need negative records, 2: need positive records\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    #print(d)\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    #print(pos, neg, pos/neg)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(neighbors[2] == -1):\n",
        "        # there is no neighbors\n",
        "        return 0\n",
        "#     if(neg == 0):\n",
        "#         return 0\n",
        "    if(total > 10):\n",
        "        # need to be large enough\n",
        "        if (pos/(neg+1) - neighbors[2] > threshold):\n",
        "            # too many positive records\n",
        "            return 1\n",
        "        if (neighbors[2] - pos/(neg+1) > threshold):\n",
        "            # too many negative records\n",
        "            return 2\n",
        "    return 0\n",
        "\n",
        "with open('local_samika.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  # writer.writerow([\"Dataset\",\"Algorithm\",\"Attribute_names\",\"NumAttr\",\"IdTime\",\"AlgoTime\"])\n",
        "  for s in range(len(columns_compas)-1):\n",
        "    minus = s\n",
        "    all_names = candidate_groups(columns_compas[:len(columns_compas)- minus])\n",
        "    all_names_lst = list(all_names.keys())[len(columns_compas)-minus+1:]\n",
        "    all_names_lst.reverse()\n",
        "    list_write = []\n",
        "    list_write.append(\"Adult\")\n",
        "    list_write.append(\"Pref_naive\")\n",
        "    list_write.append(data.shape[0])\n",
        "    list_write.append(train_set.shape[0])\n",
        "    list_write.append(columns_compas[:len(columns_compas)-minus])\n",
        "    list_write.append(len(columns_compas[:len(columns_compas)-minus]))\n",
        "    excute_time = 0\n",
        "    excute_time1 = 0\n",
        "    for a in all_names_lst:\n",
        "      need_pos = []\n",
        "      need_neg = []\n",
        "      temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "      temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "      # naive algorithm do not have a filter here.\n",
        "      # temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "      # start finding the set of problematic regions\n",
        "      start = time.time()\n",
        "      for index, row in temp_g.iterrows():\n",
        "        group_lst = []\n",
        "        for n in names:\n",
        "          group_lst.append(row[n])\n",
        "        # get neighbors\n",
        "        result = get_one_degree_neighbors(temp2, names, group_lst)\n",
        "        # get if belong in need/pos group\n",
        "        pos_neg_val = determine_problematic(group_lst, temp2, result, compas_y, threshold= 0.3)\n",
        "        # if needs neg vals\n",
        "        if pos_neg_val == 1:\n",
        "          need_neg.append(group_lst)\n",
        "      # if needs pos vals\n",
        "        if pos_neg_val == 2:\n",
        "          need_pos.append(group_lst)\n",
        "      end = time.time()\n",
        "      excute_time += end - start\n",
        "      # print(\"id time\", excute_time)\n",
        "      new_train_data['skewed'] = 0\n",
        "      new_train_data[\"diff\"] = 0\n",
        "      # call pref sampling\n",
        "      start1 = time.time()\n",
        "      new_train_data = pref_sampling_opt(new_train_data, names, compas_y, need_pos, need_neg)\n",
        "      end1 = time.time()\n",
        "      excute_time1 += end1 - start1\n",
        "      # print(\"pref_sample time\", excute_time1)\n",
        "      # print(new_train_data)\n",
        "      # print(pref_sampling_mod(train_x, train_set, train_label, names, compas_y, need_pos, need_neg))\n",
        "    list_write.append(excute_time)\n",
        "    list_write.append(excute_time1)\n",
        "    writer.writerow(list_write)"
      ],
      "metadata": {
        "id": "3Zy21oUFr4kI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "5bec2f15-a7b9-4cd9-9df1-c511aea6833d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-ad3420bd5b60>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m           \u001b[0mgroup_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# get neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_one_degree_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;31m# get if belong in need/pos group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mpos_neg_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_problematic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompas_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-ad3420bd5b60>\u001b[0m in \u001b[0;36mget_one_degree_neighbors\u001b[0;34m(temp2, names, group_lst)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__copy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__copy__\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   6372\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__copy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNDFrameT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNDFrameT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6376\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   6366\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6367\u001b[0m         \"\"\"\n\u001b[0;32m-> 6368\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6370\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1871\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1872\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_consolidate_with_refs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   2327\u001b[0m     \u001b[0mnew_blocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2329\u001b[0;31m         merged_blocks, _ = _merge_blocks(\n\u001b[0m\u001b[1;32m   2330\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_consolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2331\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[1;32m   2389\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2391\u001b[0;31m         \u001b[0mbp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockPlacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2392\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_block_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
