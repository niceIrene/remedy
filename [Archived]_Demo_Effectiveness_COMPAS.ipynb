{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Set-Up\n",
        "\n",
        "### SOURCE: **Mitigating Subgroup Unfairness in Machine Learning Classifiers: A Data-Driven Approach**  \n",
        "\n",
        "This notebook will **output a .csv file named compas.csv** with the fairness and accuracy result metrics of the different remedy methods if **all cells are run**.  \n",
        "\n",
        "The **Set-Up** section includes processing the data, running the baseline divexplorer functions and various helper functions used for **Identification** (and its relevant preprocessing methods) and helper functions for the **Remedy Algorithms**. \n",
        "\n",
        "The rest of the notebook is divided by the different **4 remedy algorithms** of: \n",
        "\n",
        "1.   Preferential Sampling\n",
        "2.   Duplication/Oversampling\n",
        "3.   Down-sampling/Undersampling\n",
        "4. Massaging\n",
        "\n",
        "Each of these Remedy Algorithms will have the 3 subgroups and the subsequent results:\n",
        "1. Lattice\n",
        "2. Leaf\n",
        "3. Top\n",
        "\n",
        " For more information about the methods, refer to the paper: Mitigating Subgroup Unfairness in Machine Learning Classifiers: A Data-Driven Approach"
      ],
      "metadata": {
        "id": "Rep5dQYjdU0t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "772S9aKIfv-9"
      },
      "source": [
        "##Imports and Dataset processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "Evnn9BbOfEme"
      },
      "outputs": [],
      "source": [
        "# Import all neccessary packages \n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, make_scorer\n",
        "import copy\n",
        "from sympy import Symbol\n",
        "from sympy.solvers import solve\n",
        "pd.options.mode.chained_assignment = None \n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_vP0FN3vfgjA",
        "outputId": "800444f1-5fa6-42b2-d949-2f9730dba07c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age  charge  race  sex  #prior  stay  class  predicted\n",
              "0       0       0     0    0       0     0      0          0\n",
              "1       1       0     1    0       0     1      1          0\n",
              "2       2       0     1    0       2     0      1          0\n",
              "3       1       1     0    0       0     0      0          0\n",
              "4       1       0     2    0       2     0      1          0\n",
              "...   ...     ...   ...  ...     ...   ...    ...        ...\n",
              "6167    2       0     1    0       0     0      0          0\n",
              "6168    2       0     1    0       0     0      0          0\n",
              "6169    0       0     0    0       0     0      0          0\n",
              "6170    1       1     1    1       1     0      0          0\n",
              "6171    2       0     3    1       1     0      1          0\n",
              "\n",
              "[6172 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4cac940d-f215-43f9-9bfa-e028e5168e5a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>charge</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>#prior</th>\n",
              "      <th>stay</th>\n",
              "      <th>class</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6167</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6168</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6169</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6170</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6171</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6172 rows Ã— 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cac940d-f215-43f9-9bfa-e028e5168e5a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4cac940d-f215-43f9-9bfa-e028e5168e5a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4cac940d-f215-43f9-9bfa-e028e5168e5a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "# read in the data, change url accordingly\n",
        "url = \"https://raw.githubusercontent.com/niceIrene/remedy/main/datasets/compas_numerical.csv\"\n",
        "data = pd.read_csv(url)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "NNSifBfwflg8"
      },
      "outputs": [],
      "source": [
        "# get training and testing set\n",
        "\n",
        "# column names that will be used as protected class\n",
        "columns_compas = ['stay', 'age', 'charge', 'sex', '#prior', 'race']\n",
        "\n",
        "#all colummns except the \n",
        "columns_all = columns_compas\n",
        "\n",
        "#y_label \n",
        "compas_y = 'class'\n",
        "\n",
        "# Used in get_train_test as helper function\n",
        "def split_train_test(data,test_ratio):\n",
        "    np.random.seed(42)\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices],data.iloc[test_indices]\n",
        "    \n",
        "\"\"\"\n",
        "Split the data into test and train dataset and get the results\n",
        "Input: \n",
        "data = whole dataset (dataframe)\n",
        "split = float between 0.0-1.0 for size of test set\n",
        "list_cols = which columns to use (list)\n",
        "y_label = str containing column name of y_label \n",
        "\"\"\"\n",
        "def get_train_test(data, split, list_cols, y_label):\n",
        "  all_list = copy.deepcopy(list_cols)\n",
        "  all_list.append(y_label)\n",
        "  data = pd.DataFrame(data, columns = all_list)\n",
        "  train_set,test_set = split_train_test(data,split)\n",
        "  print(len(train_set), \"train +\", len(test_set), \"test\")\n",
        "  train_x = pd.DataFrame(train_set, columns = list_cols)\n",
        "  train_label = train_set[y_label]\n",
        "  test_x = pd.DataFrame(test_set, columns = list_cols)\n",
        "  test_label = test_set[y_label]\n",
        "  return train_x, test_x, train_label, test_label, train_set, test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJQsq95bfpEH",
        "outputId": "838b769d-e848-41bc-82f4-97edd8baddc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4321 train + 1851 test\n"
          ]
        }
      ],
      "source": [
        "# Get test and train datasets\n",
        "train_x, test_x, train_label, test_label, train_set, test_set  = get_train_test(data, 0.3, columns_all, compas_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Model Settings and Other Global Variables\n",
        "\"\"\"\n",
        "\n",
        "# The minimum size of the group (used in the run algorithm cells)\n",
        "filter_count = 30\n",
        "\n",
        "scoring = make_scorer(accuracy_score)\n",
        "\n",
        "# #####################\n",
        "\n",
        "#Logisitic Regression Settings\n",
        "\n",
        "# #####################\n",
        "param_gridlg = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "gridlg = GridSearchCV(logreg, param_grid=param_gridlg, scoring=scoring, cv=5)\n",
        "\n",
        "\n",
        "# #####################\n",
        "\n",
        "#Decision Tree Classifier Settings\n",
        "\n",
        "# #####################\n",
        "param_griddt = {\n",
        "    'max_depth': [2, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "griddt = GridSearchCV(dt, param_grid=param_griddt, scoring=scoring, cv=5)\n",
        "\n",
        "# #####################\n",
        "\n",
        "#Random Forest Classifier Settings\n",
        "\n",
        "# #####################\n",
        "param_gridrf = {'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 100], 'random_state':[17]}\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "gridrf = GridSearchCV(rf, param_grid=param_gridrf, scoring=scoring, cv=5)\n",
        "\n",
        "# #####################\n",
        "\n",
        "# SVM Settings\n",
        "\n",
        "# #####################\n",
        "\n",
        "clf = SVC(kernel='rbf', C=1.0, gamma = 'scale', random_state =42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "asgU_pEhAOlK"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model for SVC, used for baseline results for divexplorer\n",
        "clf.fit(train_x, train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "test_set['predicted'] = test_predict\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy is \" , accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEdhtLxCTQaH",
        "outputId": "d84867f1-7dca-40d2-c4a3-166050bf2431"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is  0.6661264181523501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmhcs6wcgGiZ"
      },
      "source": [
        "## Divexplorer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install divexplorer if needed"
      ],
      "metadata": {
        "id": "OFNA1eXPU1-O"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVt4YIpUgKlo",
        "outputId": "1b90956b-7351-4566-9a4e-2d6bc1f29a83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: divexplorer in /usr/local/lib/python3.8/dist-packages (0.1.1)\n",
            "Requirement already satisfied: plotly>=4.5.0 in /usr/local/lib/python3.8/dist-packages (from divexplorer) (5.5.0)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.8/dist-packages (from divexplorer) (3.5.3)\n",
            "Requirement already satisfied: ipywidgets>=7.2.1 in /usr/local/lib/python3.8/dist-packages (from divexplorer) (7.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.8/dist-packages (from divexplorer) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.8/dist-packages (from divexplorer) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from divexplorer) (1.3.5)\n",
            "Requirement already satisfied: mlxtend>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from divexplorer) (0.21.0)\n",
            "Requirement already satisfied: python-igraph>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from divexplorer) (0.10.4)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.2.1->divexplorer) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.2.1->divexplorer) (3.6.2)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.2.1->divexplorer) (5.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.2.1->divexplorer) (5.3.4)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.2.1->divexplorer) (3.0.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.2.1->divexplorer) (7.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->divexplorer) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->divexplorer) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->divexplorer) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->divexplorer) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->divexplorer) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->divexplorer) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->divexplorer) (7.1.2)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.8/dist-packages (from mlxtend>=0.17.1->divexplorer) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend>=0.17.1->divexplorer) (1.7.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from mlxtend>=0.17.1->divexplorer) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.2->divexplorer) (2022.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=4.5.0->divexplorer) (8.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly>=4.5.0->divexplorer) (1.15.0)\n",
            "Requirement already satisfied: igraph==0.10.4 in /usr/local/lib/python3.8/dist-packages (from python-igraph>=0.8.3->divexplorer) (0.10.4)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from igraph==0.10.4->python-igraph>=0.8.3->divexplorer) (1.6.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.23.2->divexplorer) (3.1.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.2.1->divexplorer) (6.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.2.1->divexplorer) (6.1.12)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer) (0.18.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer) (2.6.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (6.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer) (0.8.3)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (21.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (5.2.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (0.13.3)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (23.2.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (0.16.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (5.6.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (5.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (2.11.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (3.0.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (2.0.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (0.4)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (2.16.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (22.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (5.12.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (1.15.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer) (3.14.0)\n"
          ]
        }
      ],
      "source": [
        "pip install divexplorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "tb3zgDbUgXcV"
      },
      "outputs": [],
      "source": [
        "# Computes the fairness scoring in terms of the support for unfair group\n",
        "# input of the dataframe from divexplorer and str of metric used\n",
        "def fairness_score_computation(d, metrics):\n",
        "    sum_of_score = 0\n",
        "    for idx, row in d.iterrows():\n",
        "      sum_of_score += row['support'] * row[metrics]\n",
        "    return sum_of_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "f-rnfp9XfuKM"
      },
      "outputs": [],
      "source": [
        "# Gets the fpr of a single group \n",
        "# Takes input of the true and predicted values as list\n",
        "def fpr_onegroup(true, predict):\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    for i in range(len(true)):\n",
        "        if (true[i] == 0 and predict[i] == 1):\n",
        "            fp += 1 \n",
        "        if(true[i] == 0 and predict[i] == 0):\n",
        "            tn += 1\n",
        "    return fp/(fp+tn)\n",
        "\n",
        "# Gets the fpr of a single group \n",
        "# Takes input of the true and predicted values as list\n",
        "def fnr_onegroup(true, predict):\n",
        "    fn = 0\n",
        "    tp = 0\n",
        "    for i in range(len(true)):\n",
        "        if (true[i] == 1 and predict[i] == 0):\n",
        "            fn += 1 \n",
        "        if(true[i] == 1 and predict[i] == 1):\n",
        "            tp += 1\n",
        "    return fn/(fn+tp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run divexplorer to find unfair groups\n",
        "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "from divexplorer.FP_Divergence import FP_Divergence\n",
        "\n",
        "\n",
        "######\n",
        "# Data-preprocessing before divexplorer results\n",
        "class_map={'N': 0, 'P': 1}\n",
        "columns_compas.extend([compas_y, \"predicted\"])\n",
        "\n",
        "df = pd.DataFrame(test_set, columns = columns_compas)\n",
        "\n",
        "columns_compas.remove(compas_y)\n",
        "columns_compas.remove('predicted')\n",
        "\n",
        "######\n",
        "\n",
        "#Support metrics for the group must be greater than 0.1\n",
        "min_sup=0.1\n",
        "\n",
        "fp_diver=FP_DivergenceExplorer(df,compas_y, \"predicted\", class_map=class_map)\n",
        "FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "\n",
        "fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "fp_divergence_fnr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "fp_divergence_acc=FP_Divergence(FP_fm, \"d_accuracy\")\n",
        "\n",
        "INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "INFO_VIZ2=[\"support\", \"itemsets\",  fp_divergence_fnr.metric, fp_divergence_fnr.t_value_col]\n",
        "INFO_VIZ3=[\"support\", \"itemsets\",  fp_divergence_acc.metric, fp_divergence_acc.t_value_col]\n",
        "\n",
        "#Setting for output of divexplorer results\n",
        "eps=0.01\n",
        "K=1000\n",
        "\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ].head(K)\n",
        "d2 = fp_divergence_fnr.getDivergence(th_redundancy=eps)[INFO_VIZ2].head(K)\n",
        "d3 = fp_divergence_acc.getDivergence(th_redundancy=eps)[INFO_VIZ3].head(K)\n",
        "\n",
        "\n",
        "\n",
        "pd.options.display.max_rows = 200\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "# summerization\n",
        "\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ].head(K)\n",
        "d= d[d['d_fpr'] > 0]\n",
        "d2= d2[d2['d_fnr'] > 0]\n",
        "d3= d3[d3['d_accuracy'] > 0]\n",
        "\n",
        "dfpr = fairness_score_computation(d, 'd_fpr')\n",
        "dfnr = fairness_score_computation(d2, 'd_fnr')\n",
        "dacc = fairness_score_computation(d3, 'd_accuracy')\n",
        "\n",
        "print(\"dfpr: \", dfpr)\n",
        "print(\"dfnr: \", dfnr)\n",
        "print(\"dacc: \", dacc)\n",
        "print()\n",
        "\n",
        "#print the d_fpr dataframe results and the most unfair group\n",
        "d.head(), list(d[\"itemsets\"].iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYDp7XFE2Q6x",
        "outputId": "87baf3ab-63ac-4222-8faa-171d8881ac34"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dfpr:  1.194963899198641\n",
            "dfnr:  3.1294379205954597\n",
            "dacc:  0.1642495580381887\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(      support                          itemsets     d_fpr  t_value_fp\n",
              " 28   0.289573                        (#prior=2)  0.745098   50.438466\n",
              " 105  0.136143          (charge=0, sex=0, age=2)  0.323529    6.417386\n",
              " 61   0.183684                    (sex=0, age=2)  0.269236    6.205293\n",
              " 148  0.104268  (charge=0, sex=0, age=2, stay=0)  0.256462    4.722968\n",
              " 75   0.162075                 (charge=0, age=2)  0.252911    5.513975,\n",
              " ['#prior=2'])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If save results to a new file: compas.csv, use this cell\n",
        "with open('compas.csv', 'w', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow([\"Dataset\",\"Remedy\", \"Algorithm\",\"d_fpr\",\"d_fnr\", \"d_acc\", \"model_acc\"])\n",
        "  writer.writerow([\"COMPAS\", \"Original\", \"SVM\", dfpr, dfnr, dacc, accuracy])"
      ],
      "metadata": {
        "id": "1QotGAAo9Y7F"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # If file: compas.csv already exists, use this cell\n",
        "\n",
        "# with open('compas.csv', 'a+', newline='') as file:\n",
        "#   writer = csv.writer(file)\n",
        "#   writer.writerow([\"COMPAS\", \"Original\", \"SVM\", dfpr, dfnr, dacc, accuracy])"
      ],
      "metadata": {
        "id": "D-xbkRgkQDxA"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TttueBgvg53C"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "These functions will be used within different remedy methods "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4TwHPK4hd0A"
      },
      "source": [
        "### General Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "aU9MirNCglkA"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "# give list_parse more parameters if smaller subset is desired\n",
        "# unnecessary to use otherwise\n",
        "def get_unfair_group(list_parse, entire = 1):\n",
        "  unfair_group = []\n",
        "  unfair_dict = {}\n",
        "  names = []\n",
        "  for col in columns_compas:\n",
        "    found = False\n",
        "    for item in list_parse:\n",
        "      attr_given = item.split(\"=\")[0]\n",
        "      if col == attr_given:\n",
        "        unfair_group.append(int(item.split(\"=\")[1]))\n",
        "        names.append(attr_given)\n",
        "        unfair_dict[attr_given] = int(item.split(\"=\")[1])\n",
        "        found = True\n",
        "  # if use the entire dataset (usually the case)\n",
        "  if entire:\n",
        "    return unfair_group, names, columns_compas, unfair_dict\n",
        "  return unfair_group, names, list(set(columns_compas).symmetric_difference(set(names))), unfair_dict\n",
        "\n",
        "# Return the combinations of the skew_candidates in dict form\n",
        "# Can use the output from get_unfair_group() to create filtered dict of combos\n",
        "def candidate_groups(skew_candidates, unfair_dict, ordering, names):\n",
        "  candidate_combos = []\n",
        "  candidate_ind = {}\n",
        "  num = 0\n",
        "  for i in range(len(skew_candidates)+1):\n",
        "    temp_candidate = list(itertools.combinations(skew_candidates, i))\n",
        "    for tc in temp_candidate:\n",
        "      candidate_ind[num] = list(tc)\n",
        "      num += 1\n",
        "  return candidate_ind\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "FMrAfuoDtjAQ"
      },
      "outputs": [],
      "source": [
        "#Runs functions to output the correct format for all candidate group combinations\n",
        "\n",
        "unfair_group, unfair_names, skew_candidates, unfair_dict = get_unfair_group([])\n",
        "all_names = candidate_groups(skew_candidates, unfair_dict, columns_compas, unfair_names)\n",
        "\n",
        "# put into list form\n",
        "all_names_lst = list(all_names.keys())[len(columns_compas)+1:]\n",
        "\n",
        "# reverse list for desired format \n",
        "all_names_lst.reverse()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "uuEIYpHwjg_H"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a new subset dataframe using the desired unfair group candidates \n",
        "# Dataframe will have a new category \"cnt\", groupby counts needed for filtering\n",
        "# and computing differences between groups \n",
        "\n",
        "def get_temp_g(train_set, names, y_label):\n",
        "  names2 = copy.deepcopy(names)\n",
        "  names2.append(y_label)\n",
        "  temp = train_set[names2]\n",
        "  temp['cnt'] = 0\n",
        "  temp_g = temp.groupby(names)['cnt'].count().reset_index()\n",
        "  return temp, temp_g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZgdhgqYZjTci",
        "outputId": "11657d6e-a029-4676-ee41-94ea71176d49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     stay  age  charge  sex  #prior  race  class  cnt\n",
              "0       0    0       0    0       0     0      0   11\n",
              "1       0    0       0    0       0     0      1    4\n",
              "2       0    0       0    0       0     1      0   11\n",
              "3       0    0       0    0       0     1      1    9\n",
              "4       0    0       0    0       0     2      0   40\n",
              "..    ...  ...     ...  ...     ...   ...    ...  ...\n",
              "483     2    2       1    0       1     1      0    1\n",
              "484     2    2       1    0       1     1      1    1\n",
              "485     2    2       1    1       0     1      0    1\n",
              "486     2    2       1    1       2     1      0    1\n",
              "487     2    2       1    1       2     2      1    1\n",
              "\n",
              "[488 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a020fe39-8cc5-40b6-a4a4-9057cb6598d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stay</th>\n",
              "      <th>age</th>\n",
              "      <th>charge</th>\n",
              "      <th>sex</th>\n",
              "      <th>#prior</th>\n",
              "      <th>race</th>\n",
              "      <th>class</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>488 rows Ã— 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a020fe39-8cc5-40b6-a4a4-9057cb6598d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a020fe39-8cc5-40b6-a4a4-9057cb6598d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a020fe39-8cc5-40b6-a4a4-9057cb6598d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "# Create a new subset dataframe using the desired unfair group candidates \n",
        "# Dataframe will have a new category \"cnt\", groupby counts that are summed up\n",
        "# needed for filtering and computing differences between groups \n",
        "def get_temp(train_set, names, y_label):\n",
        "  names2 = copy.deepcopy(names)\n",
        "  names2.append(y_label)\n",
        "  temp = train_set[names2]\n",
        "  temp['cnt'] = 0\n",
        "  temp2 = temp.groupby(names2)['cnt'].count().reset_index()\n",
        "  temp2['cnt'].sum()\n",
        "  return temp2, names\n",
        "temp2, names = get_temp(train_set, columns_compas, compas_y)\n",
        "\n",
        "# Example output\n",
        "temp2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "paqO9W2jeTMX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Function used to find all groups that belong in \"top\" group\n",
        "(Groups of size 2)\n",
        "\"\"\"\n",
        "def find_top(all_names):\n",
        "  all_names_lst_top = []\n",
        "  for all in range(len(all_names)):\n",
        "    if len(all_names[all]) == 2:\n",
        "      all_names_lst_top.append(all)\n",
        "  return all_names_lst_top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "wvC9RSgZkD80"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Finds all of the closest neighbors by one degree to a group \n",
        "Naive Method\n",
        "\"\"\"\n",
        "def get_one_degree_neighbors(temp2, names, group_lst):\n",
        "    result = []\n",
        "    for i in range(len(group_lst)):\n",
        "        d = copy.copy(temp2)\n",
        "        for k in range(len(group_lst)):\n",
        "            if k != i:\n",
        "                d = d[d[names[k]] == group_lst[k]]\n",
        "            else:\n",
        "                d = d[d[names[k]] != group_lst[k]]\n",
        "        result.append(d)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "sGQalez0kLkE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        " After finding the closest neighbors, compute the \n",
        " pos/neg ratio of these neighbors \n",
        " Naive method\n",
        "\"\"\"\n",
        "def compute_neighbors(group_lst, result):\n",
        "    # compute the ratio of positive and negative records\n",
        "    start2 = time.time()\n",
        "    pos = 0\n",
        "    neg = 0 \n",
        "    for r in result:\n",
        "        total  = r['cnt'].sum()\n",
        "        r = r[r[compas_y] == 1]\n",
        "        pos += r['cnt'].sum()\n",
        "        neg += total - r['cnt'].sum()\n",
        "    if(neg == 0):\n",
        "        return (pos, neg, -1)\n",
        "    end2 = time.time()\n",
        "    return(pos, neg, pos/neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "ijabVWcBjtCh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Used in Preferential Sampling and Massaging Algorithms\n",
        "These algorithms choose to add and remove records depending on if\n",
        "more positive or negative values or less positive or negative value are needed  \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def compute_diff_add_and_remove(group_lst, temp2, need_positive_or_negative, label, names):\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    # Total here was 0: here, errors when this is commented out\n",
        "    if total == 0:\n",
        "      return -1\n",
        "    d = d[d[label] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "\n",
        "    neg = total - pos\n",
        "    result = get_one_degree_neighbors(temp2,names, group_lst)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(need_positive_or_negative == 1):\n",
        "        # need pos\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve((pos + x)/ (neg - x) - neighbors[2])[0]\n",
        "        except:\n",
        "          return -1       \n",
        "    else:\n",
        "        #need negative\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve((pos - x)/ (neg + x) - neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "    return diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "TH7YGCuh69D7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Used in Duplication Algorithms\n",
        "This algorithm choose to add records depending on if\n",
        "more positive or negative values are needed  \n",
        "\n",
        "\"\"\"\n",
        "def compute_diff_add(group_lst, temp2, names, label_y, need_positive_or_negative):\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label_y] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    result = get_one_degree_neighbors(temp2, names, group_lst)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(need_positive_or_negative == 1):\n",
        "        # need pos\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve((pos + x)/ neg -  neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "        print(neighbors[2], pos, neg, diff)\n",
        "    else:\n",
        "        #need negative\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve(pos/ (neg + x) -  neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "    print(neighbors[2], pos, neg, diff)\n",
        "    return diff\n",
        "\n",
        "\"\"\" \n",
        "Used in Downsampling Algorithms\n",
        "This algorithm choose to remove records depending on if\n",
        "more/less positive or negative values are needed  \n",
        "\n",
        "\"\"\"\n",
        "def compute_diff_remove(group_lst, temp2, names, label_y, need_positive_or_negative):\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label_y] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    result = get_one_degree_neighbors(temp2, names, group_lst)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(need_positive_or_negative == 1):\n",
        "        # need pos, remove some neg\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve( pos/ (neg - x) -  neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "        print(neighbors[2], pos, neg, diff)\n",
        "    else:\n",
        "        #need negative\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve((pos -x )/ neg -  neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "        print(neighbors[2], pos, neg, diff)\n",
        "    return diff\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "\n",
        "\"\"\"\n",
        "Generalized function to output the results from the divexplorer functions\n",
        "prints the model accuracy, d_fpr, d_fnr, d_acc scores and writes to csv\n",
        "\"\"\"\n",
        "def div_results(db, remedy, algo):\n",
        "  columns_compas.extend([compas_y, \"predicted\"])\n",
        "\n",
        "  df = pd.DataFrame(test_set, columns = columns_compas)\n",
        "\n",
        "  columns_compas.remove(compas_y)\n",
        "  columns_compas.remove('predicted')\n",
        "  class_map={'N': 0, 'P': 1}\n",
        "  \n",
        "  min_sup=0.1\n",
        "\n",
        "\n",
        "  fp_diver=FP_DivergenceExplorer(df,compas_y, \"predicted\", class_map=class_map)\n",
        "  FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "  from divexplorer.FP_Divergence import FP_Divergence\n",
        "  fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "  fp_divergence_fnr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "  fp_divergence_acc=FP_Divergence(FP_fm, \"d_accuracy\")\n",
        "\n",
        "  INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "  INFO_VIZ2=[\"support\", \"itemsets\",  fp_divergence_fnr.metric, fp_divergence_fnr.t_value_col]\n",
        "  INFO_VIZ3=[\"support\", \"itemsets\",  fp_divergence_acc.metric, fp_divergence_acc.t_value_col]\n",
        "\n",
        "  K=200\n",
        "  d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "  # summerization\n",
        "  eps=0.01\n",
        "\n",
        "  d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ].head(K)\n",
        "  d2 = fp_divergence_fnr.getDivergence(th_redundancy=eps)[INFO_VIZ2].head(K)\n",
        "  d3 = fp_divergence_acc.getDivergence(th_redundancy=eps)[INFO_VIZ3].head(K)\n",
        "\n",
        "  d= d[d['d_fpr'] > 0]\n",
        "  d2= d2[d2['d_fnr'] > 0]\n",
        "  d3= d3[d3['d_accuracy'] > 0]\n",
        "  \n",
        "  dfpr = fairness_score_computation(d, 'd_fpr')\n",
        "  dfnr = fairness_score_computation(d2, 'd_fnr')\n",
        "  dacc = fairness_score_computation(d3, 'd_accuracy')\n",
        "\n",
        "  print(\"dfpr\", dfpr)\n",
        "  print(\"dfnr\", dfnr)\n",
        "  print(\"dacc\", dacc)\n",
        "  accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "  print(\"accuracy is \" , accuracy)\n",
        "\n",
        "  writelist = [db,remedy,algo, dfpr, dfnr, dacc, accuracy]\n",
        "  with open('compas.csv', 'a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(writelist)\n",
        "  # print(writelist)\n",
        "  return d,d2,d3"
      ],
      "metadata": {
        "id": "ZNtlejsp3sA_"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iEQ83nxkQr4"
      },
      "source": [
        "### Optimized Helper Function\n",
        "\n",
        "Used for Identification Method of Pos/Neg groups for all Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "vuxfZHSlhXNR"
      },
      "outputs": [],
      "source": [
        "# helper function for optimized\n",
        "\"\"\"\n",
        " After finding the closest neighbors, compute the \n",
        " pos/neg ratio of these neighbors \n",
        " Optimized method\n",
        "\"\"\"\n",
        "def compute_neighbors_opt(group_lst,lst_of_counts, pos, neg):\n",
        "    times = len(group_lst)\n",
        "    pos_cnt = 0\n",
        "    neg_cnt = 0\n",
        "    for i in range(times):\n",
        "        df_groupby = lst_of_counts[i]\n",
        "        temp_group_lst_pos = copy.copy(group_lst)\n",
        "        temp_group_lst_neg = copy.copy(group_lst)\n",
        "        del temp_group_lst_pos[i]\n",
        "        del temp_group_lst_neg[i]\n",
        "        # count positive\n",
        "        temp_group_lst_pos.append(1)\n",
        "        group_tuple_pos = tuple(temp_group_lst_pos)\n",
        "        if group_tuple_pos in df_groupby.keys():\n",
        "            pos_cnt += df_groupby[group_tuple_pos]\n",
        "        else:\n",
        "            pos_cnt += 0\n",
        "        # count negative\n",
        "        temp_group_lst_neg.append(0)\n",
        "        group_tuple_neg = tuple(temp_group_lst_neg)\n",
        "        if group_tuple_neg in df_groupby.keys():\n",
        "            neg_cnt += df_groupby[group_tuple_neg]\n",
        "        else:\n",
        "            neg_cnt += 0\n",
        "    pos_val = pos_cnt - times* pos\n",
        "    neg_val = neg_cnt - times* neg\n",
        "\n",
        "    if neg_val == -1 or (neg_val == 0 and pos_val == 0):\n",
        "        return (pos_val, neg_val, -1)\n",
        "    if pos_val == 0 or neg_val == 0:\n",
        "        return (pos_val, neg_val, 0)\n",
        "\n",
        "    return (pos_val, neg_val, pos_val/neg_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "J8Iny4kJhm4V"
      },
      "outputs": [],
      "source": [
        "# get the list of neighbors\n",
        "\"\"\"\n",
        "Finds all of the closest neighbors by one degree to a group \n",
        "Optimized Method\n",
        "\"\"\"\n",
        "def get_one_degree_neighbors_opt(group_lst):\n",
        "    start1 = time.time()\n",
        "    result = []\n",
        "    for i in range(len(group_lst)):\n",
        "        d = copy.copy(group_lst)\n",
        "        d[i] = 'x'\n",
        "        result.append(d)\n",
        "    end1 = time.time()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "1MmwA0X5hofE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Function to determine based on the neighbors if the group is positive or negative\n",
        "\"\"\"\n",
        "def determine_problematic_opt(group_lst, names, temp2, lst_of_counts, label, threshold= 0.3):\n",
        "    #0: ok group, 1: need negative records, 2: need positive records\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    neighbors = compute_neighbors_opt(group_lst,lst_of_counts, pos, neg)\n",
        "    if(neighbors[2] == -1):\n",
        "        # there is no neighbors\n",
        "        return 0\n",
        "    if(total > 30):\n",
        "        # need to be large enough, need to adjust with different datasets.\n",
        "        if neg == 0:\n",
        "            if (pos > neighbors[2]):\n",
        "                return 1\n",
        "            if(pos <= neighbors[2]):\n",
        "                return 0\n",
        "        if (pos/(neg) - neighbors[2] > threshold):\n",
        "            # too many positive records\n",
        "            return 1\n",
        "        if (neighbors[2] - pos/(neg) > threshold):\n",
        "            return 2\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "A76VlG-bhqqS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Function to determine based on the neighbors if the group is positive or negative\n",
        "\"\"\"\n",
        "def compute_problematic_opt(temp2, temp_g, names, label, lst_of_counts):\n",
        "    need_pos = []\n",
        "    need_neg = []\n",
        "    for index, row in temp_g.iterrows():\n",
        "        group_lst = []\n",
        "        for n in names:\n",
        "            group_lst.append(row[n])\n",
        "        problematic = determine_problematic_opt(group_lst, names, temp2, lst_of_counts,label)\n",
        "        if(problematic == 1):\n",
        "            if group_lst not in need_neg:\n",
        "                need_neg.append(group_lst)\n",
        "        if(problematic == 2):\n",
        "            if group_lst not in need_pos:\n",
        "                need_pos.append(group_lst)\n",
        "    return need_pos, need_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "tZd2c6PAhtTH"
      },
      "outputs": [],
      "source": [
        "# build the list of X00\n",
        "def compute_lst_of_counts(temp, names, label):\n",
        "    # get the list of group-by attributes\n",
        "    lst_of_counts = []\n",
        "    for i in range(len(names)):\n",
        "        grp_names = copy.copy(names)\n",
        "        del grp_names[i]\n",
        "        grp_names.append(label)\n",
        "        temp_df = temp.groupby(grp_names)['cnt'].count()\n",
        "        lst_of_counts.append(temp_df)\n",
        "    return lst_of_counts\n",
        "    \n",
        "def get_tuple(group_lst):\n",
        "    return tuple(group_lst) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnQ09ffAkalO"
      },
      "source": [
        "# Preferential Sampling "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################\n",
        "\n",
        "#  Preferential Sampling Algorithm\n",
        "\n",
        "#####################################\n",
        "def pref_sampling_opt(train_set, cols_given, label, need_pos, need_neg):\n",
        "    if len(need_pos)+ len(need_neg) > 0:\n",
        "        temp_train_x = pd.DataFrame(train_set, columns = columns_all)\n",
        "        temp_train_label = pd.DataFrame(train_set, columns = [label])\n",
        "        temp_train_label = temp_train_label[label]\n",
        "        temp_train_label = temp_train_label.astype('int')\n",
        "        mnb = MultinomialNB()\n",
        "        mnb = mnb.fit(temp_train_x, temp_train_label)\n",
        "        probs = mnb.predict_proba(temp_train_x)[:,0]\n",
        "        train_set[\"prob\"] = abs(probs - 0.5)\n",
        "    new_train_set = pd.DataFrame(columns = list(train_set.columns))\n",
        "    updated_pos = 0\n",
        "    for i in need_pos:\n",
        "        # needs to updated more positive records\n",
        "        temp_df = copy.deepcopy(train_set)\n",
        "        for n in range(len(i)):\n",
        "          temp_df = temp_df[temp_df[cols_given[n]] == i[n]]\n",
        "        # update the skew and diff\n",
        "        idx = list(temp_df.index)\n",
        "        train_set.loc[idx, 'skewed'] = 1\n",
        "        idx_pos = list(temp_df[(getattr(temp_df, label) == 1)].index)\n",
        "        if(len(idx_pos) == 0):\n",
        "          # if there is no positive\n",
        "          idx_neg = list(temp_df[(getattr(temp_df, label) == 0)].index)\n",
        "          neg_ranked = train_set.loc[idx_neg].sort_values(by=\"prob\", ascending=True)\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          continue\n",
        "        idx_neg = list(temp_df[(getattr(temp_df, label) == 0)].index)\n",
        "        pos_ranked = train_set.loc[idx_pos].sort_values(by=\"prob\", ascending=True)\n",
        "        neg_ranked = train_set.loc[idx_neg].sort_values(by=\"prob\", ascending=True)\n",
        "        diff = compute_diff_add_and_remove(i, temp2,  1, compas_y, names)\n",
        "        if diff == -1:\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          continue\n",
        "        train_set.loc[idx, 'diff'] = int(diff)\n",
        "        cnt = int(train_set.loc[idx_pos[0]][\"diff\"])\n",
        "        updated_pos += cnt * 2 \n",
        "        # add more records when there are not enough available records\n",
        "        new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "        temp_cnt = cnt\n",
        "        if len(pos_ranked) >= temp_cnt:\n",
        "            new_train_set = pd.concat([new_train_set,pos_ranked[0:cnt]], ignore_index=True)\n",
        "        else:\n",
        "            while(temp_cnt > 0 ):\n",
        "                new_train_set = pd.concat([new_train_set,pos_ranked[0:temp_cnt]], ignore_index=True) \n",
        "            # duplicate the dataframe\n",
        "                temp_cnt = temp_cnt - len(pos_ranked)\n",
        "        # duplicate the top cnt records from the pos\n",
        "        # remove the top cnt records from the neg\n",
        "        if cnt == 0:\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "        else:\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked[cnt-1:-1]], ignore_index=True)\n",
        "    print(\"updated {} positive records\".format(str(updated_pos)))\n",
        "    updated_neg = 0\n",
        "    # adding more records to the need_neg set\n",
        "    for i in need_neg:\n",
        "        # list of idx belongs to this group\n",
        "        temp_df = copy.deepcopy(train_set)\n",
        "        for n in range(len(i)):\n",
        "          temp_df = temp_df[temp_df[cols_given[n]] == i[n]]\n",
        "        # update the skew and diff\n",
        "        idx = list(temp_df.index)\n",
        "        train_set.loc[idx, 'skewed'] = 1\n",
        "        idx_pos = list(temp_df[(getattr(temp_df, label) == 1)].index)\n",
        "        idx_neg = list(temp_df[(getattr(temp_df, label) == 0)].index)\n",
        "        if(len(idx_neg) == 0):\n",
        "          pos_ranked = train_set.loc[idx_pos].sort_values(by=\"prob\", ascending=True)\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          continue\n",
        "        pos_ranked = train_set.loc[idx_pos].sort_values(by=\"prob\", ascending=True)\n",
        "        neg_ranked = train_set.loc[idx_neg].sort_values(by=\"prob\", ascending=True)\n",
        "        diff = compute_diff_add_and_remove(i, temp2, 0, compas_y, names)\n",
        "        if diff == -1:\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          continue\n",
        "        train_set.loc[idx, 'diff'] = int(diff)\n",
        "        cnt = int(train_set.loc[idx_pos[0]][\"diff\"])\n",
        "        updated_neg += cnt * 2 \n",
        "        # add more records when there are not enough available records\n",
        "        new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "        temp_cnt = cnt\n",
        "        if len(neg_ranked) >= temp_cnt:\n",
        "            new_train_set = pd.concat([new_train_set,neg_ranked[0:cnt]], ignore_index=True)\n",
        "        else:\n",
        "            while(temp_cnt > 0 ):\n",
        "                new_train_set = pd.concat([new_train_set,neg_ranked[0:temp_cnt]], ignore_index=True) \n",
        "            # duplicate the dataframe\n",
        "                temp_cnt = temp_cnt - len(neg_ranked)\n",
        "        # duplicate the top cnt records from the pos\n",
        "        # remove the top cnt records from the neg\n",
        "        if cnt ==0:\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)       \n",
        "        else:\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked[cnt-1:-1]], ignore_index=True)\n",
        "   \n",
        "    print(\"updated {} negative records\".format(str(updated_neg)))\n",
        "    # add the other irrelavant items:\n",
        "    idx_irr = list(train_set[train_set['skewed'] == 0].index)\n",
        "    irr_df = train_set.loc[idx_irr]\n",
        "    new_train_set = pd.concat([new_train_set, irr_df], ignore_index=True)\n",
        "    print(\"The new dataset contains {} rows.\".format(str(len(new_train_set))))\n",
        "    new_train_set.reset_index()\n",
        "    return new_train_set\n",
        "\n"
      ],
      "metadata": {
        "id": "LCr5MK4oTmKI"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGdoCnWLlkc4"
      },
      "source": [
        "## Run Algorithm Lattice\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfMMRp-S4vTL",
        "outputId": "b0d15a3d-7031-4557-cc52-68f134996d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "//////63///////\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1], [0, 1, 0, 1, 2, 1], [1, 1, 0, 0, 1, 1]]\n",
            "[[0, 1, 0, 0, 2, 1], [0, 1, 1, 0, 2, 1], [0, 1, 1, 0, 2, 2], [0, 2, 0, 0, 1, 1], [0, 2, 1, 0, 0, 1], [1, 1, 0, 0, 2, 1], [1, 1, 0, 0, 2, 2], [2, 1, 0, 0, 2, 1]]\n",
            "started pref sampling\n",
            "updated 104 positive records\n",
            "updated 218 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2400\n",
            "1    1921\n",
            "Name: class, dtype: int64\n",
            "//////62///////\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 1, 2]]\n",
            "[[0, 0, 0, 2, 2], [1, 0, 0, 2, 2], [1, 0, 1, 1, 2], [1, 0, 1, 2, 1], [1, 1, 0, 2, 1], [2, 0, 0, 1, 2], [2, 0, 0, 2, 1], [2, 1, 0, 1, 1]]\n",
            "started pref sampling\n",
            "updated 24 positive records\n",
            "updated 142 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2459\n",
            "1    1862\n",
            "Name: class, dtype: int64\n",
            "//////61///////\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 0, 1]]\n",
            "[[1, 0, 0, 1, 1], [1, 0, 0, 2, 1], [1, 0, 0, 2, 2], [1, 1, 0, 2, 1], [2, 0, 0, 2, 1]]\n",
            "started pref sampling\n",
            "updated 18 positive records\n",
            "updated 66 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2483\n",
            "1    1838\n",
            "Name: class, dtype: int64\n",
            "//////60///////\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1, 0, 1], [1, 0, 0, 2, 1]]\n",
            "[[0, 0, 0, 2, 1], [0, 1, 1, 1, 2], [0, 2, 1, 0, 1], [1, 1, 0, 2, 1], [1, 2, 0, 1, 1], [2, 1, 0, 2, 1]]\n",
            "started pref sampling\n",
            "updated 40 positive records\n",
            "updated 102 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2514\n",
            "1    1807\n",
            "Name: class, dtype: int64\n",
            "//////59///////\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 0, 0, 3], [0, 2, 0, 1, 2], [1, 0, 0, 2, 1], [1, 1, 1, 2, 1]]\n",
            "[[0, 2, 1, 1, 1], [1, 1, 0, 2, 1]]\n",
            "started pref sampling\n",
            "updated 54 positive records\n",
            "updated 48 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2511\n",
            "1    1810\n",
            "Name: class, dtype: int64\n",
            "//////58///////\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 0, 0, 0], [0, 1, 1, 0, 0], [1, 0, 0, 0, 1]]\n",
            "[[0, 2, 0, 0, 3], [0, 2, 0, 1, 1], [0, 2, 1, 0, 2], [1, 2, 0, 0, 1]]\n",
            "started pref sampling\n",
            "updated 30 positive records\n",
            "updated 44 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2518\n",
            "1    1803\n",
            "Name: class, dtype: int64\n",
            "//////57///////\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 0, 0, 1], [2, 0, 0, 0, 2]]\n",
            "[[0, 1, 0, 1, 2], [0, 1, 1, 0, 2], [0, 2, 0, 0, 2], [1, 2, 0, 0, 1], [2, 1, 0, 0, 2]]\n",
            "started pref sampling\n",
            "updated 30 positive records\n",
            "updated 76 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2541\n",
            "1    1780\n",
            "Name: class, dtype: int64\n",
            "//////56///////\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1, 2], [0, 1, 2, 1]]\n",
            "[[0, 1, 2, 2]]\n",
            "started pref sampling\n",
            "updated 42 positive records\n",
            "updated 16 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2528\n",
            "1    1793\n",
            "Name: class, dtype: int64\n",
            "//////55///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 1, 0]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 10 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2533\n",
            "1    1788\n",
            "Name: class, dtype: int64\n",
            "//////54///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 1, 2], [0, 1, 2, 1], [2, 0, 1, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 62 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2564\n",
            "1    1757\n",
            "Name: class, dtype: int64\n",
            "//////53///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 0, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 132 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2630\n",
            "1    1691\n",
            "Name: class, dtype: int64\n",
            "//////52///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 0, 0, 2], [2, 1, 0, 0]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 38 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2649\n",
            "1    1672\n",
            "Name: class, dtype: int64\n",
            "//////51///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 2, 1], [1, 0, 2, 2]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 68 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2683\n",
            "1    1638\n",
            "Name: class, dtype: int64\n",
            "//////50///////\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 2, 2], [1, 1, 2, 1]]\n",
            "[[0, 0, 2, 2], [1, 0, 2, 1]]\n",
            "started pref sampling\n",
            "updated 36 positive records\n",
            "updated 82 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2706\n",
            "1    1615\n",
            "Name: class, dtype: int64\n",
            "//////49///////\n",
            "The sets of need pos and neg are\n",
            "[[1, 1, 0, 1]]\n",
            "[[1, 1, 0, 2]]\n",
            "started pref sampling\n",
            "updated 20 positive records\n",
            "updated 20 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2706\n",
            "1    1615\n",
            "Name: class, dtype: int64\n",
            "//////48///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 1, 2], [1, 1, 0, 1], [2, 0, 0, 2]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 72 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2742\n",
            "1    1579\n",
            "Name: class, dtype: int64\n",
            "//////47///////\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 0, 0], [1, 0, 2, 1]]\n",
            "[[0, 0, 2, 1], [0, 2, 0, 3], [1, 1, 0, 2], [1, 1, 2, 1], [2, 1, 2, 1]]\n",
            "started pref sampling\n",
            "updated 52 positive records\n",
            "updated 90 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2761\n",
            "1    1560\n",
            "Name: class, dtype: int64\n",
            "//////46///////\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 1], [1, 0, 0, 1]]\n",
            "[[1, 0, 1, 1], [1, 1, 0, 2], [1, 1, 1, 1]]\n",
            "started pref sampling\n",
            "updated 38 positive records\n",
            "updated 74 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2779\n",
            "1    1542\n",
            "Name: class, dtype: int64\n",
            "//////45///////\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 0, 2]]\n",
            "[[1, 0, 0, 1]]\n",
            "started pref sampling\n",
            "updated 18 positive records\n",
            "updated 16 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2778\n",
            "1    1543\n",
            "Name: class, dtype: int64\n",
            "//////44///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 1, 1], [1, 2, 0, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 26 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2791\n",
            "1    1530\n",
            "Name: class, dtype: int64\n",
            "//////43///////\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 0, 1], [1, 2, 0, 0], [2, 0, 0, 2]]\n",
            "[[0, 1, 1, 2], [1, 0, 0, 2], [1, 0, 1, 1]]\n",
            "started pref sampling\n",
            "updated 40 positive records\n",
            "updated 72 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2807\n",
            "1    1514\n",
            "Name: class, dtype: int64\n",
            "//////42///////\n",
            "The sets of need pos and neg are\n",
            "[[1, 1, 0, 1]]\n",
            "[[1, 0, 1, 0]]\n",
            "started pref sampling\n",
            "updated 14 positive records\n",
            "updated 10 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2805\n",
            "1    1516\n",
            "Name: class, dtype: int64\n",
            "//////41///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 2, 3], [1, 2, 1], [1, 2, 2]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 66 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2838\n",
            "1    1483\n",
            "Name: class, dtype: int64\n",
            "//////40///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 80 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2878\n",
            "1    1443\n",
            "Name: class, dtype: int64\n",
            "//////39///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 0]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 28 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2892\n",
            "1    1429\n",
            "Name: class, dtype: int64\n",
            "//////38///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 2]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 34 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2909\n",
            "1    1412\n",
            "Name: class, dtype: int64\n",
            "//////37///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2909\n",
            "1    1412\n",
            "Name: class, dtype: int64\n",
            "//////36///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2909\n",
            "1    1412\n",
            "Name: class, dtype: int64\n",
            "//////35///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 1, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 12 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2915\n",
            "1    1406\n",
            "Name: class, dtype: int64\n",
            "//////34///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2915\n",
            "1    1406\n",
            "Name: class, dtype: int64\n",
            "//////33///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2915\n",
            "1    1406\n",
            "Name: class, dtype: int64\n",
            "//////32///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2915\n",
            "1    1406\n",
            "Name: class, dtype: int64\n",
            "//////31///////\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 1]]\n",
            "[[1, 1, 2], [2, 1, 1]]\n",
            "started pref sampling\n",
            "updated 36 positive records\n",
            "updated 36 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2915\n",
            "1    1406\n",
            "Name: class, dtype: int64\n",
            "//////30///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 2]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 12 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2921\n",
            "1    1400\n",
            "Name: class, dtype: int64\n",
            "//////29///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 0]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 26 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2934\n",
            "1    1387\n",
            "Name: class, dtype: int64\n",
            "//////28///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2934\n",
            "1    1387\n",
            "Name: class, dtype: int64\n",
            "//////27///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2934\n",
            "1    1387\n",
            "Name: class, dtype: int64\n",
            "//////26///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2934\n",
            "1    1387\n",
            "Name: class, dtype: int64\n",
            "//////25///////\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 1]]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 32 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////24///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////23///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////22///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////21///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////20///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////19///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////18///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////17///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////16///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////15///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////14///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////13///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////12///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////11///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////10///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////9///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////8///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "//////7///////\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "  print(\"//////\"+str(a)+\"///////\")\n",
        "\n",
        "  # Group pre-processing methods\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "\n",
        "  #call opt identification function  \n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started pref sampling\")\n",
        "\n",
        "  #call opt preferential sampling algorithm\n",
        "  new_train_data = pref_sampling_opt(new_train_data, names, compas_y, need_pos, need_neg)\n",
        "\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "\n",
        "#create new dataframe using the results of preferential sampling \n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euVPjcb_lqe2"
      },
      "source": [
        "### Preferential Sampling Results Lattice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Lattice\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Lattice\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Preferential Sampling-Lattice\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDvLtC3BlDpa",
        "outputId": "d9ee332a-005f-44c6-87ee-505aeb90040b"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.6753066795118818\n",
            "fpr and fnr\n",
            "0.0\n",
            "1.0\n",
            "accuracy\n",
            "0.6661264181523501\n",
            "dfpr 0\n",
            "dfnr 0\n",
            "dacc 0.8613400089486869\n",
            "accuracy is  0.5510534846029174\n",
            "\n",
            "rf\n",
            "best 0.6387417041318775\n",
            "fpr and fnr\n",
            "0.0696078431372549\n",
            "0.9121540312876053\n",
            "accuracy\n",
            "0.5510534846029174\n",
            "dfpr 0.30472896327769233\n",
            "dfnr 0.589635534178638\n",
            "dacc 0.825726219798547\n",
            "accuracy is  0.5521339816315505\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.67530668        nan 0.67530668        nan 0.67530668\n",
            "        nan 0.67530668        nan 0.67530668]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.6753066795118818\n",
            "fpr and fnr\n",
            "0.0\n",
            "1.0\n",
            "accuracy\n",
            "0.5521339816315505\n",
            "dfpr 0\n",
            "dfnr 0\n",
            "dacc 0.8613400089486869\n",
            "accuracy is  0.5510534846029174\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.0\n",
            "1.0\n",
            "accuracy\n",
            "0.5510534846029174\n",
            "dfpr 0\n",
            "dfnr 0\n",
            "dacc 0.8613400089486869\n",
            "accuracy is  0.5510534846029174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaHdC0EaqzZz"
      },
      "source": [
        "## Run Algorithm Leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh523URuq7AD",
        "outputId": "8788c6a5-578f-4115-c40e-d0cf14243424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/////////////\n",
            "63\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1], [0, 1, 0, 1, 2, 1], [1, 1, 0, 0, 1, 1]]\n",
            "[[0, 1, 0, 0, 2, 1], [0, 1, 1, 0, 2, 1], [0, 1, 1, 0, 2, 2], [0, 2, 0, 0, 1, 1], [0, 2, 1, 0, 0, 1], [1, 1, 0, 0, 2, 1], [1, 1, 0, 0, 2, 2], [2, 1, 0, 0, 2, 1]]\n",
            "started pref sampling\n",
            "updated 104 positive records\n",
            "updated 218 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2400\n",
            "1    1921\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in [all_names_lst[0]]:\n",
        "  print(\"/////////////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  # only keep the records in temp_g that have a size > 30.\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "   \n",
        "  #id function\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started pref sampling\")\n",
        "\n",
        "  #pref sampling function\n",
        "  new_train_data = pref_sampling_opt(new_train_data, names, compas_y, need_pos, need_neg)\n",
        "\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27rcEGB9rhrf"
      },
      "source": [
        "### Preferential Sampling Results Leaf\n",
        "\n",
        "Output of all of the model results from Preferential Sampling-Leaf Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Leaf\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Leaf\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Leaf\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Preferential Sampling-Leaf\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-1zYQIWsDdn",
        "outputId": "87213c10-e28f-4eea-ff35-20da7660af2f"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.6253492292870906\n",
            "fpr and fnr\n",
            "0.19509803921568628\n",
            "0.48736462093862815\n",
            "accuracy\n",
            "0.5510534846029174\n",
            "dfpr 1.830902622725156\n",
            "dfnr 2.2985472926720902\n",
            "dacc 0.15384678248590786\n",
            "accuracy is  0.6736898973527823\n",
            "\n",
            "rf\n",
            "best 0.5785886319845857\n",
            "fpr and fnr\n",
            "0.2696078431372549\n",
            "0.4464500601684717\n",
            "accuracy\n",
            "0.6736898973527823\n",
            "dfpr 2.559271701477016\n",
            "dfnr 3.511384012793787\n",
            "dacc 0.19443371827864173\n",
            "accuracy is  0.6509994597514857\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.63552746        nan 0.63761106        nan 0.63761106\n",
            "        nan 0.63761106        nan 0.63761106]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.6376110575893813\n",
            "fpr and fnr\n",
            "0.23627450980392156\n",
            "0.4428399518652226\n",
            "accuracy\n",
            "0.6509994597514857\n",
            "dfpr 3.0514811651636378\n",
            "dfnr 3.156926896160785\n",
            "dacc 0.15150687306436472\n",
            "accuracy is  0.6709886547811994\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.24705882352941178\n",
            "0.43200962695547535\n",
            "accuracy\n",
            "0.6709886547811994\n",
            "dfpr 1.0969663472342601\n",
            "dfnr 2.8144272413525213\n",
            "dacc 0.15150745680127928\n",
            "accuracy is  0.6699081577525662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM1zX7q-ruBj"
      },
      "source": [
        "## Run Algorithm Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "Mzp7XkuksXyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113567e8-95cc-4874-c457-a5bf2ddc9775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/////////////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[[0, 0]]\n",
            "[[0, 2], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]]\n",
            "started pref sampling\n",
            "updated 256 positive records\n",
            "updated 422 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2426\n",
            "1    1895\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "8\n",
            "The sets of need pos and neg are\n",
            "[[0, 1], [2, 1]]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 302 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2275\n",
            "1    2046\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "9\n",
            "The sets of need pos and neg are\n",
            "[[0, 1]]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 254 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2173\n",
            "0    2148\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "10\n",
            "The sets of need pos and neg are\n",
            "[[0, 0], [1, 1], [2, 1], [2, 2]]\n",
            "[[0, 2], [1, 2]]\n",
            "started pref sampling\n",
            "updated 1166 positive records\n",
            "updated 812 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2350\n",
            "0    1971\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "11\n",
            "The sets of need pos and neg are\n",
            "[[0, 2], [0, 3], [1, 3]]\n",
            "[[0, 0], [0, 1], [2, 1]]\n",
            "started pref sampling\n",
            "updated 546 positive records\n",
            "updated 638 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2304\n",
            "0    2017\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "12\n",
            "The sets of need pos and neg are\n",
            "[[0, 1], [1, 0]]\n",
            "[[2, 0]]\n",
            "started pref sampling\n",
            "updated 514 positive records\n",
            "updated 220 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2451\n",
            "0    1870\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "13\n",
            "The sets of need pos and neg are\n",
            "[[1, 1], [2, 1]]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 230 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2566\n",
            "0    1755\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "14\n",
            "The sets of need pos and neg are\n",
            "[[0, 0], [0, 2], [1, 1], [2, 2]]\n",
            "[[0, 1], [1, 0], [1, 2], [2, 0]]\n",
            "started pref sampling\n",
            "updated 494 positive records\n",
            "updated 600 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2513\n",
            "0    1808\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "15\n",
            "The sets of need pos and neg are\n",
            "[[0, 1], [0, 3], [1, 1], [2, 0], [2, 2]]\n",
            "[[0, 0], [0, 2], [1, 2], [2, 3]]\n",
            "started pref sampling\n",
            "updated 350 positive records\n",
            "updated 330 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2523\n",
            "0    1798\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "16\n",
            "The sets of need pos and neg are\n",
            "[[0, 1], [1, 1]]\n",
            "[[1, 0]]\n",
            "started pref sampling\n",
            "updated 246 positive records\n",
            "updated 244 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2524\n",
            "0    1797\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "17\n",
            "The sets of need pos and neg are\n",
            "[[0, 1], [1, 0]]\n",
            "[[0, 0], [1, 1], [1, 2]]\n",
            "started pref sampling\n",
            "updated 542 positive records\n",
            "updated 470 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2560\n",
            "0    1761\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "18\n",
            "The sets of need pos and neg are\n",
            "[[0, 0], [0, 1], [0, 3], [1, 2], [1, 3]]\n",
            "[[0, 2], [1, 1]]\n",
            "started pref sampling\n",
            "updated 544 positive records\n",
            "updated 394 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2635\n",
            "0    1686\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "19\n",
            "The sets of need pos and neg are\n",
            "[[0, 1], [1, 0]]\n",
            "[[0, 0], [1, 1], [1, 2]]\n",
            "started pref sampling\n",
            "updated 418 positive records\n",
            "updated 320 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2684\n",
            "0    1637\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "20\n",
            "The sets of need pos and neg are\n",
            "[[0, 2]]\n",
            "[[0, 0], [1, 1], [1, 2], [1, 3]]\n",
            "started pref sampling\n",
            "updated 214 positive records\n",
            "updated 94 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2744\n",
            "0    1577\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "21\n",
            "The sets of need pos and neg are\n",
            "[[0, 2], [0, 3], [1, 0], [1, 1], [2, 0], [2, 1], [2, 3]]\n",
            "[[0, 0], [0, 1], [1, 2], [1, 3], [2, 2]]\n",
            "started pref sampling\n",
            "updated 980 positive records\n",
            "updated 1006 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "1    2731\n",
            "0    1590\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "# Uses helper function to find all names in top group\n",
        "all_names_lst_top = find_top(all_names)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst_top:\n",
        "  print(\"/////////////\")\n",
        "  print(a)\n",
        "\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  \n",
        "  # id function   \n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started pref sampling\")\n",
        "\n",
        "  # pref sampling function\n",
        "  new_train_data = pref_sampling_opt(new_train_data, names, compas_y, need_pos, need_neg)\n",
        "\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVRTFfXmr2NG"
      },
      "source": [
        "### Preferential Sampling Results Top"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Top\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Top\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Top\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Preferential Sampling-Top\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cjoGWE-sFf9",
        "outputId": "b4b264b1-6496-485b-8cd6-a2282b917e01"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.49393197388139587\n",
            "fpr and fnr\n",
            "1.0\n",
            "0.0\n",
            "accuracy\n",
            "0.6699081577525662\n",
            "dfpr 0\n",
            "dfnr 0\n",
            "dacc 1.0206966841700187\n",
            "accuracy is  0.44894651539708263\n",
            "\n",
            "rf\n",
            "best 0.42906658103189893\n",
            "fpr and fnr\n",
            "0.7362745098039216\n",
            "0.22021660649819494\n",
            "accuracy\n",
            "0.44894651539708263\n",
            "dfpr 1.7926356268395065\n",
            "dfnr 1.0308611976690114\n",
            "dacc 0.35809778819164434\n",
            "accuracy is  0.495407887628309\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.53580283        nan 0.46173196        nan 0.39969493\n",
            "        nan 0.39969493        nan 0.39969493]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.5358028259473346\n",
            "fpr and fnr\n",
            "0.9823529411764705\n",
            "0.006016847172081829\n",
            "accuracy\n",
            "0.495407887628309\n",
            "dfpr 0.02811516827152262\n",
            "dfnr 0.005421244405038754\n",
            "dacc 0.9706937800788688\n",
            "accuracy is  0.4559697460831983\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.7509803921568627\n",
            "0.17328519855595667\n",
            "accuracy\n",
            "0.4559697460831983\n",
            "dfpr 1.5872818502278114\n",
            "dfnr 0.8451614022635038\n",
            "dacc 0.5629494591823418\n",
            "accuracy is  0.5083738519719071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeNaCEQ26n7V"
      },
      "source": [
        "# Duplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "F-x05Dlbuc62"
      },
      "outputs": [],
      "source": [
        "def round_int(x):\n",
        "    if x in [float(\"-inf\"),float(\"inf\")]: return 0\n",
        "    return int(round(x))\n",
        "    \n",
        "\n",
        "def make_duplicate(d, group_lst, diff, label_y, names, need_positive_or_negative):\n",
        "\n",
        "    selected = copy.deepcopy(d)\n",
        "\n",
        "    for i in range(len(group_lst)):\n",
        "        att_name = names[i]\n",
        "        selected = selected[(selected[att_name] == group_lst[i])]\n",
        "    selected = selected[(selected[label_y] == need_positive_or_negative)]\n",
        "\n",
        "    if len(selected) == 0:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # randomly generated diff samples:\n",
        "    while(len(selected) < diff):\n",
        "        # duplicate the dataframe\n",
        "        select_copy = selected.copy(deep=True)\n",
        "        selected = pd.concat([selected, select_copy])\n",
        "\n",
        "        # the number needed is more than the not needed numbers.\n",
        "\n",
        "    generated = selected.sample(n = diff, replace = False, axis = 0)\n",
        "\n",
        "    return generated \n",
        "\n",
        "\n",
        "def naive_duplicate(d, temp2, names, need_pos, need_neg, label_y):\n",
        "    # add more records for all groups\n",
        "    # The smote algorithm to boost the coverage\n",
        "    for r in need_pos:\n",
        "   \n",
        "    # add more positive records\n",
        "        # determine how many points to add\n",
        " \n",
        "        diff = compute_diff_add(r, temp2, names, label_y, 1)\n",
        "        if diff == -1:\n",
        "          continue\n",
        "        diff = round_int(diff)\n",
        "        # add more records\n",
        "        print(\"Adding \" + str(diff) +\" positive records\")\n",
        "        samples_to_add = make_duplicate(d, r, diff, label_y, names, need_positive_or_negative = 1)\n",
        "        d = pd.concat([d, samples_to_add], ignore_index=True) \n",
        "    for k in need_neg:\n",
        "\n",
        "   \n",
        "        diff = compute_diff_add(k, temp2, names, label_y, need_positive_or_negative = 0)\n",
        "        if diff == -1:\n",
        "          continue\n",
        "        diff = round_int(diff)\n",
        "        print(\"Adding \" + str(diff) +\" negative records\")\n",
        "        samples_to_add = make_duplicate(d, k, diff, label_y, names, need_positive_or_negative = 0)\n",
        "        d = pd.concat([d, samples_to_add], ignore_index=True)\n",
        "    return d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_HqjDkKtclY"
      },
      "source": [
        "## Run Algorithm Lattice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "ptgbqFIO8PDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac37567-3b70-4f62-b9ae-b3efe5a13374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "63\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1], [0, 1, 0, 1, 2, 1], [1, 1, 0, 0, 1, 1]]\n",
            "[[0, 1, 0, 0, 2, 1], [0, 1, 1, 0, 2, 1], [0, 1, 1, 0, 2, 2], [0, 2, 0, 0, 1, 1], [0, 2, 1, 0, 0, 1], [1, 1, 0, 0, 2, 1], [1, 1, 0, 0, 2, 2], [2, 1, 0, 0, 2, 1]]\n",
            "0.432 3 40 14.2800000000000\n",
            "0.432 3 40 14.2800000000000\n",
            "Adding 14 positive records\n",
            "1.050420168067227 8 32 25.6134453781513\n",
            "1.050420168067227 8 32 25.6134453781513\n",
            "Adding 26 positive records\n",
            "0.9322429906542056 28 83 49.3761682242991\n",
            "0.9322429906542056 28 83 49.3761682242991\n",
            "Adding 49 positive records\n",
            "1.8057553956834533 27 22 12.7266187050360\n",
            "1.8057553956834533 27 22 12.7266187050360\n",
            "Adding 13 positive records\n",
            "1.306878306878307 17 18 6.52380952380953\n",
            "1.306878306878307 17 18 6.52380952380953\n",
            "Adding 7 positive records\n",
            "1.2645348837209303 187 74 73.8804597701150\n",
            "Adding 74 negative records\n",
            "1.3547008547008548 75 38 17.3627760252368\n",
            "Adding 17 negative records\n",
            "0.8894230769230769 23 8 17.8594594594595\n",
            "Adding 18 negative records\n",
            "1.0424710424710424 92 30 58.2518518518519\n",
            "Adding 58 negative records\n",
            "0.6716417910447762 22 18 14.7555555555556\n",
            "Adding 15 negative records\n",
            "2.3655172413793104 85 20 15.9329446064140\n",
            "Adding 16 negative records\n",
            "1.8256880733944953 28 6 9.33668341708543\n",
            "Adding 9 negative records\n",
            "2.7304347826086954 25 8 1.15605095541401\n",
            "Adding 1 negative records\n",
            "label y  0    2551\n",
            "1    2087\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "62\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 1, 2], [1, 0, 1, 1, 1]]\n",
            "[[0, 0, 0, 2, 2], [1, 0, 0, 2, 2], [1, 0, 1, 1, 2], [1, 0, 1, 2, 1], [1, 1, 0, 2, 1], [2, 0, 0, 1, 2], [2, 0, 0, 2, 1], [2, 1, 0, 1, 1]]\n",
            "0.7517241379310344 26 64 22.1103448275862\n",
            "0.7517241379310344 26 64 22.1103448275862\n",
            "Adding 22 positive records\n",
            "0.9527896995708155 23 36 11.3004291845494\n",
            "0.9527896995708155 23 36 11.3004291845494\n",
            "Adding 11 positive records\n",
            "0.9831932773109243 31 19 12.5299145299145\n",
            "Adding 13 negative records\n",
            "1.162471395881007 85 56 17.1200787401573\n",
            "Adding 17 negative records\n",
            "0.6598984771573604 25 18 19.8846153846154\n",
            "Adding 20 negative records\n",
            "1.32 56 26 16.4242424242424\n",
            "Adding 16 negative records\n",
            "1.1139896373056994 101 66 24.6651162790698\n",
            "Adding 25 negative records\n",
            "0.8947368421052632 38 25 17.4705882352941\n",
            "Adding 17 negative records\n",
            "1.3918269230769231 39 5 23.0207253886011\n",
            "Adding 23 negative records\n",
            "0.928 35 17 20.7155172413793\n",
            "Adding 21 negative records\n",
            "label y  0    2703\n",
            "1    2120\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "61\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 0, 1], [0, 0, 1, 1, 2]]\n",
            "[[0, 1, 1, 1, 2], [1, 0, 0, 1, 1], [1, 0, 0, 2, 1], [1, 1, 0, 1, 1], [2, 0, 0, 2, 1]]\n",
            "0.6916890080428955 13 46 18.8176943699732\n",
            "0.6916890080428955 13 46 18.8176943699732\n",
            "Adding 19 positive records\n",
            "0.717948717948718 19 46 14.0256410256410\n",
            "0.717948717948718 19 46 14.0256410256410\n",
            "Adding 14 positive records\n",
            "0.34210526315789475 17 26 23.6923076923077\n",
            "Adding 24 negative records\n",
            "1.1108312342569269 60 36 18.0136054421767\n",
            "Adding 18 negative records\n",
            "1.5192307692307692 113 60 14.3797468354430\n",
            "Adding 14 negative records\n",
            "0.9242424242424242 22 16 7.80327868852459\n",
            "Adding 8 negative records\n",
            "1.460144927536232 43 18 11.4491315136477\n",
            "Adding 11 negative records\n",
            "label y  0    2778\n",
            "1    2153\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "60\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 0, 0, 0]]\n",
            "[[0, 2, 0, 2, 1], [1, 0, 0, 1, 2], [1, 1, 0, 2, 1], [1, 2, 0, 1, 1], [2, 1, 0, 2, 1]]\n",
            "0.5 6 35 11.5000000000000\n",
            "0.5 6 35 11.5000000000000\n",
            "Adding 12 positive records\n",
            "1.0747474747474748 25 16 7.26127819548882\n",
            "Adding 7 negative records\n",
            "0.6909090909090909 23 23 10.2894736842105\n",
            "Adding 10 negative records\n",
            "1.2062146892655368 109 61 29.3653395784541\n",
            "Adding 29 negative records\n",
            "0.9517543859649122 40 25 17.0276497695853\n",
            "Adding 17 negative records\n",
            "1.3040752351097178 27 16 4.70432692307689\n",
            "Adding 5 negative records\n",
            "label y  0    2846\n",
            "1    2165\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "59\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 0, 0, 3], [2, 1, 0, 2, 1]]\n",
            "[[1, 1, 0, 2, 1]]\n",
            "0.6458333333333334 5 27 12.4375000000000\n",
            "0.6458333333333334 5 27 12.4375000000000\n",
            "Adding 12 positive records\n",
            "1.341726618705036 26 25 7.54316546762590\n",
            "1.341726618705036 26 25 7.54316546762590\n",
            "Adding 8 positive records\n",
            "1.1466275659824048 100 68 19.2122762148341\n",
            "Adding 19 negative records\n",
            "label y  0    2865\n",
            "1    2185\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "58\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1, 0, 0], [0, 1, 1, 1, 1]]\n",
            "[[0, 0, 0, 0, 1], [0, 2, 0, 0, 3], [0, 2, 0, 1, 1], [0, 2, 1, 0, 2], [1, 1, 0, 1, 1]]\n",
            "0.605080831408776 7 30 11.1524249422633\n",
            "0.605080831408776 7 30 11.1524249422633\n",
            "Adding 11 positive records\n",
            "0.6243654822335025 16 58 20.2131979695431\n",
            "0.6243654822335025 16 58 20.2131979695431\n",
            "Adding 20 positive records\n",
            "0.8773333333333333 77 64 23.7659574468085\n",
            "Adding 24 negative records\n",
            "0.9182389937106918 20 11 10.7808219178082\n",
            "Adding 11 negative records\n",
            "0.8478260869565217 37 29 14.6410256410256\n",
            "Adding 15 negative records\n",
            "0.5411471321695761 23 19 23.5023041474654\n",
            "Adding 24 negative records\n",
            "0.995575221238938 21 16 5.09333333333333\n",
            "Adding 5 negative records\n",
            "label y  0    2944\n",
            "1    2216\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "57\n",
            "The sets of need pos and neg are\n",
            "[[2, 0, 0, 0, 2]]\n",
            "[[0, 2, 0, 0, 2], [1, 0, 0, 0, 2], [2, 1, 0, 0, 2]]\n",
            "1.3247863247863247 18 19 7.17094017094017\n",
            "1.3247863247863247 18 19 7.17094017094017\n",
            "Adding 7 positive records\n",
            "1.053639846743295 36 26 8.16727272727273\n",
            "Adding 8 negative records\n",
            "1.01953125 32 23 8.38697318007663\n",
            "Adding 8 negative records\n",
            "1.139275766016713 49 26 17.0097799511004\n",
            "Adding 17 negative records\n",
            "label y  0    2977\n",
            "1    2223\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "56\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 1, 2, 2]]\n",
            "0.9712230215827338 25 14 11.7407407407407\n",
            "Adding 12 negative records\n",
            "label y  0    2989\n",
            "1    2223\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "55\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 2, 3], [1, 1, 2, 1], [2, 0, 0, 3], [2, 0, 1, 3]]\n",
            "1.0326460481099657 23 16 6.27287853577362\n",
            "Adding 6 negative records\n",
            "0.9886148007590133 67 44 23.7715930902112\n",
            "Adding 24 negative records\n",
            "0.6798561151079137 18 18 8.47619047619048\n",
            "Adding 8 negative records\n",
            "0.8823529411764706 18 15 5.40000000000000\n",
            "Adding 5 negative records\n",
            "label y  0    3032\n",
            "1    2223\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "54\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 1]]\n",
            "[]\n",
            "0.7327586206896551 10 24 7.58620689655172\n",
            "0.7327586206896551 10 24 7.58620689655172\n",
            "Adding 8 positive records\n",
            "label y  0    3032\n",
            "1    2231\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "53\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 1], [1, 1, 1, 2]]\n",
            "[]\n",
            "0.8082191780821918 10 26 11.0136986301370\n",
            "0.8082191780821918 10 26 11.0136986301370\n",
            "Adding 11 positive records\n",
            "0.5602094240837696 17 78 26.6963350785341\n",
            "0.5602094240837696 17 78 26.6963350785341\n",
            "Adding 27 positive records\n",
            "label y  0    3032\n",
            "1    2269\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "52\n",
            "The sets of need pos and neg are\n",
            "[[1, 1, 0, 0]]\n",
            "[]\n",
            "0.62125 50 169 54.9912499999999\n",
            "0.62125 50 169 54.9912499999999\n",
            "Adding 55 positive records\n",
            "label y  0    3032\n",
            "1    2324\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "51\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 2, 0], [0, 1, 2, 2], [1, 0, 2, 2]]\n",
            "0.9609665427509294 25 9 17.0154738878143\n",
            "Adding 17 negative records\n",
            "0.6611374407582938 21 19 12.7634408602151\n",
            "Adding 13 negative records\n",
            "0.9618320610687023 51 35 18.0238095238095\n",
            "Adding 18 negative records\n",
            "label y  0    3080\n",
            "1    2324\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "50\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 0]]\n",
            "[[1, 0, 0, 1], [2, 0, 1, 1]]\n",
            "0.7931034482758621 11 24 8.03448275862070\n",
            "0.7931034482758621 11 24 8.03448275862070\n",
            "Adding 8 positive records\n",
            "0.8641188959660298 25 21 7.93120393120392\n",
            "Adding 8 negative records\n",
            "0.8943820224719101 19 12 9.24371859296482\n",
            "Adding 9 negative records\n",
            "label y  0    3097\n",
            "1    2332\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "49\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 0, 2]]\n",
            "0.6548117154811716 36 32 22.9776357827476\n",
            "Adding 23 negative records\n",
            "label y  0    3120\n",
            "1    2332\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "48\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 1, 2], [1, 1, 0, 0]]\n",
            "0.9006410256410257 26 17 11.8683274021352\n",
            "Adding 12 negative records\n",
            "0.56640625 15 16 10.4827586206897\n",
            "Adding 10 negative records\n",
            "label y  0    3142\n",
            "1    2332\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "47\n",
            "The sets of need pos and neg are\n",
            "[[1, 1, 0, 1], [1, 1, 2, 2]]\n",
            "[]\n",
            "0.8609112709832134 10 26 12.3836930455636\n",
            "0.8609112709832134 10 26 12.3836930455636\n",
            "Adding 12 positive records\n",
            "1.0161290322580645 39 57 18.9193548387097\n",
            "1.0161290322580645 39 57 18.9193548387097\n",
            "Adding 19 positive records\n",
            "label y  0    3142\n",
            "1    2363\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "46\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 2, 0, 0], [2, 2, 0, 1]]\n",
            "0.754863813229572 21 19 8.81958762886598\n",
            "Adding 9 negative records\n",
            "0.9116883116883117 20 12 9.93732193732194\n",
            "Adding 10 negative records\n",
            "label y  0    3161\n",
            "1    2363\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "45\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0], [2, 2, 0, 1]]\n",
            "[[1, 2, 0, 0], [2, 0, 0, 2]]\n",
            "0.6254335260115607 58 185 57.7052023121387\n",
            "0.6254335260115607 58 185 57.7052023121387\n",
            "Adding 58 positive records\n",
            "0.948905109489051 17 27 8.62043795620437\n",
            "0.948905109489051 17 27 8.62043795620437\n",
            "Adding 9 positive records\n",
            "0.7628571428571429 21 19 8.52808988764044\n",
            "Adding 9 negative records\n",
            "0.9791666666666666 27 21 6.57446808510638\n",
            "Adding 7 negative records\n",
            "label y  0    3177\n",
            "1    2430\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "44\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0], [0, 0, 1, 2]]\n",
            "[[1, 2, 1, 1], [2, 2, 0, 1]]\n",
            "0.8046647230320699 13 27 8.72594752186588\n",
            "0.8046647230320699 13 27 8.72594752186588\n",
            "Adding 9 positive records\n",
            "0.5606060606060606 41 160 48.6969696969698\n",
            "0.5606060606060606 41 160 48.6969696969698\n",
            "Adding 49 positive records\n",
            "0.7692307692307693 17 15 7.10000000000000\n",
            "Adding 7 negative records\n",
            "0.8840970350404312 25 18 10.2774390243902\n",
            "Adding 10 negative records\n",
            "label y  0    3194\n",
            "1    2488\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "43\n",
            "The sets of need pos and neg are\n",
            "[[1, 2, 0, 0]]\n",
            "[[0, 1, 1, 2]]\n",
            "0.8368794326241135 15 29 9.26950354609930\n",
            "0.8368794326241135 15 29 9.26950354609930\n",
            "Adding 9 positive records\n",
            "0.7478368355995055 130 120 53.8347107438016\n",
            "Adding 54 negative records\n",
            "label y  0    3248\n",
            "1    2497\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "42\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 1]]\n",
            "[]\n",
            "0.7587412587412588 24 58 20.0069930069930\n",
            "0.7587412587412588 24 58 20.0069930069930\n",
            "Adding 20 positive records\n",
            "label y  0    3248\n",
            "1    2517\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "41\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 2]]\n",
            "[]\n",
            "0.6063348416289592 40 136 42.4615384615385\n",
            "0.6063348416289592 40 136 42.4615384615385\n",
            "Adding 42 positive records\n",
            "label y  0    3248\n",
            "1    2559\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "40\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 0]]\n",
            "[[0, 2, 0]]\n",
            "0.5610561056105611 9 51 19.6138613861386\n",
            "0.5610561056105611 9 51 19.6138613861386\n",
            "Adding 20 positive records\n",
            "1.0 28 15 13.0000000000000\n",
            "Adding 13 negative records\n",
            "label y  0    3261\n",
            "1    2579\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "39\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3261\n",
            "1    2579\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "38\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 2]]\n",
            "0.66 32 18 30.4848484848485\n",
            "Adding 30 negative records\n",
            "label y  0    3291\n",
            "1    2579\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "37\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 3]]\n",
            "[]\n",
            "0.6983240223463687 11 30 9.94972067039106\n",
            "0.6983240223463687 11 30 9.94972067039106\n",
            "Adding 10 positive records\n",
            "label y  0    3291\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "36\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 0, 0]]\n",
            "0.815406976744186 39 33 14.8288770053476\n",
            "Adding 15 negative records\n",
            "label y  0    3306\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "35\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3306\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "34\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3306\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "33\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3306\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "32\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3306\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "31\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3306\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "30\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 0]]\n",
            "0.849478390461997 20 16 7.54385964912281\n",
            "Adding 8 negative records\n",
            "label y  0    3314\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "29\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3314\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "28\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3314\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "27\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3314\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "26\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3314\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "25\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3314\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "24\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3314\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "23\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3314\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "22\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 2, 1]]\n",
            "0.6727272727272727 33 31 18.0540540540541\n",
            "Adding 18 negative records\n",
            "label y  0    3332\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "21\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3332\n",
            "1    2589\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "20\n",
            "The sets of need pos and neg are\n",
            "[[1, 0]]\n",
            "[]\n",
            "0.6905574516496018 13 34 10.4789533560865\n",
            "0.6905574516496018 13 34 10.4789533560865\n",
            "Adding 10 positive records\n",
            "label y  0    3332\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "19\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3332\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "18\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3332\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "17\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3332\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "16\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3332\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "15\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3332\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "14\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3332\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "13\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3332\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "12\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3332\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "11\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 2]]\n",
            "0.7101105845181674 40 38 18.3292547274750\n",
            "Adding 18 negative records\n",
            "label y  0    3350\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "10\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3350\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "9\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3350\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "8\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 1]]\n",
            "0.6282940360610264 20 21 10.8322295805740\n",
            "Adding 11 negative records\n",
            "label y  0    3361\n",
            "1    2599\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "label y  0    3361\n",
            "1    2599\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  \n",
        "  # id function   \n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  \n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        " \n",
        " # Duplication function\n",
        "  new_train_data = naive_duplicate(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        " \n",
        "  print(\"label y \", new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuQ3lc7aU9NG"
      },
      "source": [
        "### Duplication Results Lattice\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Lattice\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(\"fpr\", fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"PDuplication-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Lattice\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Duplication-Lattice\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb6cfa7-a1ac-4eb2-d006-0af81184b84f",
        "id": "TLygptJxkQ-G"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.507718120805369\n",
            "fpr and fnr\n",
            "0.12745098039215685\n",
            "0.6762936221419976\n",
            "accuracy\n",
            "0.5083738519719071\n",
            "dfpr 2.035272689711184\n",
            "dfnr 0.7195321917643135\n",
            "dacc 0.4175525604014481\n",
            "accuracy is  0.6261480280929227\n",
            "\n",
            "rf\n",
            "best 0.4656040268456376\n",
            "fpr and fnr\n",
            "fpr 0.1568627450980392\n",
            "0.717208182912154\n",
            "accuracy\n",
            "0.6261480280929227\n",
            "dfpr 1.8997780303865845\n",
            "dfnr 1.9662288417590035\n",
            "dacc 0.4921795306229842\n",
            "accuracy is  0.5915721231766613\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.50218121        nan 0.48372483        nan 0.48573826\n",
            "        nan 0.48573826        nan 0.48573826]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.5021812080536913\n",
            "fpr and fnr\n",
            "0.03333333333333333\n",
            "0.9157641395908543\n",
            "accuracy\n",
            "0.5915721231766613\n",
            "dfpr 1.0113248929155323\n",
            "dfnr 0.2790614844975958\n",
            "dacc 0.6562285750310619\n",
            "accuracy is  0.5705024311183144\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.09117647058823529\n",
            "0.7641395908543923\n",
            "accuracy\n",
            "0.5705024311183144\n",
            "dfpr 2.7064111994318636\n",
            "dfnr 0.5884226654913153\n",
            "dacc 0.5488723516221033\n",
            "accuracy is  0.6066990815775256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ4Kag3MuFuf"
      },
      "source": [
        "## Run Algorithm Leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "XWAzykiouMXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b31dcf-a005-4d32-9b41-ca281ef6d202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "63\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1], [0, 1, 0, 1, 2, 1], [1, 1, 0, 0, 1, 1]]\n",
            "[[0, 1, 0, 0, 2, 1], [0, 1, 1, 0, 2, 1], [0, 1, 1, 0, 2, 2], [0, 2, 0, 0, 1, 1], [0, 2, 1, 0, 0, 1], [1, 1, 0, 0, 2, 1], [1, 1, 0, 0, 2, 2], [2, 1, 0, 0, 2, 1]]\n",
            "0.432 3 40 14.2800000000000\n",
            "0.432 3 40 14.2800000000000\n",
            "Adding 14 positive records\n",
            "1.050420168067227 8 32 25.6134453781513\n",
            "1.050420168067227 8 32 25.6134453781513\n",
            "Adding 26 positive records\n",
            "0.9322429906542056 28 83 49.3761682242991\n",
            "0.9322429906542056 28 83 49.3761682242991\n",
            "Adding 49 positive records\n",
            "1.8057553956834533 27 22 12.7266187050360\n",
            "1.8057553956834533 27 22 12.7266187050360\n",
            "Adding 13 positive records\n",
            "1.306878306878307 17 18 6.52380952380953\n",
            "1.306878306878307 17 18 6.52380952380953\n",
            "Adding 7 positive records\n",
            "1.2645348837209303 187 74 73.8804597701150\n",
            "Adding 74 negative records\n",
            "1.3547008547008548 75 38 17.3627760252368\n",
            "Adding 17 negative records\n",
            "0.8894230769230769 23 8 17.8594594594595\n",
            "Adding 18 negative records\n",
            "1.0424710424710424 92 30 58.2518518518519\n",
            "Adding 58 negative records\n",
            "0.6716417910447762 22 18 14.7555555555556\n",
            "Adding 15 negative records\n",
            "2.3655172413793104 85 20 15.9329446064140\n",
            "Adding 16 negative records\n",
            "1.8256880733944953 28 6 9.33668341708543\n",
            "Adding 9 negative records\n",
            "2.7304347826086954 25 8 1.15605095541401\n",
            "Adding 1 negative records\n",
            "label y 0    2551\n",
            "1    2087\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in [all_names_lst[0]]:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  \n",
        "  #id function  \n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  \n",
        "  # Duplication Function\n",
        "  new_train_data = naive_duplicate(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "\n",
        "  print(\"label y\", new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyiaC-BPuT-N"
      },
      "source": [
        "### Duplication Results Leaf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Leaf\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(\"fpr\", fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Leaf\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Leaf\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Duplication-Leaf\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ebe3d16-7dbe-4015-d117-37ec29c78042",
        "id": "AQW6bGe3lKG3"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.6116590875274337\n",
            "fpr and fnr\n",
            "0.22156862745098038\n",
            "0.4681107099879663\n",
            "accuracy\n",
            "0.6066990815775256\n",
            "dfpr 1.8892362480592937\n",
            "dfnr 2.5165630964591306\n",
            "dacc 0.16207542990034735\n",
            "accuracy is  0.6677471636952999\n",
            "\n",
            "rf\n",
            "best 0.5905297957817208\n",
            "fpr and fnr\n",
            "fpr 0.27941176470588236\n",
            "0.4536702767749699\n",
            "accuracy\n",
            "0.6677471636952999\n",
            "dfpr 2.723390637653868\n",
            "dfnr 3.3508135325004695\n",
            "dacc 0.27655382740242024\n",
            "accuracy is  0.6423554835224203\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.63107005        nan 0.63106936        nan 0.63063809\n",
            "        nan 0.63063809        nan 0.63063809]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.6310700535654503\n",
            "fpr and fnr\n",
            "0.2284313725490196\n",
            "0.4584837545126354\n",
            "accuracy\n",
            "0.6423554835224203\n",
            "dfpr 3.2425214733366707\n",
            "dfnr 2.948308955897536\n",
            "dacc 0.15983738257037464\n",
            "accuracy is  0.6682874122096164\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.24509803921568626\n",
            "0.43561973525872444\n",
            "accuracy\n",
            "0.6682874122096164\n",
            "dfpr 1.5502220353138638\n",
            "dfnr 2.7784135633982134\n",
            "dacc 0.1540189848756683\n",
            "accuracy is  0.6693679092382496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ud6LiPvubLz"
      },
      "source": [
        "## Run Algorithm Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "itgAs3JCuj6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a748917-caf5-4029-9685-0f0c6a1d64d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[[0, 0]]\n",
            "[[0, 2], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]]\n",
            "0.842139175257732 190 506 236.122422680412\n",
            "0.842139175257732 190 506 236.122422680412\n",
            "Adding 236 positive records\n",
            "0.6729970326409496 386 332 241.553791887125\n",
            "Adding 242 negative records\n",
            "0.8258513931888545 276 174 160.200562324274\n",
            "Adding 160 negative records\n",
            "1.2990033222591362 109 58 25.9104859335036\n",
            "Adding 26 negative records\n",
            "0.583203732503888 28 27 21.0106666666667\n",
            "Adding 21 negative records\n",
            "0.8615733736762481 65 41 34.4433713784021\n",
            "Adding 34 negative records\n",
            "1.2838427947598254 31 12 12.1462585034013\n",
            "Adding 12 negative records\n",
            "Label y 0    2838\n",
            "1    2214\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "8\n",
            "The sets of need pos and neg are\n",
            "[[0, 1]]\n",
            "[]\n",
            "0.8696883852691218 514 938 301.767705382436\n",
            "0.8696883852691218 514 938 301.767705382436\n",
            "Adding 302 positive records\n",
            "Label y 0    2838\n",
            "1    2516\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "9\n",
            "The sets of need pos and neg are\n",
            "[[0, 1]]\n",
            "[]\n",
            "0.9776760160274757 284 549 252.744132799084\n",
            "0.9776760160274757 284 549 252.744132799084\n",
            "Adding 253 positive records\n",
            "Label y 0    2838\n",
            "1    2769\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "10\n",
            "The sets of need pos and neg are\n",
            "[[0, 0], [1, 1], [2, 1], [2, 2]]\n",
            "[[0, 2], [1, 2]]\n",
            "1.3870967741935485 563 1118 987.774193548388\n",
            "1.3870967741935485 563 1118 987.774193548388\n",
            "Adding 988 positive records\n",
            "1.0552486187845305 169 247 91.6464088397790\n",
            "1.0552486187845305 169 247 91.6464088397790\n",
            "Adding 92 positive records\n",
            "0.9805735430157262 37 72 33.6012950971323\n",
            "0.9805735430157262 37 72 33.6012950971323\n",
            "Adding 34 positive records\n",
            "2.0465549348230914 76 57 40.6536312849162\n",
            "2.0465549348230914 76 57 40.6536312849162\n",
            "Adding 41 positive records\n",
            "0.8168197196713388 804 312 672.305325443787\n",
            "Adding 672 negative records\n",
            "1.5040760869565217 247 135 29.2204155374889\n",
            "Adding 29 negative records\n",
            "Label y 1    3924\n",
            "0    3539\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "11\n",
            "The sets of need pos and neg are\n",
            "[[2, 3]]\n",
            "[[2, 1]]\n",
            "1.2216867469879518 16 20 8.43373493975904\n",
            "1.2216867469879518 16 20 8.43373493975904\n",
            "Adding 8 positive records\n",
            "1.1793383633197911 122 82 21.4478346456694\n",
            "Adding 21 negative records\n",
            "Label y 1    3932\n",
            "0    3560\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "12\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 1]]\n",
            "1.1845386533665836 388 232 95.5536842105273\n",
            "Adding 96 negative records\n",
            "Label y 1    3932\n",
            "0    3656\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "13\n",
            "The sets of need pos and neg are\n",
            "[[1, 0], [2, 1]]\n",
            "[[2, 0]]\n",
            "1.2391304347826086 1401 1563 535.760869565217\n",
            "1.2391304347826086 1401 1563 535.760869565217\n",
            "Adding 536 positive records\n",
            "1.3200677392040643 198 228 102.975444538527\n",
            "1.3200677392040643 198 228 102.975444538527\n",
            "Adding 103 positive records\n",
            "0.9587878787878787 849 603 282.493046776232\n",
            "Adding 282 negative records\n",
            "Label y 1    4571\n",
            "0    3938\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "14\n",
            "The sets of need pos and neg are\n",
            "[[0, 2]]\n",
            "[[0, 0]]\n",
            "1.2381289865343728 323 347 106.630758327427\n",
            "1.2381289865343728 323 347 106.630758327427\n",
            "Adding 107 positive records\n",
            "1.1271611823759062 409 262 100.858485898069\n",
            "Adding 101 negative records\n",
            "Label y 1    4678\n",
            "0    4039\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "15\n",
            "The sets of need pos and neg are\n",
            "[[2, 0], [2, 2]]\n",
            "[[0, 3]]\n",
            "1.0742904841402336 50 82 38.0918196994992\n",
            "1.0742904841402336 50 82 38.0918196994992\n",
            "Adding 38 positive records\n",
            "1.1295002686727567 274 334 103.253089736701\n",
            "1.1295002686727567 274 334 103.253089736701\n",
            "Adding 103 positive records\n",
            "1.117854001759015 116 81 22.7702596380798\n",
            "Adding 23 negative records\n",
            "Label y 1    4819\n",
            "0    4062\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "16\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "Label y 1    4819\n",
            "0    4062\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "17\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "Label y 1    4819\n",
            "0    4062\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "18\n",
            "The sets of need pos and neg are\n",
            "[[1, 0]]\n",
            "[]\n",
            "1.2600370599135269 110 119 39.9444101297097\n",
            "1.2600370599135269 110 119 39.9444101297097\n",
            "Adding 40 positive records\n",
            "Label y 1    4859\n",
            "0    4062\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "19\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "Label y 1    4859\n",
            "0    4062\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "20\n",
            "The sets of need pos and neg are\n",
            "[[0, 4], [1, 0]]\n",
            "[[1, 3]]\n",
            "1.1855670103092784 9 31 27.7525773195876\n",
            "1.1855670103092784 9 31 27.7525773195876\n",
            "Adding 28 positive records\n",
            "1.3060606060606061 42 45 16.7727272727273\n",
            "1.3060606060606061 42 45 16.7727272727273\n",
            "Adding 17 positive records\n",
            "1.1616438356164382 94 55 25.9198113207546\n",
            "Adding 26 negative records\n",
            "Label y 1    4904\n",
            "0    4088\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "21\n",
            "The sets of need pos and neg are\n",
            "[[0, 4], [2, 3]]\n",
            "[[2, 0]]\n",
            "1.2596336070751737 12 24 18.2312065698042\n",
            "1.2596336070751737 12 24 18.2312065698042\n",
            "Adding 18 positive records\n",
            "1.1969189551239117 71 87 33.1319490957803\n",
            "1.1969189551239117 71 87 33.1319490957803\n",
            "Adding 33 positive records\n",
            "1.194249649368864 80 45 21.9876688197301\n",
            "Adding 22 negative records\n",
            "Label y 1    4955\n",
            "0    4110\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "all_names_lst_top = find_top(all_names)\n",
        "for a in all_names_lst_top:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  \n",
        "  #id function    \n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  \n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  \n",
        "  # Duplication Results \n",
        "  new_train_data = naive_duplicate(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "\n",
        "  print(\"Label y\", new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtQcykniuqUC"
      },
      "source": [
        "### Duplication Results Top"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Top\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(\"fpr\", fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Top\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Top\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Duplication-Top\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2791415b-c128-48bd-e030-43736bc363de",
        "id": "brVNWNKQldJf"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.47038058466629895\n",
            "fpr and fnr\n",
            "0.6823529411764706\n",
            "0.3104693140794224\n",
            "accuracy\n",
            "0.6693679092382496\n",
            "dfpr 1.762707558633074\n",
            "dfnr 0.8907361768859389\n",
            "dacc 0.7432313515756959\n",
            "accuracy is  0.4846029173419773\n",
            "\n",
            "rf\n",
            "best 0.47159404302261443\n",
            "fpr and fnr\n",
            "fpr 0.7049019607843138\n",
            "0.28760529482551145\n",
            "accuracy\n",
            "0.4846029173419773\n",
            "dfpr 1.5938455018542461\n",
            "dfnr 0.8993106528485432\n",
            "dacc 0.7645345383998194\n",
            "accuracy is  0.48244192328471097\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.3885273         nan 0.37517926        nan 0.37661335\n",
            "        nan 0.37661335        nan 0.37661335]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.38852730281301706\n",
            "fpr and fnr\n",
            "0.9990196078431373\n",
            "0.0012033694344163659\n",
            "accuracy\n",
            "0.48244192328471097\n",
            "dfpr 0\n",
            "dfnr 0\n",
            "dacc 1.0636915347348272\n",
            "accuracy is  0.44894651539708263\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.8382352941176471\n",
            "0.13598074608904934\n",
            "accuracy\n",
            "0.44894651539708263\n",
            "dfpr 1.2650288664672282\n",
            "dfnr 0.767207659695063\n",
            "dacc 0.5742459359506347\n",
            "accuracy is  0.4770394381415451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SfzogxQ-Q5d"
      },
      "source": [
        "#Down-sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "h9m0e5GbVL-d"
      },
      "outputs": [],
      "source": [
        "def round_int(x):\n",
        "    if x in [float(\"-inf\"),float(\"inf\")]: return 0\n",
        "    return int(round(x))\n",
        "\n",
        "\n",
        "def make_remove(d, group_lst, diff, names, label_y, need_positive_or_negative):\n",
        "    temp = copy.deepcopy(d)\n",
        "    for i in range(len(group_lst)):\n",
        "        att_name = names[i]\n",
        "        temp = temp[(temp[att_name] == group_lst[i])]\n",
        "    temp = temp[(temp[label_y] == need_positive_or_negative)]\n",
        "    # randomly generated diff samples\n",
        "        #generated = temp\n",
        "        # the number needed is more than the not needed numbers.\n",
        "\n",
        "    if(diff>len(temp)):\n",
        "        diff = len(temp)\n",
        "    generated = temp.sample(n = diff, replace = False, axis = 0)\n",
        "    return generated.index\n",
        "\n",
        "\n",
        "def naive_downsampling(d, temp2, names, need_pos, need_neg, label_y):\n",
        "    # add more records for all groups\n",
        "    # The smote algorithm to boost the coverage\n",
        "    for r in need_pos:\n",
        "        print(\"removing more negative\")\n",
        "    # add more positive records\n",
        "        # determine how many points to add\n",
        "        print(r)\n",
        "        diff = compute_diff_remove(r, temp2, names, label_y, need_positive_or_negative = 1)\n",
        "        if diff == -1:\n",
        "          continue\n",
        "        diff = round_int(diff)\n",
        "        # add more records\n",
        "        print(\"Removed \" + str(diff) +\" negative records\")\n",
        "        samples_to_remove = make_remove(d, r, diff, names, label_y, need_positive_or_negative = 0)\n",
        "        d.drop(index  = samples_to_remove, inplace = True)\n",
        "    for k in need_neg:\n",
        "        print(k)\n",
        "        diff = compute_diff_remove(k, temp2, names, label_y, need_positive_or_negative = 0)\n",
        "        if diff == -1:\n",
        "          continue\n",
        "        diff = round_int(diff)\n",
        "        print(\"Removed \" + str(diff) +\" positive records\")\n",
        "        samples_to_remove = make_remove(d, k, diff, names, label_y, need_positive_or_negative = 1)\n",
        "        d.drop(index  = samples_to_remove, inplace = True)\n",
        "    return d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcUYj8wJwrHK"
      },
      "source": [
        "## Run Algorithm Lattice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "QTfYbyt4pcRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235d6621-5b33-4c1b-fa27-f3ef549454c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "63\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1], [0, 1, 0, 1, 2, 1], [1, 1, 0, 0, 1, 1]]\n",
            "[[0, 1, 0, 0, 2, 1], [0, 1, 1, 0, 2, 1], [0, 1, 1, 0, 2, 2], [0, 2, 0, 0, 1, 1], [0, 2, 1, 0, 0, 1], [1, 1, 0, 0, 2, 1], [1, 1, 0, 0, 2, 2], [2, 1, 0, 0, 2, 1]]\n",
            "removing more negative\n",
            "[0, 0, 0, 0, 0, 2]\n",
            "0.432 3 40 33.0555555555556\n",
            "Removed 33 negative records\n",
            "removing more negative\n",
            "[0, 0, 0, 0, 1, 1]\n",
            "1.050420168067227 8 32 24.3840000000000\n",
            "Removed 24 negative records\n",
            "removing more negative\n",
            "[0, 1, 0, 0, 0, 1]\n",
            "0.9322429906542056 28 83 52.9649122807018\n",
            "Removed 53 negative records\n",
            "removing more negative\n",
            "[0, 1, 0, 1, 2, 1]\n",
            "1.8057553956834533 27 22 7.04780876494024\n",
            "Removed 7 negative records\n",
            "removing more negative\n",
            "[1, 1, 0, 0, 1, 1]\n",
            "1.306878306878307 17 18 4.99190283400813\n",
            "Removed 5 negative records\n",
            "[0, 1, 0, 0, 2, 1]\n",
            "1.2645348837209303 187 74 93.4244186046514\n",
            "Removed 93 positive records\n",
            "[0, 1, 1, 0, 2, 1]\n",
            "1.3547008547008548 75 38 23.5213675213675\n",
            "Removed 24 positive records\n",
            "[0, 1, 1, 0, 2, 2]\n",
            "0.8894230769230769 23 8 15.8846153846154\n",
            "Removed 16 positive records\n",
            "[0, 2, 0, 0, 1, 1]\n",
            "1.0424710424710424 92 30 60.7258687258686\n",
            "Removed 61 positive records\n",
            "[0, 2, 1, 0, 0, 1]\n",
            "0.6716417910447762 22 18 9.91044776119403\n",
            "Removed 10 positive records\n",
            "[1, 1, 0, 0, 2, 1]\n",
            "2.3655172413793104 85 20 37.6896551724138\n",
            "Removed 38 positive records\n",
            "[1, 1, 0, 0, 2, 2]\n",
            "1.8256880733944953 28 6 17.0458715596330\n",
            "Removed 17 positive records\n",
            "[2, 1, 0, 0, 2, 1]\n",
            "2.7304347826086954 25 8 3.15652173913044\n",
            "Removed 3 positive records\n",
            "0    2221\n",
            "1    1716\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "62\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 1, 2]]\n",
            "[[0, 0, 0, 2, 2], [1, 0, 0, 2, 2], [1, 0, 1, 1, 2], [1, 0, 1, 2, 1], [1, 1, 0, 2, 1], [2, 0, 0, 1, 2], [2, 0, 0, 2, 1], [2, 1, 0, 1, 1]]\n",
            "removing more negative\n",
            "[0, 0, 0, 1, 2]\n",
            "0.7639484978540773 26 64 29.9662921348315\n",
            "Removed 30 negative records\n",
            "[0, 0, 0, 2, 2]\n",
            "1.0357142857142858 31 19 11.3214285714286\n",
            "Removed 11 positive records\n",
            "[1, 0, 0, 2, 2]\n",
            "1.0914634146341464 68 47 16.7012195121951\n",
            "Removed 17 positive records\n",
            "[1, 0, 1, 1, 2]\n",
            "0.6598984771573604 25 18 13.1218274111675\n",
            "Removed 13 positive records\n",
            "[1, 0, 1, 2, 1]\n",
            "1.2445652173913044 43 19 19.3532608695653\n",
            "Removed 19 positive records\n",
            "[1, 1, 0, 2, 1]\n",
            "1.0108303249097472 77 49 27.4693140794224\n",
            "Removed 27 positive records\n",
            "[2, 0, 0, 1, 2]\n",
            "0.8603773584905661 38 25 16.4905660377358\n",
            "Removed 16 positive records\n",
            "[2, 0, 0, 2, 1]\n",
            "1.4382022471910112 39 5 31.8089887640450\n",
            "Removed 32 positive records\n",
            "[2, 1, 0, 1, 1]\n",
            "0.9096045197740112 35 17 19.5367231638417\n",
            "Removed 20 positive records\n",
            "0    2191\n",
            "1    1561\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "61\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 0, 1]]\n",
            "[[0, 0, 0, 2, 1], [0, 1, 1, 1, 2], [1, 0, 0, 1, 1], [1, 0, 0, 2, 1], [1, 1, 0, 2, 1], [2, 0, 0, 2, 1]]\n",
            "removing more negative\n",
            "[0, 0, 1, 0, 1]\n",
            "0.5886287625418061 13 46 23.9147727272727\n",
            "Removed 24 negative records\n",
            "[0, 0, 0, 2, 1]\n",
            "1.0319634703196348 131 98 29.8675799086758\n",
            "Removed 30 positive records\n",
            "[0, 1, 1, 1, 2]\n",
            "0.3333333333333333 17 26 8.33333333333333\n",
            "Removed 8 positive records\n",
            "[1, 0, 0, 1, 1]\n",
            "1.051094890510949 53 31 20.4160583941606\n",
            "Removed 20 positive records\n",
            "[1, 0, 0, 2, 1]\n",
            "1.5606060606060606 67 33 15.5000000000000\n",
            "Removed 16 positive records\n",
            "[1, 1, 0, 2, 1]\n",
            "1.2758620689655173 27 16 6.58620689655173\n",
            "Removed 7 positive records\n",
            "[2, 0, 0, 2, 1]\n",
            "1.5286624203821657 37 17 11.0127388535032\n",
            "Removed 11 positive records\n",
            "0    2167\n",
            "1    1469\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "60\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 0, 2, 1], [0, 1, 1, 2, 1], [1, 1, 0, 2, 1], [1, 2, 0, 1, 1]]\n",
            "[0, 0, 0, 2, 1]\n",
            "0.8075313807531381 43 37 13.1213389121339\n",
            "Removed 13 positive records\n",
            "[0, 1, 1, 2, 1]\n",
            "0.7379912663755459 20 16 8.19213973799126\n",
            "Removed 8 positive records\n",
            "[1, 1, 0, 2, 1]\n",
            "1.053475935828877 48 31 15.3422459893048\n",
            "Removed 15 positive records\n",
            "[1, 2, 0, 1, 1]\n",
            "1.0267857142857142 21 14 6.62500000000000\n",
            "Removed 7 positive records\n",
            "0    2167\n",
            "1    1426\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "59\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 0, 0, 3], [0, 2, 0, 1, 2], [1, 1, 0, 1, 1]]\n",
            "[[0, 1, 0, 2, 2], [1, 1, 0, 2, 1]]\n",
            "removing more negative\n",
            "[0, 1, 0, 0, 3]\n",
            "0.5221238938053098 5 27 17.4237288135593\n",
            "Removed 17 negative records\n",
            "removing more negative\n",
            "[0, 2, 0, 1, 2]\n",
            "0.8440366972477065 11 23 9.96739130434783\n",
            "Removed 10 negative records\n",
            "removing more negative\n",
            "[1, 1, 0, 1, 1]\n",
            "0.9308755760368663 14 23 7.96039603960396\n",
            "Removed 8 negative records\n",
            "[0, 1, 0, 2, 2]\n",
            "0.7564935064935064 46 43 13.4707792207792\n",
            "Removed 13 positive records\n",
            "[1, 1, 0, 2, 1]\n",
            "0.9314285714285714 34 22 13.5085714285714\n",
            "Removed 14 positive records\n",
            "0    2132\n",
            "1    1399\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "58\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 2, 0, 0, 3], [0, 2, 0, 1, 1], [0, 2, 1, 0, 2], [2, 1, 0, 0, 1]]\n",
            "[0, 2, 0, 0, 3]\n",
            "0.8915094339622641 20 11 10.1933962264151\n",
            "Removed 10 positive records\n",
            "[0, 2, 0, 1, 1]\n",
            "0.6956521739130435 25 18 12.4782608695652\n",
            "Removed 12 positive records\n",
            "[0, 2, 1, 0, 2]\n",
            "0.5015105740181269 23 19 13.4712990936556\n",
            "Removed 13 positive records\n",
            "[2, 1, 0, 0, 1]\n",
            "0.9523809523809523 19 15 4.71428571428571\n",
            "Removed 5 positive records\n",
            "0    2132\n",
            "1    1359\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "57\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 1, 0, 1, 2], [0, 1, 1, 0, 2], [1, 0, 0, 0, 2], [2, 1, 0, 0, 2]]\n",
            "[0, 1, 0, 1, 2]\n",
            "0.7215189873417721 23 22 7.12658227848101\n",
            "Removed 7 positive records\n",
            "[0, 1, 1, 0, 2]\n",
            "0.5562632696390658 46 52 17.0743099787686\n",
            "Removed 17 positive records\n",
            "[1, 0, 0, 0, 2]\n",
            "1.0476190476190477 22 16 5.23809523809524\n",
            "Removed 5 positive records\n",
            "[2, 1, 0, 0, 2]\n",
            "0.9047619047619048 23 11 13.0476190476190\n",
            "Removed 13 positive records\n",
            "0    2132\n",
            "1    1317\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "56\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 1, 2, 2]]\n",
            "[0, 1, 2, 2]\n",
            "0.7096774193548387 18 14 8.06451612903226\n",
            "Removed 8 positive records\n",
            "0    2132\n",
            "1    1309\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "55\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 2, 3], [2, 0, 1, 2]]\n",
            "[1, 0, 2, 3]\n",
            "0.7254901960784313 19 16 7.39215686274510\n",
            "Removed 7 positive records\n",
            "[2, 0, 1, 2]\n",
            "0.773109243697479 30 27 9.12605042016806\n",
            "Removed 9 positive records\n",
            "0    2132\n",
            "1    1293\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "54\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1293\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "53\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1293\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "52\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1293\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "51\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 0, 1], [1, 0, 2, 2]]\n",
            "[1, 0, 0, 1]\n",
            "0.7411764705882353 22 20 7.17647058823529\n",
            "Removed 7 positive records\n",
            "[1, 0, 2, 2]\n",
            "0.8642533936651584 24 17 9.30769230769231\n",
            "Removed 9 positive records\n",
            "0    2132\n",
            "1    1277\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "50\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 2, 1]]\n",
            "[1, 1, 2, 1]\n",
            "0.7829457364341085 20 17 6.68992248062016\n",
            "Removed 7 positive records\n",
            "0    2132\n",
            "1    1270\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "49\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 0, 2]]\n",
            "[1, 1, 0, 2]\n",
            "0.49295774647887325 28 27 14.6901408450704\n",
            "Removed 15 positive records\n",
            "0    2132\n",
            "1    1255\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "48\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1255\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "47\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 2, 1], [1, 1, 0, 2]]\n",
            "[1, 0, 2, 1]\n",
            "0.7982456140350878 21 18 6.63157894736842\n",
            "Removed 7 positive records\n",
            "[1, 1, 0, 2]\n",
            "0.41263940520446096 13 18 5.57249070631970\n",
            "Removed 6 positive records\n",
            "0    2132\n",
            "1    1242\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "46\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 2, 0, 0], [1, 2, 0, 2]]\n",
            "[0, 2, 0, 0]\n",
            "0.677115987460815 17 17 5.48902821316614\n",
            "Removed 5 positive records\n",
            "[1, 2, 0, 2]\n",
            "0.7431693989071039 16 15 4.85245901639345\n",
            "Removed 5 positive records\n",
            "0    2132\n",
            "1    1232\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "45\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 1, 1, 2], [2, 0, 0, 2]]\n",
            "[0, 1, 1, 2]\n",
            "0.508274231678487 22 26 8.78486997635933\n",
            "Removed 9 positive records\n",
            "[2, 0, 0, 2]\n",
            "0.8108108108108109 18 15 5.83783783783784\n",
            "Removed 6 positive records\n",
            "0    2132\n",
            "1    1217\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "44\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1217\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "43\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1217\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "42\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1217\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "41\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 2, 0]]\n",
            "[0, 2, 0]\n",
            "0.6593886462882096 23 10 16.4061135371179\n",
            "Removed 16 positive records\n",
            "0    2132\n",
            "1    1201\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "40\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1201\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "39\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1201\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "38\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1201\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "37\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 1, 3]]\n",
            "[2, 1, 3]\n",
            "0.7582938388625592 17 14 6.38388625592417\n",
            "Removed 6 positive records\n",
            "0    2132\n",
            "1    1195\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "36\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1195\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "35\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 0, 0], [2, 0, 2]]\n",
            "[2, 0, 0]\n",
            "0.4687975646879756 131 168 52.2420091324201\n",
            "Removed 52 positive records\n",
            "[2, 0, 2]\n",
            "0.7758064516129032 20 13 9.91451612903226\n",
            "Removed 10 positive records\n",
            "0    2132\n",
            "1    1133\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "34\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1133\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "33\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1133\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "32\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1133\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "31\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 1, 1]]\n",
            "[2, 1, 1]\n",
            "0.7251908396946565 20 17 7.67175572519085\n",
            "Removed 8 positive records\n",
            "0    2132\n",
            "1    1125\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "30\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 1], [1, 1, 2]]\n",
            "[1, 1, 1]\n",
            "0.5537974683544303 20 23 7.26265822784810\n",
            "Removed 7 positive records\n",
            "[1, 1, 2]\n",
            "0.41379310344827586 18 24 8.06896551724138\n",
            "Removed 8 positive records\n",
            "0    2132\n",
            "1    1110\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "29\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2132\n",
            "1    1110\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "28\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0]]\n",
            "[]\n",
            "removing more negative\n",
            "[0, 0, 0]\n",
            "0.6290502793296089 26 81 39.6678507992895\n",
            "Removed 40 negative records\n",
            "0    2092\n",
            "1    1110\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "27\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1    1110\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "26\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1    1110\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "25\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1    1110\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "24\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1    1110\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "23\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1    1110\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "22\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 1]]\n",
            "[1, 0, 1]\n",
            "0.3306878306878307 15 23 7.39417989417990\n",
            "Removed 7 positive records\n",
            "0    2092\n",
            "1    1103\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "21\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1    1103\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "20\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1    1103\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "19\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1    1103\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "18\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1    1103\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "17\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1    1103\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "16\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0]]\n",
            "[0, 0]\n",
            "0.4078516902944384 665 914 292.223555070883\n",
            "Removed 292 positive records\n",
            "0    2092\n",
            "1     811\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "15\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1     811\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "14\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1     811\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "13\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1     811\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "12\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1     811\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "11\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1     811\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "10\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1     811\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "9\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1     811\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "8\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1     811\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2092\n",
            "1     811\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  \n",
        "  #id function   \n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  \n",
        "  #Down-sampling function\n",
        "  new_train_data = naive_downsampling(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "  \n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhS42vuGsI2q"
      },
      "source": [
        "### Down-sampling Results Lattice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Down Sampling-Lattice\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Down Sampling-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Down Sampling-Lattice\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Down Sampling-Lattice\",\"SVM\")"
      ],
      "metadata": {
        "id": "dbzCpafMsVko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd36d89d-d962-4780-9245-5f419f71955c"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.7206338655113063\n",
            "fpr and fnr\n",
            "0.0\n",
            "1.0\n",
            "accuracy\n",
            "0.4770394381415451\n",
            "dfpr 0\n",
            "dfnr 0\n",
            "dacc 0.8613400089486869\n",
            "accuracy is  0.5510534846029174\n",
            "\n",
            "rf\n",
            "best 0.7020274200249274\n",
            "fpr and fnr\n",
            "0.016666666666666666\n",
            "0.9771359807460891\n",
            "accuracy\n",
            "0.5510534846029174\n",
            "dfpr 0.044888568609463574\n",
            "dfnr 0.03148005823324494\n",
            "dacc 0.7904641321393582\n",
            "accuracy is  0.5521339816315505\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.72063387        nan 0.72063387        nan 0.72063387\n",
            "        nan 0.72063387        nan 0.72063387]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.7206338655113063\n",
            "fpr and fnr\n",
            "0.0\n",
            "1.0\n",
            "accuracy\n",
            "0.5521339816315505\n",
            "dfpr 0\n",
            "dfnr 0\n",
            "dacc 0.8613400089486869\n",
            "accuracy is  0.5510534846029174\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.0\n",
            "1.0\n",
            "accuracy\n",
            "0.5510534846029174\n",
            "dfpr 0\n",
            "dfnr 0\n",
            "dacc 0.8613400089486869\n",
            "accuracy is  0.5510534846029174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqfnIjDrwk9i"
      },
      "source": [
        "## Run Algorithm Leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "IvmlKdUqwl_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece7c986-6446-4c8e-a072-55bfcd01ed59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "63\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1], [0, 1, 0, 1, 2, 1], [1, 1, 0, 0, 1, 1]]\n",
            "[[0, 1, 0, 0, 2, 1], [0, 1, 1, 0, 2, 1], [0, 1, 1, 0, 2, 2], [0, 2, 0, 0, 1, 1], [0, 2, 1, 0, 0, 1], [1, 1, 0, 0, 2, 1], [1, 1, 0, 0, 2, 2], [2, 1, 0, 0, 2, 1]]\n",
            "removing more negative\n",
            "[0, 0, 0, 0, 0, 2]\n",
            "0.432 3 40 33.0555555555556\n",
            "Removed 33 negative records\n",
            "removing more negative\n",
            "[0, 0, 0, 0, 1, 1]\n",
            "1.050420168067227 8 32 24.3840000000000\n",
            "Removed 24 negative records\n",
            "removing more negative\n",
            "[0, 1, 0, 0, 0, 1]\n",
            "0.9322429906542056 28 83 52.9649122807018\n",
            "Removed 53 negative records\n",
            "removing more negative\n",
            "[0, 1, 0, 1, 2, 1]\n",
            "1.8057553956834533 27 22 7.04780876494024\n",
            "Removed 7 negative records\n",
            "removing more negative\n",
            "[1, 1, 0, 0, 1, 1]\n",
            "1.306878306878307 17 18 4.99190283400813\n",
            "Removed 5 negative records\n",
            "[0, 1, 0, 0, 2, 1]\n",
            "1.2645348837209303 187 74 93.4244186046514\n",
            "Removed 93 positive records\n",
            "[0, 1, 1, 0, 2, 1]\n",
            "1.3547008547008548 75 38 23.5213675213675\n",
            "Removed 24 positive records\n",
            "[0, 1, 1, 0, 2, 2]\n",
            "0.8894230769230769 23 8 15.8846153846154\n",
            "Removed 16 positive records\n",
            "[0, 2, 0, 0, 1, 1]\n",
            "1.0424710424710424 92 30 60.7258687258686\n",
            "Removed 61 positive records\n",
            "[0, 2, 1, 0, 0, 1]\n",
            "0.6716417910447762 22 18 9.91044776119403\n",
            "Removed 10 positive records\n",
            "[1, 1, 0, 0, 2, 1]\n",
            "2.3655172413793104 85 20 37.6896551724138\n",
            "Removed 38 positive records\n",
            "[1, 1, 0, 0, 2, 2]\n",
            "1.8256880733944953 28 6 17.0458715596330\n",
            "Removed 17 positive records\n",
            "[2, 1, 0, 0, 2, 1]\n",
            "2.7304347826086954 25 8 3.15652173913044\n",
            "Removed 3 positive records\n",
            "0    2221\n",
            "1    1716\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in [all_names_lst[0]]:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "\n",
        "  # id function \n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  \n",
        "  #Down-sampling function\n",
        "  new_train_data = naive_downsampling(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "  \n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-O26rF9xYc-"
      },
      "source": [
        "### Down-sampling Results Leaf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Down Sampling-Leaf\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Down Sampling-Leaf\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Down Sampling-Leaf\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Down Sampling-Leaf\",\"SVM\")"
      ],
      "metadata": {
        "id": "7HWsJpa-sgzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04d8c35-0c98-4fc8-a488-4a805f5bef05"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.6426202439386219\n",
            "fpr and fnr\n",
            "0.19509803921568628\n",
            "0.4897713598074609\n",
            "accuracy\n",
            "0.5510534846029174\n",
            "dfpr 1.830902622725156\n",
            "dfnr 2.272430033368377\n",
            "dacc 0.16091963080975125\n",
            "accuracy is  0.6726094003241491\n",
            "\n",
            "rf\n",
            "best 0.6271264004540793\n",
            "fpr and fnr\n",
            "0.28431372549019607\n",
            "0.44765342960288806\n",
            "accuracy\n",
            "0.6726094003241491\n",
            "dfpr 2.6686762557146304\n",
            "dfnr 3.4572695041471087\n",
            "dacc 0.29274581380368514\n",
            "accuracy is  0.6423554835224203\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.64515993        nan 0.64693658        nan 0.64769735\n",
            "        nan 0.64769735        nan 0.64769735]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.647697353569102\n",
            "fpr and fnr\n",
            "0.246078431372549\n",
            "0.4404332129963899\n",
            "accuracy\n",
            "0.6423554835224203\n",
            "dfpr 2.9184364873000423\n",
            "dfnr 3.010392566801359\n",
            "dacc 0.16855753646677485\n",
            "accuracy is  0.6666666666666666\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.24509803921568626\n",
            "0.43441636582430804\n",
            "accuracy\n",
            "0.6666666666666666\n",
            "dfpr 1.1265062029685533\n",
            "dfnr 2.7888665853963444\n",
            "dacc 0.15757948818531073\n",
            "accuracy is  0.6699081577525662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEjc2orXxeJU"
      },
      "source": [
        "## Run Algorithm Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "g1ttSPisxj-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "869b9862-6827-4b67-e11b-d312ee1b9121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[[0, 0]]\n",
            "[[0, 2], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]]\n",
            "removing more negative\n",
            "[0, 0]\n",
            "0.842139175257732 190 506 280.384085692425\n",
            "Removed 280 negative records\n",
            "[0, 2]\n",
            "0.6729970326409496 386 332 162.564985163205\n",
            "Removed 163 positive records\n",
            "[1, 1]\n",
            "0.8258513931888545 276 174 132.301857585139\n",
            "Removed 132 positive records\n",
            "[1, 2]\n",
            "1.2990033222591362 109 58 33.6578073089701\n",
            "Removed 34 positive records\n",
            "[2, 0]\n",
            "0.583203732503888 28 27 12.2534992223950\n",
            "Removed 12 positive records\n",
            "[2, 1]\n",
            "0.8615733736762481 65 41 29.6754916792739\n",
            "Removed 30 positive records\n",
            "[2, 2]\n",
            "1.2838427947598254 31 12 15.5938864628821\n",
            "Removed 16 positive records\n",
            "0    2063\n",
            "1    1591\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "8\n",
            "The sets of need pos and neg are\n",
            "[[0, 1]]\n",
            "[]\n",
            "removing more negative\n",
            "[0, 1]\n",
            "0.8658420551855376 388 714 265.881318681319\n",
            "Removed 266 negative records\n",
            "0    1797\n",
            "1    1591\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "9\n",
            "The sets of need pos and neg are\n",
            "[[0, 1]]\n",
            "[]\n",
            "removing more negative\n",
            "[0, 1]\n",
            "0.9559471365638766 187 329 133.382488479263\n",
            "Removed 133 negative records\n",
            "0    1664\n",
            "1    1591\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "10\n",
            "The sets of need pos and neg are\n",
            "[[0, 0], [2, 1], [2, 2]]\n",
            "[[0, 2]]\n",
            "removing more negative\n",
            "[0, 0]\n",
            "1.282184655396619 276 581 365.742393509128\n",
            "Removed 366 negative records\n",
            "removing more negative\n",
            "[2, 1]\n",
            "0.9088145896656535 20 40 17.9933110367893\n",
            "Removed 18 negative records\n",
            "removing more negative\n",
            "[2, 2]\n",
            "1.894736842105263 40 31 9.88888888888889\n",
            "Removed 10 negative records\n",
            "[0, 2]\n",
            "0.773552290406223 510 227 334.403630077788\n",
            "Removed 334 positive records\n",
            "0    1270\n",
            "1    1257\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "11\n",
            "The sets of need pos and neg are\n",
            "[[1, 3]]\n",
            "[]\n",
            "removing more negative\n",
            "[1, 3]\n",
            "0.9812834224598931 18 28 9.65667574931880\n",
            "Removed 10 negative records\n",
            "0    1260\n",
            "1    1257\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "12\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 0], [2, 1]]\n",
            "[2, 0]\n",
            "0.9348659003831418 221 167 64.8773946360153\n",
            "Removed 65 positive records\n",
            "[2, 1]\n",
            "1.10062893081761 78 40 33.9748427672956\n",
            "Removed 34 positive records\n",
            "0    1260\n",
            "1    1158\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "13\n",
            "The sets of need pos and neg are\n",
            "[[2, 1]]\n",
            "[[0, 1]]\n",
            "removing more negative\n",
            "[2, 1]\n",
            "1.0857142857142856 26 36 12.0526315789474\n",
            "Removed 12 negative records\n",
            "[0, 1]\n",
            "1.0466472303206997 38 22 14.9737609329446\n",
            "Removed 15 positive records\n",
            "0    1248\n",
            "1    1143\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "14\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0]]\n",
            "[0, 0]\n",
            "0.9540229885057471 47 30 18.3793103448276\n",
            "Removed 18 positive records\n",
            "0    1248\n",
            "1    1125\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "15\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 1]]\n",
            "[2, 1]\n",
            "0.9181669394435352 126 103 31.4288052373159\n",
            "Removed 31 positive records\n",
            "0    1248\n",
            "1    1094\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "16\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    1248\n",
            "1    1094\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "17\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    1248\n",
            "1    1094\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "18\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    1248\n",
            "1    1094\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "19\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    1248\n",
            "1    1094\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "20\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    1248\n",
            "1    1094\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "21\n",
            "The sets of need pos and neg are\n",
            "[[2, 3]]\n",
            "[]\n",
            "removing more negative\n",
            "[2, 3]\n",
            "1.0481012658227848 12 21 9.55072463768116\n",
            "Removed 10 negative records\n",
            "0    1238\n",
            "1    1094\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "all_names_lst_top = find_top(all_names)\n",
        "for a in all_names_lst_top:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  \n",
        "  # id function  \n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        " \n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  \n",
        "  # Down-sampling function\n",
        "  new_train_data = naive_downsampling(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQOAJrGyxrsr"
      },
      "source": [
        "### Down-sampling Results Top"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Down Sampling-Top\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Down Sampling-Top\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Down Sampling-Top\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Down Sampling-Top\",\"SVM\")"
      ],
      "metadata": {
        "id": "WyrmV-7cshtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70cb115c-30dc-4193-9ed0-292559d7e031"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.5634660098703256\n",
            "fpr and fnr\n",
            "0.05392156862745098\n",
            "0.8592057761732852\n",
            "accuracy\n",
            "0.6699081577525662\n",
            "dfpr 0.9104801161528263\n",
            "dfnr 0.28995383761466764\n",
            "dacc 0.4868152802477146\n",
            "accuracy is  0.5845488924905456\n",
            "\n",
            "rf\n",
            "best 0.5415849500510059\n",
            "fpr and fnr\n",
            "0.42254901960784313\n",
            "0.6546329723225031\n",
            "accuracy\n",
            "0.5845488924905456\n",
            "dfpr 1.2188209103874605\n",
            "dfnr 1.764597455353002\n",
            "dacc 0.2590951318968153\n",
            "accuracy is  0.473257698541329\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.53215576        nan 0.53087555        nan 0.5313029\n",
            "        nan 0.53087464        nan 0.53087464]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.5321557563114023\n",
            "fpr and fnr\n",
            "0.03725490196078431\n",
            "0.9253910950661853\n",
            "accuracy\n",
            "0.473257698541329\n",
            "dfpr 0.38911614211769197\n",
            "dfnr 0.4355413996347597\n",
            "dacc 0.7054288408648532\n",
            "accuracy is  0.5640194489465153\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.453921568627451\n",
            "0.6534296028880866\n",
            "accuracy\n",
            "0.5640194489465153\n",
            "dfpr 1.7393511410177387\n",
            "dfnr 2.4182032576591137\n",
            "dacc 0.3683096817729024\n",
            "accuracy is  0.45650999459751485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWbCzMkrnT-0"
      },
      "source": [
        "# Massaging "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "tINoeYnSnWn4"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "def round_int(x):\n",
        "    if x in [float(\"-inf\"),float(\"inf\")]: return 0\n",
        "    return int(round(x))\n",
        "\n",
        "def get_depromotion(d, diff, group_lst, names, label_y, flag_depro):\n",
        "\n",
        "    input_test = pd.DataFrame(d, columns = columns_compas)\n",
        "    clf = MultinomialNB()\n",
        "    temp_train_label = pd.DataFrame(d, columns = [label_y])\n",
        "    temp_train_label = temp_train_label[label_y]\n",
        "    temp_train_label = temp_train_label.astype('int')\n",
        "    clf = clf.fit(input_test, temp_train_label)\n",
        "    prob  = clf.predict_proba(input_test)[:,0]\n",
        "    select = copy.deepcopy(d)\n",
        "    select['prob'] = prob # the higher the probablity is, the more likely for it to be 0\n",
        "    # filter out those belongs to this group\n",
        "    for i in range(len(group_lst)):\n",
        "        att_name = names[i]\n",
        "        select = select[(select[att_name] == group_lst[i])]\n",
        "    select = select[(select[label_y] == flag_depro)]\n",
        "    # rank them according to the probability\n",
        "    # filp the records and remove the records from d\n",
        "    if (flag_depro == 0):\n",
        "        select.sort_values(by=\"prob\", ascending=True, inplace=True)\n",
        "        select[label_y] = 1\n",
        "    else:\n",
        "        select.sort_values(by=\"prob\", ascending=False, inplace=True)\n",
        "        select[label_y] = 0\n",
        "    head = select.head(diff)\n",
        "    index_list = []\n",
        "    index_list = list(head.index)\n",
        "    d.drop(index_list,inplace = True)\n",
        "    head.drop(columns = ['prob'],inplace = True)\n",
        "    return head\n",
        "\n",
        "\n",
        "\n",
        "def naive_massaging(d, temp2, names, need_pos, need_neg,label_y):\n",
        "    # add more records for all groups\n",
        "    # The smote algorithm to boost the coverage\n",
        "    for r in need_pos:\n",
        "        print(\"adding more positive\")\n",
        "    # add more positive records\n",
        "        # determine how many points to add\n",
        "        print(r)\n",
        "        diff = compute_diff_add_and_remove(r, temp2, 1, label_y, names)\n",
        "        diff =  round_int(diff)\n",
        "        # add more records\n",
        "        #0 for promotion\n",
        "        samples_to_add = get_depromotion(d, diff, r, names, label_y, flag_depro = 0)\n",
        "        print(\"Changed \" + str(len(samples_to_add)) +\" records\")\n",
        "        d = pd.concat([d, samples_to_add])\n",
        "        print(len(d))\n",
        "    for k in need_neg:\n",
        "        print(k)\n",
        "        print(\"adding more negative\")\n",
        "        diff = compute_diff_add_and_remove(k, temp2, 0, label_y, names)\n",
        "        diff =  round_int(diff)\n",
        "        #1 for demotion\n",
        "        samples_to_add = get_depromotion(d, diff, k, names, label_y, flag_depro = 1)\n",
        "        print(\"Changed \" + str(len(samples_to_add)) +\" records\")\n",
        "        d = pd.concat([d, samples_to_add])\n",
        "        print(len(d))\n",
        "    return d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6JgxVuTx8cj"
      },
      "source": [
        "## Run Algorithm Lattice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "8CvRKxY6ne5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8fb094e-b1c6-417f-8425-e579ac38e489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "63\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1], [0, 1, 0, 1, 2, 1], [1, 1, 0, 0, 1, 1]]\n",
            "[[0, 1, 0, 0, 2, 1], [0, 1, 1, 0, 2, 1], [0, 1, 1, 0, 2, 2], [0, 2, 0, 0, 1, 1], [0, 2, 1, 0, 0, 1], [1, 1, 0, 0, 2, 1], [1, 1, 0, 0, 2, 2], [2, 1, 0, 0, 2, 1]]\n",
            "adding more positive\n",
            "[0, 0, 0, 0, 0, 2]\n",
            "Changed 10 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 0, 0, 0, 1, 1]\n",
            "Changed 12 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 1, 0, 0, 0, 1]\n",
            "Changed 26 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 1, 0, 1, 2, 1]\n",
            "Changed 5 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 0, 0, 1, 1]\n",
            "Changed 3 records\n",
            "4321\n",
            "[0, 1, 0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 41 records\n",
            "4321\n",
            "[0, 1, 1, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "4321\n",
            "[0, 1, 1, 0, 2, 2]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "[0, 2, 0, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 30 records\n",
            "4321\n",
            "[0, 2, 1, 0, 0, 1]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "[1, 1, 0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 11 records\n",
            "4321\n",
            "[1, 1, 0, 0, 2, 2]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "[2, 1, 0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 1 records\n",
            "4321\n",
            "0    2400\n",
            "1    1921\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "62\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 1, 2]]\n",
            "[[0, 0, 0, 2, 2], [1, 0, 0, 2, 2], [1, 0, 1, 1, 2], [1, 0, 1, 2, 1], [1, 1, 0, 2, 1], [2, 0, 0, 1, 2], [2, 0, 0, 2, 1], [2, 1, 0, 1, 1]]\n",
            "adding more positive\n",
            "[0, 0, 0, 1, 2]\n",
            "Changed 12 records\n",
            "4321\n",
            "[0, 0, 0, 2, 2]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "[1, 0, 0, 2, 2]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "[1, 0, 1, 1, 2]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "[1, 0, 1, 2, 1]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "4321\n",
            "[1, 1, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 13 records\n",
            "4321\n",
            "[2, 0, 0, 1, 2]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "4321\n",
            "[2, 0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 13 records\n",
            "4321\n",
            "[2, 1, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "4321\n",
            "0    2464\n",
            "1    1857\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "61\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 0, 1], [0, 0, 1, 1, 2]]\n",
            "[[0, 1, 1, 1, 2], [1, 0, 0, 1, 1], [1, 0, 0, 1, 2], [1, 0, 0, 2, 1], [1, 0, 0, 2, 2], [1, 1, 0, 1, 1], [1, 1, 0, 2, 1], [2, 0, 0, 2, 1]]\n",
            "adding more positive\n",
            "[0, 0, 1, 0, 1]\n",
            "Changed 10 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 0, 1, 1, 2]\n",
            "Changed 7 records\n",
            "4321\n",
            "[0, 1, 1, 1, 2]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "4321\n",
            "[1, 0, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "[1, 0, 0, 1, 2]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "4321\n",
            "[1, 0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 13 records\n",
            "4321\n",
            "[1, 0, 0, 2, 2]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "[1, 1, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "[1, 1, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "[2, 0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "0    2505\n",
            "1    1816\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "60\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 0, 0, 0], [0, 1, 1, 0, 1], [1, 0, 0, 2, 1]]\n",
            "[[0, 0, 0, 2, 1], [0, 2, 1, 0, 1], [1, 1, 0, 2, 1], [1, 2, 0, 1, 1], [2, 1, 0, 2, 1]]\n",
            "adding more positive\n",
            "[0, 1, 0, 0, 0]\n",
            "Changed 7 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 1, 1, 0, 1]\n",
            "Changed 13 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 0, 2, 1]\n",
            "Changed 15 records\n",
            "4321\n",
            "[0, 0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "[0, 2, 1, 0, 1]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "[1, 1, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 22 records\n",
            "4321\n",
            "[1, 2, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 14 records\n",
            "4321\n",
            "[2, 1, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "0    2528\n",
            "1    1793\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "59\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 0, 0, 3], [0, 2, 0, 2, 1], [1, 1, 1, 2, 1]]\n",
            "[[0, 0, 0, 2, 1], [0, 1, 0, 0, 1], [0, 1, 1, 2, 2], [1, 0, 0, 2, 1], [1, 1, 0, 1, 2], [1, 1, 0, 2, 1], [1, 2, 0, 1, 1]]\n",
            "adding more positive\n",
            "[0, 1, 0, 0, 3]\n",
            "Changed 8 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 2, 0, 2, 1]\n",
            "Changed 3 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 1, 2, 1]\n",
            "Changed 17 records\n",
            "4321\n",
            "[0, 0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "[0, 1, 0, 0, 1]\n",
            "adding more negative\n",
            "Changed 14 records\n",
            "4321\n",
            "[0, 1, 1, 2, 2]\n",
            "adding more negative\n",
            "Changed 4 records\n",
            "4321\n",
            "[1, 0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 3 records\n",
            "4321\n",
            "[1, 1, 0, 1, 2]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "[1, 1, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 24 records\n",
            "4321\n",
            "[1, 2, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 4 records\n",
            "4321\n",
            "0    2559\n",
            "1    1762\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "58\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1, 0, 0], [1, 1, 0, 1, 1]]\n",
            "[[0, 0, 0, 0, 1], [0, 2, 0, 0, 3], [0, 2, 0, 1, 1], [0, 2, 1, 0, 2], [1, 1, 0, 0, 1], [1, 2, 0, 0, 1]]\n",
            "adding more positive\n",
            "[0, 1, 1, 0, 0]\n",
            "Changed 6 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 0, 1, 1]\n",
            "Changed 12 records\n",
            "4321\n",
            "[0, 0, 0, 0, 1]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "4321\n",
            "[0, 2, 0, 0, 3]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "[0, 2, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 11 records\n",
            "4321\n",
            "[0, 2, 1, 0, 2]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "4321\n",
            "[1, 1, 0, 0, 1]\n",
            "adding more negative\n",
            "Changed 13 records\n",
            "4321\n",
            "[1, 2, 0, 0, 1]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "0    2595\n",
            "1    1726\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "57\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0, 0], [0, 0, 1, 0, 2], [0, 2, 0, 1, 0], [1, 0, 0, 0, 1], [1, 1, 0, 0, 0], [2, 0, 0, 0, 2]]\n",
            "[[0, 1, 0, 1, 2], [0, 2, 0, 0, 2], [0, 2, 0, 1, 1], [1, 0, 0, 0, 2], [1, 1, 0, 0, 2], [1, 2, 0, 0, 1], [2, 1, 0, 0, 2]]\n",
            "adding more positive\n",
            "[0, 0, 0, 0, 0]\n",
            "Changed 15 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 0, 1, 0, 2]\n",
            "Changed 7 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 2, 0, 1, 0]\n",
            "Changed 7 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 0, 0, 1]\n",
            "Changed 13 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 0, 0, 0]\n",
            "Changed 9 records\n",
            "4321\n",
            "adding more positive\n",
            "[2, 0, 0, 0, 2]\n",
            "Changed 6 records\n",
            "4321\n",
            "[0, 1, 0, 1, 2]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "[0, 2, 0, 0, 2]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "[0, 2, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "4321\n",
            "[1, 0, 0, 0, 2]\n",
            "adding more negative\n",
            "Changed 4 records\n",
            "4321\n",
            "[1, 1, 0, 0, 2]\n",
            "adding more negative\n",
            "Changed 16 records\n",
            "4321\n",
            "[1, 2, 0, 0, 1]\n",
            "adding more negative\n",
            "Changed 11 records\n",
            "4321\n",
            "[2, 1, 0, 0, 2]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "0    2598\n",
            "1    1723\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "56\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 2, 3], [0, 1, 0, 1], [1, 0, 0, 0], [1, 0, 1, 1]]\n",
            "[[0, 0, 0, 0], [0, 0, 2, 1], [0, 1, 2, 2]]\n",
            "adding more positive\n",
            "[0, 0, 2, 3]\n",
            "Changed 12 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 1, 0, 1]\n",
            "Changed 10 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 0, 0]\n",
            "Changed 8 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 1, 1]\n",
            "Changed 23 records\n",
            "4321\n",
            "[0, 0, 0, 0]\n",
            "adding more negative\n",
            "Changed 16 records\n",
            "4321\n",
            "[0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 72 records\n",
            "4321\n",
            "[0, 1, 2, 2]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "4321\n",
            "0    2640\n",
            "1    1681\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "55\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 2, 1]]\n",
            "[[1, 0, 2, 3], [1, 1, 2, 1], [2, 0, 2, 1]]\n",
            "adding more positive\n",
            "[0, 0, 2, 1]\n",
            "Changed 20 records\n",
            "4321\n",
            "[1, 0, 2, 3]\n",
            "adding more negative\n",
            "Changed 3 records\n",
            "4321\n",
            "[1, 1, 2, 1]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "4321\n",
            "[2, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "4321\n",
            "0    2642\n",
            "1    1679\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "54\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1, 1]]\n",
            "[[0, 0, 1, 1], [1, 0, 0, 0], [2, 1, 1, 1]]\n",
            "adding more positive\n",
            "[0, 1, 1, 1]\n",
            "Changed 5 records\n",
            "4321\n",
            "[0, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "4321\n",
            "[1, 0, 0, 0]\n",
            "adding more negative\n",
            "Changed 4 records\n",
            "4321\n",
            "[2, 1, 1, 1]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "0    2653\n",
            "1    1668\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "53\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 1], [1, 1, 1, 1]]\n",
            "[[2, 0, 1, 1]]\n",
            "adding more positive\n",
            "[0, 0, 1, 1]\n",
            "Changed 13 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 1, 1]\n",
            "Changed 13 records\n",
            "4321\n",
            "[2, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "4321\n",
            "0    2636\n",
            "1    1685\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "52\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0], [0, 0, 1, 1]]\n",
            "[[2, 1, 0, 1]]\n",
            "adding more positive\n",
            "[0, 0, 0, 0]\n",
            "Changed 17 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 0, 1, 1]\n",
            "Changed 6 records\n",
            "4321\n",
            "[2, 1, 0, 1]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "0    2621\n",
            "1    1700\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "51\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 2, 1], [0, 1, 0, 1], [1, 0, 0, 1], [1, 0, 2, 2]]\n",
            "[[0, 1, 2, 1], [1, 0, 0, 2], [1, 0, 1, 1], [1, 0, 2, 1], [2, 0, 1, 1], [2, 0, 2, 1]]\n",
            "adding more positive\n",
            "[0, 0, 2, 1]\n",
            "Changed 54 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 1, 0, 1]\n",
            "Changed 31 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 0, 1]\n",
            "Changed 8 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 2, 2]\n",
            "Changed 8 records\n",
            "4321\n",
            "[0, 1, 2, 1]\n",
            "adding more negative\n",
            "Changed 12 records\n",
            "4321\n",
            "[1, 0, 0, 2]\n",
            "adding more negative\n",
            "Changed 12 records\n",
            "4321\n",
            "[1, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 21 records\n",
            "4321\n",
            "[1, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 38 records\n",
            "4321\n",
            "[2, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "[2, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 21 records\n",
            "4321\n",
            "0    2629\n",
            "1    1692\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "50\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 2, 3], [1, 1, 2, 1]]\n",
            "[[1, 0, 0, 1], [1, 0, 2, 1], [1, 1, 1, 2]]\n",
            "adding more positive\n",
            "[0, 0, 2, 3]\n",
            "Changed 5 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 2, 1]\n",
            "Changed 24 records\n",
            "4321\n",
            "[1, 0, 0, 1]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "[1, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 29 records\n",
            "4321\n",
            "[1, 1, 1, 2]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "0    2639\n",
            "1    1682\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "49\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1, 1], [1, 0, 0, 3], [1, 0, 1, 1]]\n",
            "[[1, 0, 0, 1], [1, 0, 1, 2], [2, 0, 0, 2]]\n",
            "adding more positive\n",
            "[0, 1, 1, 1]\n",
            "Changed 19 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 0, 3]\n",
            "Changed 7 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 1, 1]\n",
            "Changed 17 records\n",
            "4321\n",
            "[1, 0, 0, 1]\n",
            "adding more negative\n",
            "Changed 24 records\n",
            "4321\n",
            "[1, 0, 1, 2]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "4321\n",
            "[2, 0, 0, 2]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "4321\n",
            "0    2634\n",
            "1    1687\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "48\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 2], [0, 1, 1, 0]]\n",
            "[[0, 1, 1, 1], [1, 0, 1, 2], [2, 0, 0, 2]]\n",
            "adding more positive\n",
            "[0, 0, 1, 2]\n",
            "Changed 10 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 1, 1, 0]\n",
            "Changed 41 records\n",
            "4321\n",
            "[0, 1, 1, 1]\n",
            "adding more negative\n",
            "Changed 12 records\n",
            "4321\n",
            "[1, 0, 1, 2]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "[2, 0, 0, 2]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "0    2609\n",
            "1    1712\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "47\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 1], [0, 0, 2, 1], [0, 1, 2, 3], [1, 0, 2, 1], [1, 1, 1, 1]]\n",
            "[[0, 2, 0, 0], [0, 2, 0, 1], [0, 2, 2, 1], [1, 1, 2, 1], [1, 2, 1, 1]]\n",
            "adding more positive\n",
            "[0, 0, 0, 1]\n",
            "Changed 11 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 0, 2, 1]\n",
            "Changed 24 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 1, 2, 3]\n",
            "Changed 4 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 2, 1]\n",
            "Changed 16 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 1, 1]\n",
            "Changed 9 records\n",
            "4321\n",
            "[0, 2, 0, 0]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "4321\n",
            "[0, 2, 0, 1]\n",
            "adding more negative\n",
            "Changed 28 records\n",
            "4321\n",
            "[0, 2, 2, 1]\n",
            "adding more negative\n",
            "Changed 15 records\n",
            "4321\n",
            "[1, 1, 2, 1]\n",
            "adding more negative\n",
            "Changed 29 records\n",
            "4321\n",
            "[1, 2, 1, 1]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "0    2632\n",
            "1    1689\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "46\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 1], [0, 1, 1, 2], [0, 1, 1, 3], [1, 1, 1, 2]]\n",
            "[[0, 2, 0, 0], [0, 2, 1, 1], [0, 2, 1, 2], [1, 2, 0, 1]]\n",
            "adding more positive\n",
            "[0, 0, 1, 1]\n",
            "Changed 11 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 1, 1, 2]\n",
            "Changed 26 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 1, 1, 3]\n",
            "Changed 7 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 1, 2]\n",
            "Changed 6 records\n",
            "4321\n",
            "[0, 2, 0, 0]\n",
            "adding more negative\n",
            "Changed 4 records\n",
            "4321\n",
            "[0, 2, 1, 1]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "4321\n",
            "[0, 2, 1, 2]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "4321\n",
            "[1, 2, 0, 1]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "0    2613\n",
            "1    1708\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "45\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 0], [1, 0, 0, 1], [1, 1, 1, 1], [2, 0, 0, 2]]\n",
            "[[0, 1, 1, 2], [0, 2, 0, 2], [2, 1, 0, 2]]\n",
            "adding more positive\n",
            "[0, 0, 1, 0]\n",
            "Changed 16 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 0, 1]\n",
            "Changed 12 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 1, 1]\n",
            "Changed 5 records\n",
            "4321\n",
            "adding more positive\n",
            "[2, 0, 0, 2]\n",
            "Changed 10 records\n",
            "4321\n",
            "[0, 1, 1, 2]\n",
            "adding more negative\n",
            "Changed 20 records\n",
            "4321\n",
            "[0, 2, 0, 2]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "[2, 1, 0, 2]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "0    2603\n",
            "1    1718\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "44\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 0, 0], [0, 2, 1, 1], [1, 0, 0, 2], [1, 1, 1, 1]]\n",
            "[[0, 0, 0, 0], [0, 1, 1, 0], [1, 0, 0, 1]]\n",
            "adding more positive\n",
            "[0, 1, 0, 0]\n",
            "Changed 8 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 2, 1, 1]\n",
            "Changed 21 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 0, 2]\n",
            "Changed 9 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 1, 1]\n",
            "Changed 20 records\n",
            "4321\n",
            "[0, 0, 0, 0]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "[0, 1, 1, 0]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "[1, 0, 0, 1]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "4321\n",
            "0    2568\n",
            "1    1753\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "43\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 0, 1], [1, 1, 0, 0]]\n",
            "[[0, 2, 1, 1], [1, 1, 0, 1], [1, 1, 0, 2]]\n",
            "adding more positive\n",
            "[1, 0, 0, 1]\n",
            "Changed 7 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 0, 0]\n",
            "Changed 11 records\n",
            "4321\n",
            "[0, 2, 1, 1]\n",
            "adding more negative\n",
            "Changed 13 records\n",
            "4321\n",
            "[1, 1, 0, 1]\n",
            "adding more negative\n",
            "Changed 11 records\n",
            "4321\n",
            "[1, 1, 0, 2]\n",
            "adding more negative\n",
            "Changed 18 records\n",
            "4321\n",
            "0    2592\n",
            "1    1729\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "42\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1, 1], [1, 1, 0, 1]]\n",
            "[[0, 0, 0, 1], [1, 0, 0, 0], [1, 1, 0, 0], [2, 2, 0, 0]]\n",
            "adding more positive\n",
            "[0, 1, 1, 1]\n",
            "Changed 32 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 0, 1]\n",
            "Changed 29 records\n",
            "4321\n",
            "[0, 0, 0, 1]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "4321\n",
            "[1, 0, 0, 0]\n",
            "adding more negative\n",
            "Changed 11 records\n",
            "4321\n",
            "[1, 1, 0, 0]\n",
            "adding more negative\n",
            "Changed 39 records\n",
            "4321\n",
            "[2, 2, 0, 0]\n",
            "adding more negative\n",
            "Changed 9 records\n",
            "4321\n",
            "0    2599\n",
            "1    1722\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "41\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 1, 0], [0, 2, 0], [0, 2, 1], [1, 1, 1], [1, 2, 1], [1, 2, 2]]\n",
            "[0, 1, 0]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "4321\n",
            "[0, 2, 0]\n",
            "adding more negative\n",
            "Changed 15 records\n",
            "4321\n",
            "[0, 2, 1]\n",
            "adding more negative\n",
            "Changed 58 records\n",
            "4321\n",
            "[1, 1, 1]\n",
            "adding more negative\n",
            "Changed 12 records\n",
            "4321\n",
            "[1, 2, 1]\n",
            "adding more negative\n",
            "Changed 13 records\n",
            "4321\n",
            "[1, 2, 2]\n",
            "adding more negative\n",
            "Changed 12 records\n",
            "4321\n",
            "0    2719\n",
            "1    1602\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "40\n",
            "The sets of need pos and neg are\n",
            "[[1, 2, 1]]\n",
            "[[0, 1, 0], [0, 2, 1]]\n",
            "adding more positive\n",
            "[1, 2, 1]\n",
            "Changed 65 records\n",
            "4321\n",
            "[0, 1, 0]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "[0, 2, 1]\n",
            "adding more negative\n",
            "Changed 85 records\n",
            "4321\n",
            "0    2745\n",
            "1    1576\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "39\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 0]]\n",
            "[[0, 0, 0], [0, 0, 1]]\n",
            "adding more positive\n",
            "[1, 0, 0]\n",
            "Changed 20 records\n",
            "4321\n",
            "[0, 0, 0]\n",
            "adding more negative\n",
            "Changed 13 records\n",
            "4321\n",
            "[0, 0, 1]\n",
            "adding more negative\n",
            "Changed 139 records\n",
            "4321\n",
            "0    2877\n",
            "1    1444\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "38\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0], [0, 1, 2]]\n",
            "[[0, 0, 2], [0, 1, 0]]\n",
            "adding more positive\n",
            "[0, 0, 0]\n",
            "Changed 137 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 1, 2]\n",
            "Changed 18 records\n",
            "4321\n",
            "[0, 0, 2]\n",
            "adding more negative\n",
            "Changed 131 records\n",
            "4321\n",
            "[0, 1, 0]\n",
            "adding more negative\n",
            "Changed 32 records\n",
            "4321\n",
            "0    2885\n",
            "1    1436\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "37\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 0], [1, 0, 0], [2, 0, 0], [2, 0, 3], [2, 1, 1], [2, 2, 1]]\n",
            "[0, 0, 0]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "4321\n",
            "[1, 0, 0]\n",
            "adding more negative\n",
            "Changed 12 records\n",
            "4321\n",
            "[2, 0, 0]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "4321\n",
            "[2, 0, 3]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "[2, 1, 1]\n",
            "adding more negative\n",
            "Changed 35 records\n",
            "4321\n",
            "[2, 2, 1]\n",
            "adding more negative\n",
            "Changed 23 records\n",
            "4321\n",
            "0    2978\n",
            "1    1343\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "36\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 0], [2, 0, 0]]\n",
            "[1, 0, 0]\n",
            "adding more negative\n",
            "Changed 19 records\n",
            "4321\n",
            "[2, 0, 0]\n",
            "adding more negative\n",
            "Changed 11 records\n",
            "4321\n",
            "0    3008\n",
            "1    1313\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "35\n",
            "The sets of need pos and neg are\n",
            "[[1, 1, 0], [2, 1, 1]]\n",
            "[]\n",
            "adding more positive\n",
            "[1, 1, 0]\n",
            "Changed 40 records\n",
            "4321\n",
            "adding more positive\n",
            "[2, 1, 1]\n",
            "Changed 18 records\n",
            "4321\n",
            "0    2950\n",
            "1    1371\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "34\n",
            "The sets of need pos and neg are\n",
            "[[2, 1, 1]]\n",
            "[[1, 0, 0]]\n",
            "adding more positive\n",
            "[2, 1, 1]\n",
            "Changed 28 records\n",
            "4321\n",
            "[1, 0, 0]\n",
            "adding more negative\n",
            "Changed 16 records\n",
            "4321\n",
            "0    2938\n",
            "1    1383\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "33\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 0, 1]]\n",
            "[2, 0, 1]\n",
            "adding more negative\n",
            "Changed 42 records\n",
            "4321\n",
            "0    2980\n",
            "1    1341\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "32\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2980\n",
            "1    1341\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "31\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 1], [1, 1, 2], [1, 1, 3]]\n",
            "[[1, 0, 1], [1, 0, 2], [1, 1, 1], [1, 2, 1], [1, 2, 2], [2, 1, 1], [2, 2, 1]]\n",
            "adding more positive\n",
            "[0, 2, 1]\n",
            "Changed 104 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 2]\n",
            "Changed 27 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 3]\n",
            "Changed 7 records\n",
            "4321\n",
            "[1, 0, 1]\n",
            "adding more negative\n",
            "Changed 25 records\n",
            "4321\n",
            "[1, 0, 2]\n",
            "adding more negative\n",
            "Changed 24 records\n",
            "4321\n",
            "[1, 1, 1]\n",
            "adding more negative\n",
            "Changed 15 records\n",
            "4321\n",
            "[1, 2, 1]\n",
            "adding more negative\n",
            "Changed 88 records\n",
            "4321\n",
            "[1, 2, 2]\n",
            "adding more negative\n",
            "Changed 20 records\n",
            "4321\n",
            "[2, 1, 1]\n",
            "adding more negative\n",
            "Changed 5 records\n",
            "4321\n",
            "[2, 2, 1]\n",
            "adding more negative\n",
            "Changed 27 records\n",
            "4321\n",
            "0    3046\n",
            "1    1275\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "30\n",
            "The sets of need pos and neg are\n",
            "[[1, 1, 1], [1, 1, 2]]\n",
            "[[1, 0, 2], [1, 0, 3], [2, 0, 1]]\n",
            "adding more positive\n",
            "[1, 1, 1]\n",
            "Changed 13 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 2]\n",
            "Changed 10 records\n",
            "4321\n",
            "[1, 0, 2]\n",
            "adding more negative\n",
            "Changed 36 records\n",
            "4321\n",
            "[1, 0, 3]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "4321\n",
            "[2, 0, 1]\n",
            "adding more negative\n",
            "Changed 12 records\n",
            "4321\n",
            "0    3078\n",
            "1    1243\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "29\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 2]]\n",
            "[1, 1, 2]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "4321\n",
            "0    3085\n",
            "1    1236\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "28\n",
            "The sets of need pos and neg are\n",
            "[[1, 1, 1]]\n",
            "[[1, 0, 1], [2, 0, 2]]\n",
            "adding more positive\n",
            "[1, 1, 1]\n",
            "Changed 34 records\n",
            "4321\n",
            "[1, 0, 1]\n",
            "adding more negative\n",
            "Changed 77 records\n",
            "4321\n",
            "[2, 0, 2]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "4321\n",
            "0    3135\n",
            "1    1186\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "27\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 2]]\n",
            "[1, 0, 2]\n",
            "adding more negative\n",
            "Changed 41 records\n",
            "4321\n",
            "0    3176\n",
            "1    1145\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "26\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 1]]\n",
            "[]\n",
            "adding more positive\n",
            "[1, 0, 1]\n",
            "Changed 20 records\n",
            "4321\n",
            "0    3156\n",
            "1    1165\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "25\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1], [1, 0, 1]]\n",
            "[[1, 2, 1], [1, 2, 2], [2, 2, 1]]\n",
            "adding more positive\n",
            "[0, 0, 1]\n",
            "Changed 49 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 1]\n",
            "Changed 18 records\n",
            "4321\n",
            "[1, 2, 1]\n",
            "adding more negative\n",
            "Changed 24 records\n",
            "4321\n",
            "[1, 2, 2]\n",
            "adding more negative\n",
            "Changed 19 records\n",
            "4321\n",
            "[2, 2, 1]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "4321\n",
            "0    3142\n",
            "1    1179\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "24\n",
            "The sets of need pos and neg are\n",
            "[[1, 1, 1], [2, 0, 2], [2, 1, 1]]\n",
            "[[0, 1, 1], [0, 2, 2], [1, 1, 2], [1, 2, 1]]\n",
            "adding more positive\n",
            "[1, 1, 1]\n",
            "Changed 28 records\n",
            "4321\n",
            "adding more positive\n",
            "[2, 0, 2]\n",
            "Changed 11 records\n",
            "4321\n",
            "adding more positive\n",
            "[2, 1, 1]\n",
            "Changed 6 records\n",
            "4321\n",
            "[0, 1, 1]\n",
            "adding more negative\n",
            "Changed 108 records\n",
            "4321\n",
            "[0, 2, 2]\n",
            "adding more negative\n",
            "Changed 17 records\n",
            "4321\n",
            "[1, 1, 2]\n",
            "adding more negative\n",
            "Changed 32 records\n",
            "4321\n",
            "[1, 2, 1]\n",
            "adding more negative\n",
            "Changed 22 records\n",
            "4321\n",
            "0    3276\n",
            "1    1045\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "23\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 1, 0]]\n",
            "[2, 1, 0]\n",
            "adding more negative\n",
            "Changed 15 records\n",
            "4321\n",
            "0    3291\n",
            "1    1030\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "22\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3291\n",
            "1    1030\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "21\n",
            "The sets of need pos and neg are\n",
            "[[2, 3]]\n",
            "[[2, 0], [2, 1]]\n",
            "adding more positive\n",
            "[2, 3]\n",
            "Changed 17 records\n",
            "4321\n",
            "[2, 0]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "[2, 1]\n",
            "adding more negative\n",
            "Changed 163 records\n",
            "4321\n",
            "0    3445\n",
            "1     876\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "20\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3445\n",
            "1     876\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "19\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3445\n",
            "1     876\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "18\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3445\n",
            "1     876\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "17\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3445\n",
            "1     876\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "16\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3445\n",
            "1     876\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "15\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3445\n",
            "1     876\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "14\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 2]]\n",
            "[2, 2]\n",
            "adding more negative\n",
            "Changed 19 records\n",
            "4321\n",
            "0    3464\n",
            "1     857\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "13\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3464\n",
            "1     857\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "12\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3464\n",
            "1     857\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "11\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3464\n",
            "1     857\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "10\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 2]]\n",
            "[2, 2]\n",
            "adding more negative\n",
            "Changed 37 records\n",
            "4321\n",
            "0    3501\n",
            "1     820\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "9\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3501\n",
            "1     820\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "8\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3501\n",
            "1     820\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    3501\n",
            "1     820\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "   \n",
        "   #id function\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "\n",
        "  # massaging function\n",
        "  new_train_data = naive_massaging(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6hqSHlurjGO"
      },
      "source": [
        "### Massaging Results Lattice "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massage-Lattice\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massage-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massage-Lattice\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Massage-Lattice\",\"SVM\")"
      ],
      "metadata": {
        "id": "OvXIDnsDsiz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b41c511b-174d-4487-e07a-33a45d35c734"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.7949512952258617\n",
            "fpr and fnr\n",
            "0.0\n",
            "1.0\n",
            "accuracy\n",
            "0.45650999459751485\n",
            "dfpr 0\n",
            "dfnr 0\n",
            "dacc 0.8613400089486869\n",
            "accuracy is  0.5510534846029174\n",
            "\n",
            "rf\n",
            "best 0.7859227146221366\n",
            "fpr and fnr\n",
            "0.06764705882352941\n",
            "0.9025270758122743\n",
            "accuracy\n",
            "0.5510534846029174\n",
            "dfpr 0.7479327437364252\n",
            "dfnr 0.48184544385839373\n",
            "dacc 0.7116412609768078\n",
            "accuracy is  0.5575364667747164\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.81022907        nan 0.81022907        nan 0.81022907\n",
            "        nan 0.81022907        nan 0.81022907]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.8102290730036396\n",
            "fpr and fnr\n",
            "0.0\n",
            "1.0\n",
            "accuracy\n",
            "0.5575364667747164\n",
            "dfpr 0\n",
            "dfnr 0\n",
            "dacc 0.8613400089486869\n",
            "accuracy is  0.5510534846029174\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.04411764705882353\n",
            "0.9169675090252708\n",
            "accuracy\n",
            "0.5510534846029174\n",
            "dfpr 0.7608212562028613\n",
            "dfnr 0.3789451626427168\n",
            "dacc 0.7324395153699396\n",
            "accuracy is  0.5640194489465153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfBfO1hhytVS"
      },
      "source": [
        "## Run Algorithm Leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "R6oMxp2hzVXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60386abd-3dcd-44b0-9131-14f7ff662514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "63\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1], [0, 1, 0, 1, 2, 1], [1, 1, 0, 0, 1, 1]]\n",
            "[[0, 1, 0, 0, 2, 1], [0, 1, 1, 0, 2, 1], [0, 1, 1, 0, 2, 2], [0, 2, 0, 0, 1, 1], [0, 2, 1, 0, 0, 1], [1, 1, 0, 0, 2, 1], [1, 1, 0, 0, 2, 2], [2, 1, 0, 0, 2, 1]]\n",
            "adding more positive\n",
            "[0, 0, 0, 0, 0, 2]\n",
            "Changed 10 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 0, 0, 0, 1, 1]\n",
            "Changed 12 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 1, 0, 0, 0, 1]\n",
            "Changed 26 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 1, 0, 1, 2, 1]\n",
            "Changed 5 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 0, 0, 1, 1]\n",
            "Changed 3 records\n",
            "4321\n",
            "[0, 1, 0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 41 records\n",
            "4321\n",
            "[0, 1, 1, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 10 records\n",
            "4321\n",
            "[0, 1, 1, 0, 2, 2]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "[0, 2, 0, 0, 1, 1]\n",
            "adding more negative\n",
            "Changed 30 records\n",
            "4321\n",
            "[0, 2, 1, 0, 0, 1]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "[1, 1, 0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 11 records\n",
            "4321\n",
            "[1, 1, 0, 0, 2, 2]\n",
            "adding more negative\n",
            "Changed 6 records\n",
            "4321\n",
            "[2, 1, 0, 0, 2, 1]\n",
            "adding more negative\n",
            "Changed 1 records\n",
            "4321\n",
            "0    2400\n",
            "1    1921\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in [all_names_lst[0]]:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  \n",
        "  #id function  \n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "\n",
        "  # massaging function\n",
        "  new_train_data = naive_massaging(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM-vpguwyt2H"
      },
      "source": [
        "### Massaging Results Leaf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massage-Leaf\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massage-Leaf\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massage-Leaf\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Massage-Leaf\",\"SVM\")"
      ],
      "metadata": {
        "id": "g0N6uIH9slwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d403c2-f1bf-4de4-fbf0-5c8a91e47f5f"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.621149111539285\n",
            "fpr and fnr\n",
            "0.19411764705882353\n",
            "0.4897713598074609\n",
            "accuracy\n",
            "0.5640194489465153\n",
            "dfpr 2.223247068811258\n",
            "dfnr 2.275118418495093\n",
            "dacc 0.1604053585881271\n",
            "accuracy is  0.6731496488384657\n",
            "\n",
            "rf\n",
            "best 0.6086493791479339\n",
            "fpr and fnr\n",
            "0.2735294117647059\n",
            "0.4500601684717208\n",
            "accuracy\n",
            "0.6731496488384657\n",
            "dfpr 2.4803519161042393\n",
            "dfnr 3.4909766650703578\n",
            "dacc 0.23710167617136318\n",
            "accuracy is  0.6472177201512695\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.63989055        nan 0.64266752        nan 0.64151038\n",
            "        nan 0.64266645        nan 0.64266645]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.6426675230143438\n",
            "fpr and fnr\n",
            "0.23529411764705882\n",
            "0.4428399518652226\n",
            "accuracy\n",
            "0.6472177201512695\n",
            "dfpr 3.0625152182392226\n",
            "dfnr 3.156926896160785\n",
            "dacc 0.15393609423381752\n",
            "accuracy is  0.671528903295516\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.24705882352941178\n",
            "0.43200962695547535\n",
            "accuracy\n",
            "0.671528903295516\n",
            "dfpr 1.0969663472342601\n",
            "dfnr 2.8144272413525213\n",
            "dacc 0.15150745680127928\n",
            "accuracy is  0.6699081577525662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6oj1yzvyuNv"
      },
      "source": [
        "## Run Algorithm Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "lXWlcnvmzaef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b2e7c0-d553-4422-d45c-9f3de3225f00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[[0, 0]]\n",
            "[[0, 2], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]]\n",
            "adding more positive\n",
            "[0, 0]\n",
            "Changed 128 records\n",
            "4321\n",
            "[0, 2]\n",
            "adding more negative\n",
            "Changed 97 records\n",
            "4321\n",
            "[1, 1]\n",
            "adding more negative\n",
            "Changed 72 records\n",
            "4321\n",
            "[1, 2]\n",
            "adding more negative\n",
            "Changed 15 records\n",
            "4321\n",
            "[2, 0]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "[2, 1]\n",
            "adding more negative\n",
            "Changed 16 records\n",
            "4321\n",
            "[2, 2]\n",
            "adding more negative\n",
            "Changed 7 records\n",
            "4321\n",
            "0    2430\n",
            "1    1891\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "8\n",
            "The sets of need pos and neg are\n",
            "[[0, 1]]\n",
            "[[0, 0]]\n",
            "adding more positive\n",
            "[0, 1]\n",
            "Changed 255 records\n",
            "4321\n",
            "[0, 0]\n",
            "adding more negative\n",
            "Changed 261 records\n",
            "4321\n",
            "0    2436\n",
            "1    1885\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "9\n",
            "The sets of need pos and neg are\n",
            "[[0, 1]]\n",
            "[[0, 0]]\n",
            "adding more positive\n",
            "[0, 1]\n",
            "Changed 236 records\n",
            "4321\n",
            "[0, 0]\n",
            "adding more negative\n",
            "Changed 381 records\n",
            "4321\n",
            "0    2581\n",
            "1    1740\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "10\n",
            "The sets of need pos and neg are\n",
            "[[0, 0], [2, 1], [2, 2]]\n",
            "[[0, 1], [0, 2], [1, 2]]\n",
            "adding more positive\n",
            "[0, 0]\n",
            "Changed 735 records\n",
            "4321\n",
            "adding more positive\n",
            "[2, 1]\n",
            "Changed 12 records\n",
            "4321\n",
            "adding more positive\n",
            "[2, 2]\n",
            "Changed 13 records\n",
            "4321\n",
            "[0, 1]\n",
            "adding more negative\n",
            "Changed 131 records\n",
            "4321\n",
            "[0, 2]\n",
            "adding more negative\n",
            "Changed 456 records\n",
            "4321\n",
            "[1, 2]\n",
            "adding more negative\n",
            "Changed 22 records\n",
            "4321\n",
            "0    2430\n",
            "1    1891\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "11\n",
            "The sets of need pos and neg are\n",
            "[[0, 3], [1, 3]]\n",
            "[[0, 0], [1, 1], [2, 1]]\n",
            "adding more positive\n",
            "[0, 3]\n",
            "Changed 101 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 3]\n",
            "Changed 13 records\n",
            "4321\n",
            "[0, 0]\n",
            "adding more negative\n",
            "Changed 99 records\n",
            "4321\n",
            "[1, 1]\n",
            "adding more negative\n",
            "Changed 49 records\n",
            "4321\n",
            "[2, 1]\n",
            "adding more negative\n",
            "Changed 20 records\n",
            "4321\n",
            "0    2484\n",
            "1    1837\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "12\n",
            "The sets of need pos and neg are\n",
            "[[2, 0], [2, 1]]\n",
            "[[0, 0], [0, 1]]\n",
            "adding more positive\n",
            "[2, 0]\n",
            "Changed 181 records\n",
            "4321\n",
            "adding more positive\n",
            "[2, 1]\n",
            "Changed 76 records\n",
            "4321\n",
            "[0, 0]\n",
            "adding more negative\n",
            "Changed 111 records\n",
            "4321\n",
            "[0, 1]\n",
            "adding more negative\n",
            "Changed 176 records\n",
            "4321\n",
            "0    2514\n",
            "1    1807\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "13\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 1], [1, 1], [2, 1]]\n",
            "[0, 1]\n",
            "adding more negative\n",
            "Changed 61 records\n",
            "4321\n",
            "[1, 1]\n",
            "adding more negative\n",
            "Changed 185 records\n",
            "4321\n",
            "[2, 1]\n",
            "adding more negative\n",
            "Changed 77 records\n",
            "4321\n",
            "0    2837\n",
            "1    1484\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "14\n",
            "The sets of need pos and neg are\n",
            "[[0, 1], [2, 0]]\n",
            "[[0, 0], [1, 0]]\n",
            "adding more positive\n",
            "[0, 1]\n",
            "Changed 66 records\n",
            "4321\n",
            "adding more positive\n",
            "[2, 0]\n",
            "Changed 47 records\n",
            "4321\n",
            "[0, 0]\n",
            "adding more negative\n",
            "Changed 121 records\n",
            "4321\n",
            "[1, 0]\n",
            "adding more negative\n",
            "Changed 187 records\n",
            "4321\n",
            "0    3032\n",
            "1    1289\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "15\n",
            "The sets of need pos and neg are\n",
            "[[1, 2]]\n",
            "[[0, 2], [2, 2], [2, 3]]\n",
            "adding more positive\n",
            "[1, 2]\n",
            "Changed 181 records\n",
            "4321\n",
            "[0, 2]\n",
            "adding more negative\n",
            "Changed 70 records\n",
            "4321\n",
            "[2, 2]\n",
            "adding more negative\n",
            "Changed 64 records\n",
            "4321\n",
            "[2, 3]\n",
            "adding more negative\n",
            "Changed 24 records\n",
            "4321\n",
            "0    3009\n",
            "1    1312\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "16\n",
            "The sets of need pos and neg are\n",
            "[[0, 0]]\n",
            "[[0, 1], [1, 1]]\n",
            "adding more positive\n",
            "[0, 0]\n",
            "Changed 393 records\n",
            "4321\n",
            "[0, 1]\n",
            "adding more negative\n",
            "Changed 90 records\n",
            "4321\n",
            "[1, 1]\n",
            "adding more negative\n",
            "Changed 169 records\n",
            "4321\n",
            "0    2875\n",
            "1    1446\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "17\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2875\n",
            "1    1446\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "18\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0]]\n",
            "[0, 0]\n",
            "adding more negative\n",
            "Changed 49 records\n",
            "4321\n",
            "0    2924\n",
            "1    1397\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "19\n",
            "The sets of need pos and neg are\n",
            "[[1, 1]]\n",
            "[]\n",
            "adding more positive\n",
            "[1, 1]\n",
            "Changed 55 records\n",
            "4321\n",
            "0    2869\n",
            "1    1452\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "20\n",
            "The sets of need pos and neg are\n",
            "[[1, 3]]\n",
            "[[1, 0]]\n",
            "adding more positive\n",
            "[1, 3]\n",
            "Changed 17 records\n",
            "4321\n",
            "[1, 0]\n",
            "adding more negative\n",
            "Changed 8 records\n",
            "4321\n",
            "0    2860\n",
            "1    1461\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "21\n",
            "The sets of need pos and neg are\n",
            "[[0, 2], [0, 3]]\n",
            "[[0, 1], [1, 3]]\n",
            "adding more positive\n",
            "[0, 2]\n",
            "Changed 99 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 3]\n",
            "Changed 32 records\n",
            "4321\n",
            "[0, 1]\n",
            "adding more negative\n",
            "Changed 150 records\n",
            "4321\n",
            "[1, 3]\n",
            "adding more negative\n",
            "Changed 24 records\n",
            "4321\n",
            "0    2903\n",
            "1    1418\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "all_names_lst_top = find_top(all_names)\n",
        "for a in all_names_lst_top:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  \n",
        "  # id function   \n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        " \n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  \n",
        "  # massaging function\n",
        "  new_train_data = naive_massaging(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "\n",
        "  print(new_train_data[compas_y].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YylnNCsvyuuU"
      },
      "source": [
        "### Massaging Results Top"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massage-Top\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massage-Top\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massage-Top\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_set['predicted'])\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Massage-Top\",\"SVM\")"
      ],
      "metadata": {
        "id": "NWUjzEK5smxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4efdccd5-df12-44b7-a240-7efa304c92d3"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dt\n",
            "best 0.834049721687005\n",
            "fpr and fnr\n",
            "0.22549019607843138\n",
            "0.7436823104693141\n",
            "accuracy\n",
            "0.6699081577525662\n",
            "dfpr 0.8901317055556609\n",
            "dfnr 1.2506835775488587\n",
            "dacc 0.3718001366528118\n",
            "accuracy is  0.5418692598595354\n",
            "\n",
            "rf\n",
            "best 0.7752411153928495\n",
            "fpr and fnr\n",
            "0.31470588235294117\n",
            "0.6979542719614922\n",
            "accuracy\n",
            "0.5418692598595354\n",
            "dfpr 0.9527189020743742\n",
            "dfnr 1.703938178835546\n",
            "dacc 0.30697381735630835\n",
            "accuracy is  0.5132360886007563\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.82341255        nan 0.85488386        nan 0.85789285\n",
            "        nan 0.85789285        nan 0.85789285]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.8578928494968958\n",
            "fpr and fnr\n",
            "0.21862745098039216\n",
            "0.7099879663056559\n",
            "accuracy\n",
            "0.5132360886007563\n",
            "dfpr 0.7141845146034491\n",
            "dfnr 1.1550471253780277\n",
            "dacc 0.40275132719884194\n",
            "accuracy is  0.5607779578606159\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.31862745098039214\n",
            "0.6847172081829122\n",
            "accuracy\n",
            "0.5607779578606159\n",
            "dfpr 1.0638524793865747\n",
            "dfnr 1.829136870553926\n",
            "dacc 0.3284684698883693\n",
            "accuracy is  0.5170178282009724\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "vmhcs6wcgGiZ"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
