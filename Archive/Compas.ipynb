{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DecisionTreeClassifer\n"
      ],
      "metadata": {
        "id": "7oMgFj8Ve2Oq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports and Dataset processing"
      ],
      "metadata": {
        "id": "772S9aKIfv-9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Evnn9BbOfEme"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "import copy\n",
        "from sympy import Symbol\n",
        "from sympy.solvers import solve\n",
        "pd.options.mode.chained_assignment = None\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/niceIrene/remedy/main/datasets/compas_numerical.csv\"\n",
        "data = pd.read_csv(url, delimiter=',')\n",
        "# data.dtypes\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_vP0FN3vfgjA",
        "outputId": "8f5c4dbe-e0c0-4f56-b813-c571b224295b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age  charge  race  sex  #prior  stay  class  predicted\n",
              "0       0       0     0    0       0     0      0          0\n",
              "1       1       0     1    0       0     1      1          0\n",
              "2       2       0     1    0       2     0      1          0\n",
              "3       1       1     0    0       0     0      0          0\n",
              "4       1       0     2    0       2     0      1          0\n",
              "...   ...     ...   ...  ...     ...   ...    ...        ...\n",
              "6167    2       0     1    0       0     0      0          0\n",
              "6168    2       0     1    0       0     0      0          0\n",
              "6169    0       0     0    0       0     0      0          0\n",
              "6170    1       1     1    1       1     0      0          0\n",
              "6171    2       0     3    1       1     0      1          0\n",
              "\n",
              "[6172 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef012dd4-6eb4-439a-8a27-cf857c312e2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>charge</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>#prior</th>\n",
              "      <th>stay</th>\n",
              "      <th>class</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6167</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6168</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6169</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6170</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6171</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6172 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef012dd4-6eb4-439a-8a27-cf857c312e2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef012dd4-6eb4-439a-8a27-cf857c312e2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef012dd4-6eb4-439a-8a27-cf857c312e2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dc0fd474-14d1-44a6-8afe-0e416ae8ea23\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc0fd474-14d1-44a6-8afe-0e416ae8ea23')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dc0fd474-14d1-44a6-8afe-0e416ae8ea23 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRNedFyDETRZ",
        "outputId": "faad3ab8-e0f2-431c-f227-36f77942b1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3363\n",
              "1    2809\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get training and testing set\n",
        "\n",
        "columns_compas = ['stay', 'age', 'charge', 'sex', '#prior', 'race']\n",
        "# columns_compas = ['age', 'race', 'sex']\n",
        "\n",
        "\n",
        "compas_y = 'class'\n",
        "adult_y = 'income'\n",
        "def split_train_test(data,test_ratio):\n",
        "    np.random.seed(42)\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices],data.iloc[test_indices]\n",
        "\n",
        "def get_train_test(data, split, list_cols, y_label):\n",
        "  train_set,test_set = split_train_test(data,split)\n",
        "  print(len(train_set), \"train +\", len(test_set), \"test\")\n",
        "  train_x = pd.DataFrame(train_set, columns = list_cols)\n",
        "  train_label = train_set[y_label]\n",
        "  test_x = pd.DataFrame(test_set, columns = list_cols)\n",
        "  test_label = test_set[y_label]\n",
        "  return train_x, test_x, train_label, test_label, train_set, test_set"
      ],
      "metadata": {
        "id": "NNSifBfwflg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x, train_label, test_label, train_set, test_set  = get_train_test(data, 0.3, columns_compas, compas_y)\n",
        "\n",
        "###################\n",
        "\n",
        "### about decision tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, make_scorer\n",
        "\n",
        "\n",
        "filter_count = 30\n",
        "\n",
        "\n",
        "\n",
        "scoring = make_scorer(accuracy_score)\n",
        "\n",
        "\n",
        "# #####################\n",
        "param_gridlg = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "gridlg = GridSearchCV(logreg, param_grid=param_gridlg, scoring=scoring, cv=5)\n",
        "# #####################\n",
        "param_griddt = {\n",
        "    'max_depth': [2, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "griddt = GridSearchCV(dt, param_grid=param_griddt, scoring=scoring, cv=5)\n",
        "\n",
        "# #####################\n",
        "param_gridrf = {'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 100], 'random_state':[17]}\n",
        "# param_gridrf = {\n",
        "#     'max_depth': [10, 20, 30],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4],\n",
        "# }\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "gridrf = GridSearchCV(rf, param_grid=param_gridrf, scoring=scoring, cv=5)\n",
        "\n",
        "clf = SVC(kernel='rbf', C=6.0, gamma = 100, random_state =42)\n",
        "\n",
        "\n",
        "# print(\"best\", grid.best_score_)\n",
        "# test_predict = grid.predict(test_x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJQsq95bfpEH",
        "outputId": "f503afbd-a4c0-46d5-ac54-3294cbdfe2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4321 train + 1851 test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install divexplorer==0.1.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVt4YIpUgKlo",
        "outputId": "4caeda04-81b2-464a-ba18-7d9b3a692595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting divexplorer==0.1.1\n",
            "  Downloading divexplorer-0.1.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: ipywidgets>=7.2.1 in /usr/local/lib/python3.10/dist-packages (from divexplorer==0.1.1) (7.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from divexplorer==0.1.1) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.10/dist-packages (from divexplorer==0.1.1) (1.23.5)\n",
            "Requirement already satisfied: mlxtend>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from divexplorer==0.1.1) (0.22.0)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from divexplorer==0.1.1) (1.5.3)\n",
            "Requirement already satisfied: plotly>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from divexplorer==0.1.1) (5.15.0)\n",
            "Collecting python-igraph>=0.8.3 (from divexplorer==0.1.1)\n",
            "  Downloading python_igraph-0.11.3-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from divexplorer==0.1.1) (1.2.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.2.1->divexplorer==0.1.1) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.2.1->divexplorer==0.1.1) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.2.1->divexplorer==0.1.1) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.2.1->divexplorer==0.1.1) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.2.1->divexplorer==0.1.1) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.2.1->divexplorer==0.1.1) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer==0.1.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer==0.1.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer==0.1.1) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer==0.1.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer==0.1.1) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer==0.1.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer==0.1.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->divexplorer==0.1.1) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from mlxtend>=0.17.1->divexplorer==0.1.1) (1.11.3)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend>=0.17.1->divexplorer==0.1.1) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from mlxtend>=0.17.1->divexplorer==0.1.1) (67.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->divexplorer==0.1.1) (2023.3.post1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.5.0->divexplorer==0.1.1) (8.2.3)\n",
            "Collecting igraph==0.11.3 (from python-igraph>=0.8.3->divexplorer==0.1.1)\n",
            "  Downloading igraph-0.11.3-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable>=1.6.2 (from igraph==0.11.3->python-igraph>=0.8.3->divexplorer==0.1.1)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->divexplorer==0.1.1) (3.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.2.1->divexplorer==0.1.1) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.2.1->divexplorer==0.1.1) (6.3.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer==0.1.1)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (4.8.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.1->divexplorer==0.1.1) (1.16.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (3.1.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (5.5.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.18.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.2.10)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (4.0.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (4.19.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.13.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (1.6.4)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (1.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.2.1->divexplorer==0.1.1) (2.21)\n",
            "Installing collected packages: texttable, jedi, igraph, python-igraph, divexplorer\n",
            "Successfully installed divexplorer-0.1.1 igraph-0.11.3 jedi-0.19.1 python-igraph-0.11.3 texttable-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fairness_score_computation(d, metrics):\n",
        "    sum_of_score = 0\n",
        "    for idx, row in d.iterrows():\n",
        "      sum_of_score += row['support'] * row[metrics]\n",
        "    return sum_of_score\n",
        "\n",
        "# print(fairness_score_computation(d, 'd_fpr'))\n"
      ],
      "metadata": {
        "id": "tb3zgDbUgXcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ceddb5-68fa-48b5-eed7-85ae5cb06bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fpr_onegroup(true, predict):\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    for i in range(len(true)):\n",
        "        if (true[i] == 0 and predict[i] == 1):\n",
        "            fp += 1\n",
        "        if(true[i] == 0 and predict[i] == 0):\n",
        "            tn += 1\n",
        "    return fp/(fp+tn)\n",
        "\n",
        "\n",
        "def fnr_onegroup(true, predict):\n",
        "    fn = 0\n",
        "    tp = 0\n",
        "    for i in range(len(true)):\n",
        "        if (true[i] == 1 and predict[i] == 0):\n",
        "            fn += 1\n",
        "        if(true[i] == 1 and predict[i] == 1):\n",
        "            tp += 1\n",
        "    return fn/(fn+tp)"
      ],
      "metadata": {
        "id": "f-rnfp9XfuKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb649bb1-8977-4e8b-fe4c-6019a8528075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fpr = fpr_onegroup(list(test_label), test_predict)\n",
        "# print(\"fpr is \" , fpr)\n",
        "\n",
        "# fnr = fnr_onegroup(list(test_label), test_predict)\n",
        "# print(\"fnr is \" , fnr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axb85-QngAPX",
        "outputId": "35fbb4d8-4dd4-4845-f358-18d8e1af8554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fpr is  0.23137254901960785\n",
            "fnr is  0.4548736462093863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(fpr_onegroup(l1, l3))\n",
        "# accuracy = accuracy_score(test_label, test_predict)\n",
        "# print(\"accuracy is \" , accuracy)\n",
        "# test_set[\"predicted\"] = test_predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qzANv0KigX3",
        "outputId": "5e3060b3-69e3-442f-d037-9ae96038adf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is  0.6682874122096164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gridlg.fit(train_x, train_label)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "test_set['predicted'] = test_predict\n",
        "accuracy_score(test_label, test_set['predicted'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cndF9JDHQ-O",
        "outputId": "eaf475d5-757f-4c5f-a404-ea8604f60890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.67484318        nan 0.67368577        nan 0.67391752\n",
            "        nan 0.67391752        nan 0.67391752]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6634251755807672"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_map={'N': 0, 'P': 1}\n",
        "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "columns_compas.extend([compas_y, \"predicted\"])\n",
        "\n",
        "df = pd.DataFrame(test_set, columns = columns_compas)\n",
        "# print(test_set.columns)\n",
        "# print(columns_compas)\n",
        "# print(df.columns)\n",
        "# print(columns_compas)\n",
        "\n",
        "columns_compas.remove(compas_y)\n",
        "columns_compas.remove('predicted')\n",
        "\n",
        "######\n",
        "\n",
        "min_sup=0.1\n",
        "# min_sup = 0.05\n",
        "# min_sup = 0.01\n",
        "\n",
        "fp_diver=FP_DivergenceExplorer(df,compas_y, \"predicted\", class_map=class_map)\n",
        "FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "from divexplorer.FP_Divergence import FP_Divergence\n",
        "fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "fp_divergence_fnr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "fp_divergence_acc=FP_Divergence(FP_fm, \"d_accuracy\")\n",
        "  # fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "INFO_VIZ2=[\"support\", \"itemsets\",  fp_divergence_fnr.metric, fp_divergence_fnr.t_value_col]\n",
        "INFO_VIZ3=[\"support\", \"itemsets\",  fp_divergence_acc.metric, fp_divergence_acc.t_value_col]\n",
        "eps=0.01\n",
        "K=1000\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ]\n",
        "d2 = fp_divergence_fnr.getDivergence(th_redundancy=eps)[INFO_VIZ2]\n",
        "d3 = fp_divergence_acc.getDivergence(th_redundancy=eps)[INFO_VIZ3]\n",
        "\n",
        "\n",
        "\n",
        "pd.options.display.max_rows = 200\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "# summerization\n",
        "\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ]\n",
        "d= d[d['d_fpr'] > 0]\n",
        "d2= d2[d2['d_fnr'] > 0]\n",
        "d3= d3[d3['d_accuracy'] > 0]\n",
        "\n",
        "dfpr = fairness_score_computation(d, 'd_fpr')\n",
        "dfnr = fairness_score_computation(d2, 'd_fnr')\n",
        "dacc = fairness_score_computation(d3, 'd_accuracy')\n",
        "\"dt\", dfpr, dfnr, dacc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0TNYKJBl2ss",
        "outputId": "69721c47-ea21-4c0a-e046-fba78ff8a1f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('dt', 2.126008125545188, 2.72581484642408, 0.16653663926897447)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "griddt.fit(train_x, train_label)\n",
        "test_predict = griddt.predict(test_x)\n",
        "test_set['predicted'] = test_predict\n",
        "accuracy_score(test_label, test_set['predicted'])"
      ],
      "metadata": {
        "id": "1nr-LivCqD4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42a058c-0152-413c-d265-e720ae4bf460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6682874122096164"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_map={'N': 0, 'P': 1}\n",
        "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "columns_compas.extend([compas_y, \"predicted\"])\n",
        "\n",
        "df = pd.DataFrame(test_set, columns = columns_compas)\n",
        "# print(test_set.columns)\n",
        "# print(columns_compas)\n",
        "# print(df.columns)\n",
        "# print(columns_compas)\n",
        "\n",
        "columns_compas.remove(compas_y)\n",
        "columns_compas.remove('predicted')\n",
        "\n",
        "######\n",
        "\n",
        "min_sup=0.1\n",
        "# min_sup = 0.05\n",
        "# min_sup = 0.01\n",
        "\n",
        "fp_diver=FP_DivergenceExplorer(df,compas_y, \"predicted\", class_map=class_map)\n",
        "FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "from divexplorer.FP_Divergence import FP_Divergence\n",
        "fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "fp_divergence_fnr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "fp_divergence_acc=FP_Divergence(FP_fm, \"d_accuracy\")\n",
        "  # fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "INFO_VIZ2=[\"support\", \"itemsets\",  fp_divergence_fnr.metric, fp_divergence_fnr.t_value_col]\n",
        "INFO_VIZ3=[\"support\", \"itemsets\",  fp_divergence_acc.metric, fp_divergence_acc.t_value_col]\n",
        "eps=0.01\n",
        "K=1000\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ]\n",
        "d2 = fp_divergence_fnr.getDivergence(th_redundancy=eps)[INFO_VIZ2]\n",
        "d3 = fp_divergence_acc.getDivergence(th_redundancy=eps)[INFO_VIZ3]\n",
        "\n",
        "\n",
        "\n",
        "pd.options.display.max_rows = 200\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "# summerization\n",
        "\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ]\n",
        "d= d[d['d_fpr'] > 0]\n",
        "d2= d2[d2['d_fnr'] > 0]\n",
        "d3= d3[d3['d_accuracy'] > 0]\n",
        "\n",
        "dfpr = fairness_score_computation(d, 'd_fpr')\n",
        "dfnr = fairness_score_computation(d2, 'd_fnr')\n",
        "dacc = fairness_score_computation(d3, 'd_accuracy')\n",
        "\"dt\", dfpr, dfnr, dacc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E74EqS_qHoLb",
        "outputId": "c3197d06-d35d-4ece-c338-3b10fe342f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('dt', 2.076573156048045, 2.241622773843088, 0.15435288239072967)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gridrf.fit(train_x, train_label)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "test_set['predicted'] = test_predict\n",
        "accuracy_score(test_label, test_set['predicted'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t3Hh8yuG6K_",
        "outputId": "c367555b-d752-475b-be68-f511af70d3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6472177201512695"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_map={'N': 0, 'P': 1}\n",
        "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "columns_compas.extend([compas_y, \"predicted\"])\n",
        "\n",
        "df = pd.DataFrame(test_set, columns = columns_compas)\n",
        "# print(test_set.columns)\n",
        "# print(columns_compas)\n",
        "# print(df.columns)\n",
        "# print(columns_compas)\n",
        "\n",
        "columns_compas.remove(compas_y)\n",
        "columns_compas.remove('predicted')\n",
        "\n",
        "######\n",
        "\n",
        "min_sup=0.1\n",
        "# min_sup = 0.05\n",
        "# min_sup = 0.01\n",
        "\n",
        "fp_diver=FP_DivergenceExplorer(df,compas_y, \"predicted\", class_map=class_map)\n",
        "FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "from divexplorer.FP_Divergence import FP_Divergence\n",
        "fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "fp_divergence_fnr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "fp_divergence_acc=FP_Divergence(FP_fm, \"d_accuracy\")\n",
        "  # fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "INFO_VIZ2=[\"support\", \"itemsets\",  fp_divergence_fnr.metric, fp_divergence_fnr.t_value_col]\n",
        "INFO_VIZ3=[\"support\", \"itemsets\",  fp_divergence_acc.metric, fp_divergence_acc.t_value_col]\n",
        "eps=0.01\n",
        "K=1000\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ]\n",
        "d2 = fp_divergence_fnr.getDivergence(th_redundancy=eps)[INFO_VIZ2]\n",
        "d3 = fp_divergence_acc.getDivergence(th_redundancy=eps)[INFO_VIZ3]\n",
        "\n",
        "\n",
        "\n",
        "pd.options.display.max_rows = 200\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "# summerization\n",
        "\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ]\n",
        "d= d[d['d_fpr'] > 0]\n",
        "d2= d2[d2['d_fnr'] > 0]\n",
        "d3= d3[d3['d_accuracy'] > 0]\n",
        "\n",
        "dfpr = fairness_score_computation(d, 'd_fpr')\n",
        "dfnr = fairness_score_computation(d2, 'd_fnr')\n",
        "dacc = fairness_score_computation(d3, 'd_accuracy')\n",
        "\"dt\", dfpr, dfnr, dacc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKG5UXy6Hqmp",
        "outputId": "8bd1bd95-af77-4a4c-bd3e-860196a4ef45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('dt', 2.2680186269977827, 3.512495110997562, 0.24541350609611082)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for SVC\n",
        "clf = SVC(kernel='rbf', C=6.0, gamma = 100, random_state =42)\n",
        "clf.fit(train_x, train_label)\n",
        "test_predict = clf.predict(test_x)\n",
        "test_set['predicted'] = test_predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnvmmvRuHIHl",
        "outputId": "bba01b31-2ebd-46f0-a356-3e39e03a6349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_map={'N': 0, 'P': 1}\n",
        "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "columns_compas.extend([compas_y, \"predicted\"])\n",
        "\n",
        "df = pd.DataFrame(test_set, columns = columns_compas)\n",
        "# print(test_set.columns)\n",
        "# print(columns_compas)\n",
        "# print(df.columns)\n",
        "# print(columns_compas)\n",
        "\n",
        "columns_compas.remove(compas_y)\n",
        "columns_compas.remove('predicted')\n",
        "\n",
        "######\n",
        "\n",
        "min_sup=0.1\n",
        "# min_sup = 0.05\n",
        "# min_sup = 0.01\n",
        "\n",
        "fp_diver=FP_DivergenceExplorer(df,compas_y, \"predicted\", class_map=class_map)\n",
        "FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "from divexplorer.FP_Divergence import FP_Divergence\n",
        "fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "fp_divergence_fnr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "fp_divergence_acc=FP_Divergence(FP_fm, \"d_accuracy\")\n",
        "  # fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "INFO_VIZ2=[\"support\", \"itemsets\",  fp_divergence_fnr.metric, fp_divergence_fnr.t_value_col]\n",
        "INFO_VIZ3=[\"support\", \"itemsets\",  fp_divergence_acc.metric, fp_divergence_acc.t_value_col]\n",
        "eps=0.01\n",
        "K=1000\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ]\n",
        "d2 = fp_divergence_fnr.getDivergence(th_redundancy=eps)[INFO_VIZ2]\n",
        "d3 = fp_divergence_acc.getDivergence(th_redundancy=eps)[INFO_VIZ3]\n",
        "\n",
        "\n",
        "\n",
        "pd.options.display.max_rows = 200\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "# summerization\n",
        "\n",
        "d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ]\n",
        "d= d[d['d_fpr'] > 0]\n",
        "d2= d2[d2['d_fnr'] > 0]\n",
        "d3= d3[d3['d_accuracy'] > 0]\n",
        "\n",
        "dfpr = fairness_score_computation(d, 'd_fpr')\n",
        "dfnr = fairness_score_computation(d2, 'd_fnr')\n",
        "dacc = fairness_score_computation(d3, 'd_accuracy')\n",
        "\"dt\", dfpr, dfnr, dacc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWiJZApcHsom",
        "outputId": "a28423a6-4a3e-49ff-e1ce-162034bad3f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('dt', 2.506933621447892, 3.2527051351850194, 0.2873993674043055)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Divexplorer"
      ],
      "metadata": {
        "id": "vmhcs6wcgGiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYDp7XFE2Q6x",
        "outputId": "1c69ab19-8add-493b-b5c1-19a4323b6397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('COMPAS_results.csv', 'w', newline='') as file:\n",
        "#   writer = csv.writer(file)\n",
        "#   writer.writerow([\"Dataset\",\"Remedy\", \"Algorithm\",\"d_fpr\",\"d_fnr\", \"d_acc\", \"model_acc\"])\n",
        "#   writer.writerow([\"COMPAS\", \"Original\", \"None\", dfpr, dfnr, dacc, \"None\"])"
      ],
      "metadata": {
        "id": "W08EGOfn2S_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fecf170-a87f-40a8-ceb8-ed9648081cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # run divexplorer to find unfair groups\n",
        "# class_map={'N': 0, 'P': 1}\n",
        "# from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "\n",
        "# min_sup=0.1\n",
        "# # min_sup = 0.05\n",
        "# # min_sup = 0.01\n",
        "\n",
        "# fp_diver=FP_DivergenceExplorer(test_set,\"class\", \"predicted\", class_map=class_map)\n",
        "# FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "# from divexplorer.FP_Divergence import FP_Divergence\n",
        "# fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "# # fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "# INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "\n",
        "# K=10\n",
        "# pd.options.display.max_rows = 200\n",
        "# d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "# # summerization\n",
        "# eps=0.01\n",
        "\n",
        "# d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ].head(K)\n",
        "\n",
        "# d, list(d[\"itemsets\"].iloc[0])"
      ],
      "metadata": {
        "id": "oT6Kmu35gRYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e91223-0f3f-4970-98f5-15baa2b7ca4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For entire dataset\n"
      ],
      "metadata": {
        "id": "Kf1ffb1bggPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "def get_unfair_group(list_parse, entire = 1):\n",
        "  unfair_group = []\n",
        "  unfair_dict = {}\n",
        "  names = []\n",
        "  for col in columns_compas:\n",
        "    found = False\n",
        "    for item in list_parse:\n",
        "      attr_given = item.split(\"=\")[0]\n",
        "      if col == attr_given:\n",
        "        unfair_group.append(int(item.split(\"=\")[1]))\n",
        "        names.append(attr_given)\n",
        "        unfair_dict[attr_given] = int(item.split(\"=\")[1])\n",
        "        found = True\n",
        "  # if use the entire dataset\n",
        "  if entire:\n",
        "    return unfair_group, names, columns_compas, unfair_dict\n",
        "        # break\n",
        "    # if found == False:\n",
        "    #   unfair_group.append(-1)\n",
        "  return unfair_group, names, list(set(columns_compas).symmetric_difference(set(names))), unfair_dict\n",
        "def candidate_groups(skew_candidates, unfair_dict, ordering, names):\n",
        "  candidate_combos = []\n",
        "  candidate_ind = []\n",
        "  for i in range(len(skew_candidates)+1):\n",
        "    temp_candidate = list(itertools.combinations(skew_candidates, i))\n",
        "    for tc in temp_candidate:\n",
        "      candidate_combos.append(list(tuple(names) + tc))\n",
        "      candidate_ind.append(list(tc))\n",
        "  c_all = {}\n",
        "  for ind in range(len(candidate_ind)):\n",
        "    temp_all = []\n",
        "    for product in candidate_ind[ind]:\n",
        "      temp_all.append(list(train_x[product].unique()))\n",
        "    # print(temp_all)\n",
        "    temp_c = list(itertools.product(*temp_all))\n",
        "    c_all[ind] = temp_c\n",
        "  # print(c_all, candidate_ind)\n",
        "  combos_dict = {}\n",
        "  t_names = {}\n",
        "  for a in c_all:\n",
        "    for a_vals in c_all[a]:\n",
        "      # print(a_vals)\n",
        "      t = []\n",
        "      t_n = []\n",
        "      for ord in ordering:\n",
        "        if ord not in unfair_dict and ord in candidate_ind[a]:\n",
        "          t.append(a_vals[candidate_ind[a].index(ord)])\n",
        "          t_n.append(candidate_ind[a][candidate_ind[a].index(ord)])\n",
        "        elif ord in unfair_dict:\n",
        "          t.append(unfair_dict[ord])\n",
        "          t_n.append(ord)\n",
        "      # print(t)\n",
        "      if a not in combos_dict:\n",
        "        combos_dict[a] = []\n",
        "        t_names[a] = t_n\n",
        "        # t_names[a].append(t_n)\n",
        "      combos_dict[a].append(t)\n",
        "  return combos_dict, t_names\n"
      ],
      "metadata": {
        "id": "aU9MirNCglkA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed50dcf8-e7b7-4827-a1e9-397fc3eea504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_temp(train_set, names, y_label):\n",
        "  names2 = copy.deepcopy(names)\n",
        "  names2.append(y_label)\n",
        "  temp = train_set[names2]\n",
        "  temp['cnt'] = 0\n",
        "  temp2 = temp.groupby(names2)['cnt'].count().reset_index()\n",
        "  temp2['cnt'].sum()\n",
        "  return temp2, names\n",
        "temp2, names = get_temp(train_set, columns_compas, compas_y)\n",
        "temp2"
      ],
      "metadata": {
        "id": "ZgdhgqYZjTci",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "f994f1c3-711b-46a4-bc4d-ccac33c35cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     stay  age  charge  sex  #prior  race  class  cnt\n",
              "0       0    0       0    0       0     0      0   11\n",
              "1       0    0       0    0       0     0      1    4\n",
              "2       0    0       0    0       0     1      0   11\n",
              "3       0    0       0    0       0     1      1    9\n",
              "4       0    0       0    0       0     2      0   40\n",
              "..    ...  ...     ...  ...     ...   ...    ...  ...\n",
              "483     2    2       1    0       1     1      0    1\n",
              "484     2    2       1    0       1     1      1    1\n",
              "485     2    2       1    1       0     1      0    1\n",
              "486     2    2       1    1       2     1      0    1\n",
              "487     2    2       1    1       2     2      1    1\n",
              "\n",
              "[488 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89fa6942-365f-4769-893f-5d182ae7a39f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stay</th>\n",
              "      <th>age</th>\n",
              "      <th>charge</th>\n",
              "      <th>sex</th>\n",
              "      <th>#prior</th>\n",
              "      <th>race</th>\n",
              "      <th>class</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>488 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89fa6942-365f-4769-893f-5d182ae7a39f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89fa6942-365f-4769-893f-5d182ae7a39f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89fa6942-365f-4769-893f-5d182ae7a39f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a988d318-2322-49f5-81ba-a0169a1935ff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a988d318-2322-49f5-81ba-a0169a1935ff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a988d318-2322-49f5-81ba-a0169a1935ff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_temp_g(train_set, names, y_label):\n",
        "  names2 = copy.deepcopy(names)\n",
        "  names2.append(y_label)\n",
        "  temp = train_set[names2]\n",
        "  temp['cnt'] = 0\n",
        "  temp_g = temp.groupby(names)['cnt'].count().reset_index()\n",
        "  return temp, temp_g"
      ],
      "metadata": {
        "id": "uuEIYpHwjg_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5e6213-ebf4-4479-8f2b-ffc3dcaaa90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unfair_group, unfair_names, skew_candidates, unfair_dict = get_unfair_group([])\n",
        "# print(unfair_group, unfair_names, skew_candidates, unfair_dict)\n",
        "combos_dict, all_names = candidate_groups(skew_candidates, unfair_dict, columns_compas, unfair_names)\n",
        "# print(combos_dict)\n",
        "print(all_names)\n",
        "\n",
        "# the\n",
        "print(list(all_names.keys())[len(columns_compas)+1:])\n",
        "# all_names_lst = list(all_names.keys())[len(columns_compas)+1:]\n",
        "all_names_lst = list(all_names.keys())[1:] # CHANGED HERE\n",
        "all_names_lst.reverse()\n",
        "print(all_names_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k-CLD9ygjS9",
        "outputId": "edec5d13-1eab-4764-ae15-3e76a52c34f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: [], 1: ['stay'], 2: ['age'], 3: ['charge'], 4: ['sex'], 5: ['#prior'], 6: ['race'], 7: ['stay', 'age'], 8: ['stay', 'charge'], 9: ['stay', 'sex'], 10: ['stay', '#prior'], 11: ['stay', 'race'], 12: ['age', 'charge'], 13: ['age', 'sex'], 14: ['age', '#prior'], 15: ['age', 'race'], 16: ['charge', 'sex'], 17: ['charge', '#prior'], 18: ['charge', 'race'], 19: ['sex', '#prior'], 20: ['sex', 'race'], 21: ['#prior', 'race'], 22: ['stay', 'age', 'charge'], 23: ['stay', 'age', 'sex'], 24: ['stay', 'age', '#prior'], 25: ['stay', 'age', 'race'], 26: ['stay', 'charge', 'sex'], 27: ['stay', 'charge', '#prior'], 28: ['stay', 'charge', 'race'], 29: ['stay', 'sex', '#prior'], 30: ['stay', 'sex', 'race'], 31: ['stay', '#prior', 'race'], 32: ['age', 'charge', 'sex'], 33: ['age', 'charge', '#prior'], 34: ['age', 'charge', 'race'], 35: ['age', 'sex', '#prior'], 36: ['age', 'sex', 'race'], 37: ['age', '#prior', 'race'], 38: ['charge', 'sex', '#prior'], 39: ['charge', 'sex', 'race'], 40: ['charge', '#prior', 'race'], 41: ['sex', '#prior', 'race'], 42: ['stay', 'age', 'charge', 'sex'], 43: ['stay', 'age', 'charge', '#prior'], 44: ['stay', 'age', 'charge', 'race'], 45: ['stay', 'age', 'sex', '#prior'], 46: ['stay', 'age', 'sex', 'race'], 47: ['stay', 'age', '#prior', 'race'], 48: ['stay', 'charge', 'sex', '#prior'], 49: ['stay', 'charge', 'sex', 'race'], 50: ['stay', 'charge', '#prior', 'race'], 51: ['stay', 'sex', '#prior', 'race'], 52: ['age', 'charge', 'sex', '#prior'], 53: ['age', 'charge', 'sex', 'race'], 54: ['age', 'charge', '#prior', 'race'], 55: ['age', 'sex', '#prior', 'race'], 56: ['charge', 'sex', '#prior', 'race'], 57: ['stay', 'age', 'charge', 'sex', '#prior'], 58: ['stay', 'age', 'charge', 'sex', 'race'], 59: ['stay', 'age', 'charge', '#prior', 'race'], 60: ['stay', 'age', 'sex', '#prior', 'race'], 61: ['stay', 'charge', 'sex', '#prior', 'race'], 62: ['age', 'charge', 'sex', '#prior', 'race'], 63: ['stay', 'age', 'charge', 'sex', '#prior', 'race']}\n",
            "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
            "[63, 62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "TttueBgvg53C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Helper Functions\n"
      ],
      "metadata": {
        "id": "g4TwHPK4hd0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_one_degree_neighbors(temp2, names, group_lst):\n",
        "    result = []\n",
        "    for i in range(len(group_lst)):\n",
        "        d = copy.copy(temp2)\n",
        "        for k in range(len(group_lst)):\n",
        "            if k != i:\n",
        "                d = d[d[names[k]] == group_lst[k]]\n",
        "            else:\n",
        "                d = d[d[names[k]] != group_lst[k]]\n",
        "        # print(d)\n",
        "        result.append(d)\n",
        "    return result"
      ],
      "metadata": {
        "id": "wvC9RSgZkD80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62052025-28b9-4221-feb2-fdf26c981661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the pos/neg ration of this neighbor\n",
        "def compute_neighbors(group_lst, result):\n",
        "    # compute the ratio of positive and negative records\n",
        "    start2 = time.time()\n",
        "    pos = 0\n",
        "    neg = 0\n",
        "    for r in result:\n",
        "        total  = r['cnt'].sum()\n",
        "        r = r[r['class'] == 1]\n",
        "        pos += r['cnt'].sum()\n",
        "        neg += total - r['cnt'].sum()\n",
        "    if(neg == 0):\n",
        "        return (pos, neg, -1)\n",
        "    end2 = time.time()\n",
        "    # print(\"The time to compute the neighbor counts for \" +  str(group_lst) +\" is \" + str(end2-start2))\n",
        "    return(pos, neg, pos/neg)"
      ],
      "metadata": {
        "id": "sGQalez0kLkE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455fd9a9-e1e2-43c5-e433-c4142a5e4765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_diff_add_and_remove(group_lst, temp2, need_positive_or_negative, label, names):\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "        # print(len(d))\n",
        "    total =  d['cnt'].sum()\n",
        "    # Total here was 0: here, errors when this is commented out\n",
        "    if total == 0:\n",
        "      return -1\n",
        "    d = d[d[label] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    # print(d, group_lst)\n",
        "    neg = total - pos\n",
        "    result = get_one_degree_neighbors(temp2,names, group_lst)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(need_positive_or_negative == 1):\n",
        "        # need pos\n",
        "        x = Symbol('x')\n",
        "        # print(pos, neg , neighbors[2])\n",
        "        try:\n",
        "          diff = solve((pos + x)/ (neg - x) - neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "        # print(solve((pos + x)/ (neg - x) - neighbors[2]))\n",
        "    else:\n",
        "        #need negative\n",
        "        x = Symbol('x')\n",
        "        try:\n",
        "          diff = solve((pos - x)/ (neg + x) - neighbors[2])[0]\n",
        "        except:\n",
        "          return -1\n",
        "    print(neighbors[2],pos, neg, diff)\n",
        "    return diff"
      ],
      "metadata": {
        "id": "ijabVWcBjtCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f0838f-f7f7-4c17-b8b9-bf9784f31ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_diff_add(group_lst, temp2, names, label_y, need_positive_or_negative):\n",
        "    # print(\"compute diff\")\n",
        "    d = copy.copy(temp2)\n",
        "    # print(\"here\", d, names)\n",
        "    for i in range(len(group_lst)):\n",
        "        # print(d, group_lst[i])\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label_y] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    result = get_one_degree_neighbors(temp2, names, group_lst)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(need_positive_or_negative == 1):\n",
        "        # need pos\n",
        "        # if neg == 0:\n",
        "        #     # to avoid zero neg\n",
        "        #     neg = 1\n",
        "        x = Symbol('x')\n",
        "        diff = solve((pos + x)/ neg -  neighbors[2])[0]\n",
        "        # enough = neighbors[2] * neg\n",
        "        # diff = round_int(enough - pos)\n",
        "        print(neighbors[2], pos, neg, diff)\n",
        "    else:\n",
        "        #need negative\n",
        "        # if(pos == 0):\n",
        "        #     diff  = 0\n",
        "        #     enough = 0\n",
        "        # else:\n",
        "        # enough = pos / (neighbors[2] )\n",
        "        x = Symbol('x')\n",
        "        diff = solve(pos/ (neg + x) -  neighbors[2])[0]\n",
        "    print(neighbors[2], pos, neg, diff)\n",
        "    return diff\n",
        "\n",
        "def compute_diff_remove(group_lst, temp2, names, label_y, need_positive_or_negative):\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        # print(d, group_lst[i])\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label_y] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    result = get_one_degree_neighbors(temp2, names, group_lst)\n",
        "    neighbors = compute_neighbors(group_lst, result)\n",
        "    if(need_positive_or_negative == 1):\n",
        "        # need pos, remove some neg\n",
        "        x = Symbol('x')\n",
        "        diff = solve( pos/ (neg - x) -  neighbors[2])[0]\n",
        "        # enough = neighbors[2] * neg\n",
        "        # diff = round_int(enough - pos)\n",
        "        print(neighbors[2], pos, neg, diff)\n",
        "    else:\n",
        "        #need negative\n",
        "        x = Symbol('x')\n",
        "        diff = solve((pos -x )/ neg -  neighbors[2])[0]\n",
        "        print(neighbors[2], pos, neg, diff)\n",
        "    return diff\n"
      ],
      "metadata": {
        "id": "TH7YGCuh69D7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51ae034c-dd38-4829-8374-eaac43b1561f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "\n",
        "def div_results(db, remedy, algo):\n",
        "  columns_compas.extend([compas_y, \"predicted\"])\n",
        "\n",
        "  df = pd.DataFrame(test_set, columns = columns_compas)\n",
        "  # print(test_set.columns)\n",
        "  # print(columns_compas)\n",
        "  # print(df.columns)\n",
        "  # print(columns_compas)\n",
        "\n",
        "  columns_compas.remove(compas_y)\n",
        "  columns_compas.remove('predicted')\n",
        "  class_map={'N': 0, 'P': 1}\n",
        "\n",
        "  min_sup=0.1\n",
        "\n",
        "  # min_sup = 0.05\n",
        "\n",
        "  fp_diver=FP_DivergenceExplorer(df,compas_y, \"predicted\", class_map=class_map)\n",
        "  FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "  from divexplorer.FP_Divergence import FP_Divergence\n",
        "  fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "  fp_divergence_fnr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "  fp_divergence_acc=FP_Divergence(FP_fm, \"d_accuracy\")\n",
        "  # fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "  INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "  INFO_VIZ2=[\"support\", \"itemsets\",  fp_divergence_fnr.metric, fp_divergence_fnr.t_value_col]\n",
        "  INFO_VIZ3=[\"support\", \"itemsets\",  fp_divergence_acc.metric, fp_divergence_acc.t_value_col]\n",
        "\n",
        "  K=1000\n",
        "  pd.options.display.max_rows = 200\n",
        "  d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "  # summerization\n",
        "  eps=0.01\n",
        "\n",
        "  # d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ].head(K)\n",
        "  # d2 = fp_divergence_fnr.getDivergence(th_redundancy=eps)[INFO_VIZ2].head(K)\n",
        "  # d3 = fp_divergence_acc.getDivergence(th_redundancy=eps)[INFO_VIZ3].head(K)\n",
        "\n",
        "  d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ]\n",
        "  d2 = fp_divergence_fnr.getDivergence(th_redundancy=eps)[INFO_VIZ2]\n",
        "  d3 = fp_divergence_acc.getDivergence(th_redundancy=eps)[INFO_VIZ3]\n",
        "\n",
        "\n",
        "  d= d[d['d_fpr'] > 0]\n",
        "  d2= d2[d2['d_fnr'] > 0]\n",
        "  d3= d3[d3['d_accuracy'] > 0]\n",
        "  dfpr = fairness_score_computation(d, 'd_fpr')\n",
        "  dfnr = fairness_score_computation(d2, 'd_fnr')\n",
        "  dacc = fairness_score_computation(d3, 'd_accuracy')\n",
        "  print(dfpr)\n",
        "  print(dfnr)\n",
        "  print(dacc)\n",
        "  accuracy = accuracy_score(test_label, test_predict)\n",
        "  print(\"accuracy is \" , accuracy)\n",
        "  writelist = [db,remedy,algo, dfpr, dfnr, dacc, accuracy]\n",
        "  with open('COMPAS_results.csv', 'a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(writelist)\n",
        "  print(writelist)\n",
        "  return d,d2,d3"
      ],
      "metadata": {
        "id": "ZNtlejsp3sA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650fc3c8-122f-40da-cc15-5451dd8f8a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def div_results():\n",
        "#   class_map={'N': 0, 'P': 1}\n",
        "#   from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "\n",
        "#   min_sup=0.1\n",
        "\n",
        "#   # min_sup = 0.05\n",
        "\n",
        "#   fp_diver=FP_DivergenceExplorer(test_set,\"class\", \"predicted\", class_map=class_map)\n",
        "#   FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "#   from divexplorer.FP_Divergence import FP_Divergence\n",
        "#   fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "#   fp_divergence_fnr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "#   fp_divergence_acc=FP_Divergence(FP_fm, \"d_accuracy\")\n",
        "#   # fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "#   INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "#   INFO_VIZ2=[\"support\", \"itemsets\",  fp_divergence_fnr.metric, fp_divergence_fnr.t_value_col]\n",
        "#   INFO_VIZ3=[\"support\", \"itemsets\",  fp_divergence_acc.metric, fp_divergence_acc.t_value_col]\n",
        "\n",
        "#   K=10\n",
        "#   pd.options.display.max_rows = 200\n",
        "#   d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "#   # summerization\n",
        "#   eps=0.01\n",
        "\n",
        "#   d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ].head(K)\n",
        "#   d2 = fp_divergence_fnr.getDivergence(th_redundancy=eps)[INFO_VIZ2].head(K)\n",
        "#   d3 = fp_divergence_acc.getDivergence(th_redundancy=eps)[INFO_VIZ3].head(K)\n",
        "\n",
        "#   print(fairness_score_computation(d, 'd_fpr'))\n",
        "#   print(fairness_score_computation(d2, 'd_fnr'))\n",
        "#   print(fairness_score_computation(d3, 'd_accuracy'))\n",
        "#   accuracy = accuracy_score(test_label, test_predict)\n",
        "#   print(\"accuracy is \" , accuracy)\n",
        "#   return d,d2,d3"
      ],
      "metadata": {
        "id": "3J0EcLGqrH0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a048ecfc-4aa3-496f-8d72-5ec2315478c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimized Helper Function\n"
      ],
      "metadata": {
        "id": "4iEQ83nxkQr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function for optimized\n",
        "# def compute_neighbors_opt(group_lst,lst_of_counts, pos, neg):\n",
        "#     #start2 = time.time()\n",
        "#     times = len(group_lst)\n",
        "#     pos_cnt = 0\n",
        "#     neg_cnt = 0\n",
        "#     for i in range(times):\n",
        "#         df_groupby = lst_of_counts[i]\n",
        "#         temp_group_lst_pos = copy.copy(group_lst)\n",
        "#         temp_group_lst_neg = copy.copy(group_lst)\n",
        "#         del temp_group_lst_pos[i]\n",
        "#         del temp_group_lst_neg[i]\n",
        "#         # count positive\n",
        "#         temp_group_lst_pos.append(1)\n",
        "#         group_tuple_pos = tuple(temp_group_lst_pos)\n",
        "#         if group_tuple_pos in df_groupby.keys():\n",
        "#             pos_cnt += df_groupby[group_tuple_pos]\n",
        "#         else:\n",
        "#             pos_cnt += 0\n",
        "#         # count negative\n",
        "#         temp_group_lst_neg.append(0)\n",
        "#         group_tuple_neg = tuple(temp_group_lst_neg)\n",
        "#         if group_tuple_neg in df_groupby.keys():\n",
        "#             neg_cnt += df_groupby[group_tuple_neg]\n",
        "#         else:\n",
        "#             neg_cnt += 0\n",
        "#     pos_val = pos_cnt - times* pos\n",
        "#     neg_val = neg_cnt - times* neg\n",
        "#     #end2 = time.time()\n",
        "#     #print(\"The time to compute the neighbor counts for \" +  str(group_lst) +\" is \" + str(end2-start2))\n",
        "#     if neg_val == -1:\n",
        "#         return (pos_val, neg_val, -1)\n",
        "#     return (pos_val, neg_val, pos_val/neg_val)\n",
        "def compute_neighbors_opt(group_lst, lst_of_counts, pos, neg):\n",
        "    times = len(group_lst)\n",
        "    pos_cnt = 0\n",
        "    neg_cnt = 0\n",
        "    for i in range(times):\n",
        "        df_groupby = lst_of_counts[i]\n",
        "        if len(df_groupby) == 2: # for the first layer\n",
        "            pos_val = df_groupby[1] - pos\n",
        "            neg_val = df_groupby[0] - neg\n",
        "        else:\n",
        "            temp_group_lst_pos = copy.copy(group_lst)\n",
        "            temp_group_lst_neg = copy.copy(group_lst)\n",
        "            del temp_group_lst_pos[i]\n",
        "            del temp_group_lst_neg[i]\n",
        "            # count positive\n",
        "            temp_group_lst_pos.append(1)\n",
        "            group_tuple_pos = tuple(temp_group_lst_pos)\n",
        "            if group_tuple_pos in df_groupby.keys():\n",
        "                pos_cnt += df_groupby[group_tuple_pos]\n",
        "            else:\n",
        "                pos_cnt += 0\n",
        "            # count negative\n",
        "            temp_group_lst_neg.append(0)\n",
        "            group_tuple_neg = tuple(temp_group_lst_neg)\n",
        "            if group_tuple_neg in df_groupby.keys():\n",
        "                neg_cnt += df_groupby[group_tuple_neg]\n",
        "            else:\n",
        "                neg_cnt += 0\n",
        "            pos_val = pos_cnt - times* pos\n",
        "            neg_val = neg_cnt - times* neg\n",
        "    if neg_val == -1:\n",
        "        return (pos_val, neg_val, -1)\n",
        "    return (pos_val, neg_val, pos_val/neg_val)"
      ],
      "metadata": {
        "id": "vuxfZHSlhXNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8f0717-d3aa-4967-9b83-d7936de9c8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the list of neighbors\n",
        "def get_one_degree_neighbors_opt(group_lst):\n",
        "    start1 = time.time()\n",
        "    result = []\n",
        "    for i in range(len(group_lst)):\n",
        "        d = copy.copy(group_lst)\n",
        "        d[i] = 'x'\n",
        "        result.append(d)\n",
        "    end1 = time.time()\n",
        "    return result"
      ],
      "metadata": {
        "id": "J8Iny4kJhm4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6d36c3-0b14-435a-8203-d823d53ae7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_problematic_opt(group_lst, names, temp2, lst_of_counts, label, threshold= 0.3):\n",
        "    #0: ok group, 1: need negative records, 2: need positive records\n",
        "    d = copy.copy(temp2)\n",
        "    for i in range(len(group_lst)):\n",
        "        d = d[d[names[i]] == group_lst[i]]\n",
        "    total =  d['cnt'].sum()\n",
        "    d = d[d[label] == 1]\n",
        "    pos = d['cnt'].sum()\n",
        "    neg = total - pos\n",
        "    neighbors = compute_neighbors_opt(group_lst,lst_of_counts, pos, neg)\n",
        "    if(neighbors[2] == -1):\n",
        "        # there is no neighbors\n",
        "        return 0\n",
        "    if(total > 30):\n",
        "        # need to be large enough, need to adjust with different datasets.\n",
        "        if neg == 0:\n",
        "            if (pos > neighbors[2]):\n",
        "                return 1\n",
        "            if(pos <= neighbors[2]):\n",
        "                return 0\n",
        "        if (pos/(neg) - neighbors[2] > threshold):\n",
        "            # too many positive records\n",
        "            return 1\n",
        "        if (neighbors[2] - pos/(neg) > threshold):\n",
        "            return 2\n",
        "    return 0"
      ],
      "metadata": {
        "id": "1MmwA0X5hofE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db97f251-bf8f-4862-f67f-bd328ec54c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_problematic_opt(temp2, temp_g, names, label, lst_of_counts):\n",
        "    need_pos = []\n",
        "    need_neg = []\n",
        "    for index, row in temp_g.iterrows():\n",
        "        group_lst = []\n",
        "        for n in names:\n",
        "            group_lst.append(row[n])\n",
        "        problematic = determine_problematic_opt(group_lst, names, temp2, lst_of_counts,label)\n",
        "#         #print(problematic)\n",
        "        if(problematic == 1):\n",
        "            if group_lst not in need_neg:\n",
        "                need_neg.append(group_lst)\n",
        "        if(problematic == 2):\n",
        "            if group_lst not in need_pos:\n",
        "                need_pos.append(group_lst)\n",
        "    return need_pos, need_neg"
      ],
      "metadata": {
        "id": "A76VlG-bhqqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea5a725f-5e73-440c-f879-8717dd866fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the list of X00\n",
        "def compute_lst_of_counts(temp, names, label):\n",
        "    # get the list of group-by attributes\n",
        "    lst_of_counts = []\n",
        "    for i in range(len(names)):\n",
        "        grp_names = copy.copy(names)\n",
        "        del grp_names[i]\n",
        "        grp_names.append(label)\n",
        "        temp_df = temp.groupby(grp_names)['cnt'].count()\n",
        "        lst_of_counts.append(temp_df)\n",
        "    return lst_of_counts\n",
        "\n",
        "def get_tuple(group_lst):\n",
        "    return tuple(group_lst)\n",
        "\n",
        "\n",
        "def get_temp_g(train_set, names, y_label):\n",
        "  names2 = copy.deepcopy(names)\n",
        "  names2.append(y_label)\n",
        "  temp = train_set[names2]\n",
        "  temp['cnt'] = 0\n",
        "  temp_g = temp.groupby(names)['cnt'].count().reset_index()\n",
        "  return temp, temp_g"
      ],
      "metadata": {
        "id": "tZd2c6PAhtTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3b91d3-84b7-497b-922a-4544d4ac65fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preferential Sampling"
      ],
      "metadata": {
        "id": "qnQ09ffAkalO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "def pref_sampling_opt(train_set, cols_given, label, need_pos, need_neg):\n",
        "    if len(need_pos)+ len(need_neg) > 0:\n",
        "        temp_train_x = pd.DataFrame(train_set, columns = columns_all)\n",
        "        temp_train_label = pd.DataFrame(train_set, columns = [label])\n",
        "        temp_train_label = temp_train_label[label]\n",
        "        temp_train_label = temp_train_label.astype('int')\n",
        "        mnb = MultinomialNB()\n",
        "        mnb = mnb.fit(temp_train_x, temp_train_label)\n",
        "        probs = mnb.predict_proba(temp_train_x)[:,0]\n",
        "        train_set[\"prob\"] = abs(probs - 0.5)\n",
        "        # get the set of\n",
        "    new_train_set = pd.DataFrame(columns = list(train_set.columns))\n",
        "    updated_pos = 0\n",
        "    for i in need_pos:\n",
        "        # needs to updated more positive records\n",
        "        # print(i)\n",
        "        temp_df = copy.deepcopy(train_set)\n",
        "        for n in range(len(i)):\n",
        "          temp_df = temp_df[temp_df[cols_given[n]] == i[n]]\n",
        "        # update the skew and diff\n",
        "        idx = list(temp_df.index)\n",
        "        train_set.loc[idx, 'skewed'] = 1\n",
        "        idx_pos = list(temp_df[(getattr(temp_df, label) == 1)].index)\n",
        "        if(len(idx_pos) == 0):\n",
        "          # if there is no positive\n",
        "          idx_neg = list(temp_df[(getattr(temp_df, label) == 0)].index)\n",
        "          neg_ranked = train_set.loc[idx_neg].sort_values(by=\"prob\", ascending=True)\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          continue\n",
        "        idx_neg = list(temp_df[(getattr(temp_df, label) == 0)].index)\n",
        "        pos_ranked = train_set.loc[idx_pos].sort_values(by=\"prob\", ascending=True)\n",
        "        neg_ranked = train_set.loc[idx_neg].sort_values(by=\"prob\", ascending=True)\n",
        "        diff = compute_diff_add_and_remove(i, temp2,  1, compas_y, names)\n",
        "        if diff == -1:\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          continue\n",
        "        train_set.loc[idx, 'diff'] = int(diff)\n",
        "        cnt = int(train_set.loc[idx_pos[0]][\"diff\"])\n",
        "        updated_pos += cnt * 2\n",
        "        # add more records when there are not enough available records\n",
        "        new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "        temp_cnt = cnt\n",
        "        if len(pos_ranked) >= temp_cnt:\n",
        "            new_train_set = pd.concat([new_train_set,pos_ranked[0:cnt]], ignore_index=True)\n",
        "        else:\n",
        "            while(temp_cnt > 0 ):\n",
        "                new_train_set = pd.concat([new_train_set,pos_ranked[0:temp_cnt]], ignore_index=True)\n",
        "            # duplicate the dataframe\n",
        "                temp_cnt = temp_cnt - len(pos_ranked)\n",
        "        # duplicate the top cnt records from the pos\n",
        "        # remove the top cnt records from the neg\n",
        "        if cnt == 0:\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "          # print(\"+++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "          # print(i)\n",
        "          # print(len(pos_ranked)+cnt)\n",
        "          # print(len(neg_ranked))\n",
        "        else:\n",
        "          new_train_set = pd.concat([new_train_set, neg_ranked[cnt-1:-1]], ignore_index=True)\n",
        "          # print(\"+++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "          # print(i)\n",
        "          # print(len(pos_ranked)+cnt)\n",
        "          # print(len(neg_ranked[cnt-1:-1]))\n",
        "    print(\"updated {} positive records\".format(str(updated_pos)))\n",
        "    updated_neg = 0\n",
        "    # adding more records to the need_neg set\n",
        "    for i in need_neg:\n",
        "        # print(i)\n",
        "        # list of idx belongs to this group\n",
        "        temp_df = copy.deepcopy(train_set)\n",
        "        for n in range(len(i)):\n",
        "          temp_df = temp_df[temp_df[cols_given[n]] == i[n]]\n",
        "        # update the skew and diff\n",
        "        idx = list(temp_df.index)\n",
        "        train_set.loc[idx, 'skewed'] = 1\n",
        "        idx_pos = list(temp_df[(getattr(temp_df, label) == 1)].index)\n",
        "        idx_neg = list(temp_df[(getattr(temp_df, label) == 0)].index)\n",
        "        if(len(idx_neg) == 0):\n",
        "          pos_ranked = train_set.loc[idx_pos].sort_values(by=\"prob\", ascending=True)\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          continue\n",
        "        pos_ranked = train_set.loc[idx_pos].sort_values(by=\"prob\", ascending=True)\n",
        "        neg_ranked = train_set.loc[idx_neg].sort_values(by=\"prob\", ascending=True)\n",
        "        diff = compute_diff_add_and_remove(i, temp2, 0, compas_y, names)\n",
        "        if diff == -1:\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          continue\n",
        "        train_set.loc[idx, 'diff'] = int(diff)\n",
        "        cnt = int(train_set.loc[idx_pos[0]][\"diff\"])\n",
        "        updated_neg += cnt * 2\n",
        "        # add more records when there are not enough available records\n",
        "        new_train_set = pd.concat([new_train_set, neg_ranked], ignore_index=True)\n",
        "        temp_cnt = cnt\n",
        "        if len(neg_ranked) >= temp_cnt:\n",
        "            new_train_set = pd.concat([new_train_set,neg_ranked[0:cnt]], ignore_index=True)\n",
        "        else:\n",
        "            while(temp_cnt > 0 ):\n",
        "                new_train_set = pd.concat([new_train_set,neg_ranked[0:temp_cnt]], ignore_index=True)\n",
        "            # duplicate the dataframe\n",
        "                temp_cnt = temp_cnt - len(neg_ranked)\n",
        "        # duplicate the top cnt records from the pos\n",
        "        # remove the top cnt records from the neg\n",
        "        if cnt ==0:\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked], ignore_index=True)\n",
        "          # print(\"+++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "          # print(i)\n",
        "          # print(len(neg_ranked)+cnt)\n",
        "          # print(len(pos_ranked))\n",
        "        else:\n",
        "          new_train_set = pd.concat([new_train_set, pos_ranked[cnt-1:-1]], ignore_index=True)\n",
        "          # print(\"+++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "          # print(i)\n",
        "          # print(len(neg_ranked)+cnt)\n",
        "          # print(len(pos_ranked[cnt-1:-1]))\n",
        "        #print(len(new_train_set[new_train_set['income'] == 1]), len(new_train_set[new_train_set['income'] == 0]))\n",
        "        # print(train_set.loc[idx_neg])\n",
        "    print(\"updated {} negative records\".format(str(updated_neg)))\n",
        "    # add the other irrelavant items:\n",
        "    idx_irr = list(train_set[train_set['skewed'] == 0].index)\n",
        "    irr_df = train_set.loc[idx_irr]\n",
        "    new_train_set = pd.concat([new_train_set, irr_df], ignore_index=True)\n",
        "    print(\"The new dataset contains {} rows.\".format(str(len(new_train_set))))\n",
        "    new_train_set.reset_index()\n",
        "    return new_train_set\n"
      ],
      "metadata": {
        "id": "2L4D0kJ7h2lS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022d045e-8305-4f37-b76f-d022472804ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_all = columns_compas"
      ],
      "metadata": {
        "id": "vMrjlEciiv--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b589397-28e2-4e6c-de57-b64af0c6d237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "unfair_group, unfair_names, skew_candidates, unfair_dict = get_unfair_group([])\n",
        "print(unfair_group, unfair_names, skew_candidates, unfair_dict)\n",
        "combos_dict, all_names = candidate_groups(skew_candidates, unfair_dict, columns_compas, unfair_names)\n",
        "print(combos_dict, all_names)\n",
        "\n",
        "# the\n",
        "print(list(all_names.keys())[len(columns_compas)+1:])\n",
        "all_names_lst = list(all_names.keys())[len(columns_compas)+1:]\n",
        "all_names_lst.reverse()\n",
        "print(all_names_lst)\n",
        "\n",
        "def find_top(all_names):\n",
        "  all_names_lst_top = []\n",
        "  for all in range(len(all_names)):\n",
        "    if len(all_names[all]) == 1: #CHANGED HERE\n",
        "      all_names_lst_top.append(all)\n",
        "  return all_names_lst_top"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paqO9W2jeTMX",
        "outputId": "3393eb44-e6f8-43b5-8d80-7724e9faee07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[] [] ['stay', 'age', 'charge', 'sex', '#prior', 'race'] {}\n",
            "{0: [[]], 1: [[0], [1], [2]], 2: [[0], [1], [2]], 3: [[1], [0]], 4: [[0], [1]], 5: [[2], [1], [0]], 6: [[2], [1], [0], [3], [4], [5]], 7: [[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]], 8: [[0, 1], [0, 0], [1, 1], [1, 0], [2, 1], [2, 0]], 9: [[0, 0], [0, 1], [1, 0], [1, 1], [2, 0], [2, 1]], 10: [[0, 2], [0, 1], [0, 0], [1, 2], [1, 1], [1, 0], [2, 2], [2, 1], [2, 0]], 11: [[0, 2], [0, 1], [0, 0], [0, 3], [0, 4], [0, 5], [1, 2], [1, 1], [1, 0], [1, 3], [1, 4], [1, 5], [2, 2], [2, 1], [2, 0], [2, 3], [2, 4], [2, 5]], 12: [[0, 1], [0, 0], [1, 1], [1, 0], [2, 1], [2, 0]], 13: [[0, 0], [0, 1], [1, 0], [1, 1], [2, 0], [2, 1]], 14: [[0, 2], [0, 1], [0, 0], [1, 2], [1, 1], [1, 0], [2, 2], [2, 1], [2, 0]], 15: [[0, 2], [0, 1], [0, 0], [0, 3], [0, 4], [0, 5], [1, 2], [1, 1], [1, 0], [1, 3], [1, 4], [1, 5], [2, 2], [2, 1], [2, 0], [2, 3], [2, 4], [2, 5]], 16: [[1, 0], [1, 1], [0, 0], [0, 1]], 17: [[1, 2], [1, 1], [1, 0], [0, 2], [0, 1], [0, 0]], 18: [[1, 2], [1, 1], [1, 0], [1, 3], [1, 4], [1, 5], [0, 2], [0, 1], [0, 0], [0, 3], [0, 4], [0, 5]], 19: [[0, 2], [0, 1], [0, 0], [1, 2], [1, 1], [1, 0]], 20: [[0, 2], [0, 1], [0, 0], [0, 3], [0, 4], [0, 5], [1, 2], [1, 1], [1, 0], [1, 3], [1, 4], [1, 5]], 21: [[2, 2], [2, 1], [2, 0], [2, 3], [2, 4], [2, 5], [1, 2], [1, 1], [1, 0], [1, 3], [1, 4], [1, 5], [0, 2], [0, 1], [0, 0], [0, 3], [0, 4], [0, 5]], 22: [[0, 0, 1], [0, 0, 0], [0, 1, 1], [0, 1, 0], [0, 2, 1], [0, 2, 0], [1, 0, 1], [1, 0, 0], [1, 1, 1], [1, 1, 0], [1, 2, 1], [1, 2, 0], [2, 0, 1], [2, 0, 0], [2, 1, 1], [2, 1, 0], [2, 2, 1], [2, 2, 0]], 23: [[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [0, 2, 0], [0, 2, 1], [1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1], [1, 2, 0], [1, 2, 1], [2, 0, 0], [2, 0, 1], [2, 1, 0], [2, 1, 1], [2, 2, 0], [2, 2, 1]], 24: [[0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 2, 2], [0, 2, 1], [0, 2, 0], [1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 2, 2], [1, 2, 1], [1, 2, 0], [2, 0, 2], [2, 0, 1], [2, 0, 0], [2, 1, 2], [2, 1, 1], [2, 1, 0], [2, 2, 2], [2, 2, 1], [2, 2, 0]], 25: [[0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 0, 3], [0, 0, 4], [0, 0, 5], [0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 1, 3], [0, 1, 4], [0, 1, 5], [0, 2, 2], [0, 2, 1], [0, 2, 0], [0, 2, 3], [0, 2, 4], [0, 2, 5], [1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 0, 3], [1, 0, 4], [1, 0, 5], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 1, 3], [1, 1, 4], [1, 1, 5], [1, 2, 2], [1, 2, 1], [1, 2, 0], [1, 2, 3], [1, 2, 4], [1, 2, 5], [2, 0, 2], [2, 0, 1], [2, 0, 0], [2, 0, 3], [2, 0, 4], [2, 0, 5], [2, 1, 2], [2, 1, 1], [2, 1, 0], [2, 1, 3], [2, 1, 4], [2, 1, 5], [2, 2, 2], [2, 2, 1], [2, 2, 0], [2, 2, 3], [2, 2, 4], [2, 2, 5]], 26: [[0, 1, 0], [0, 1, 1], [0, 0, 0], [0, 0, 1], [1, 1, 0], [1, 1, 1], [1, 0, 0], [1, 0, 1], [2, 1, 0], [2, 1, 1], [2, 0, 0], [2, 0, 1]], 27: [[0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 0, 2], [0, 0, 1], [0, 0, 0], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 0, 2], [1, 0, 1], [1, 0, 0], [2, 1, 2], [2, 1, 1], [2, 1, 0], [2, 0, 2], [2, 0, 1], [2, 0, 0]], 28: [[0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 1, 3], [0, 1, 4], [0, 1, 5], [0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 0, 3], [0, 0, 4], [0, 0, 5], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 1, 3], [1, 1, 4], [1, 1, 5], [1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 0, 3], [1, 0, 4], [1, 0, 5], [2, 1, 2], [2, 1, 1], [2, 1, 0], [2, 1, 3], [2, 1, 4], [2, 1, 5], [2, 0, 2], [2, 0, 1], [2, 0, 0], [2, 0, 3], [2, 0, 4], [2, 0, 5]], 29: [[0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 1, 2], [0, 1, 1], [0, 1, 0], [1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 1, 2], [1, 1, 1], [1, 1, 0], [2, 0, 2], [2, 0, 1], [2, 0, 0], [2, 1, 2], [2, 1, 1], [2, 1, 0]], 30: [[0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 0, 3], [0, 0, 4], [0, 0, 5], [0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 1, 3], [0, 1, 4], [0, 1, 5], [1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 0, 3], [1, 0, 4], [1, 0, 5], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 1, 3], [1, 1, 4], [1, 1, 5], [2, 0, 2], [2, 0, 1], [2, 0, 0], [2, 0, 3], [2, 0, 4], [2, 0, 5], [2, 1, 2], [2, 1, 1], [2, 1, 0], [2, 1, 3], [2, 1, 4], [2, 1, 5]], 31: [[0, 2, 2], [0, 2, 1], [0, 2, 0], [0, 2, 3], [0, 2, 4], [0, 2, 5], [0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 1, 3], [0, 1, 4], [0, 1, 5], [0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 0, 3], [0, 0, 4], [0, 0, 5], [1, 2, 2], [1, 2, 1], [1, 2, 0], [1, 2, 3], [1, 2, 4], [1, 2, 5], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 1, 3], [1, 1, 4], [1, 1, 5], [1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 0, 3], [1, 0, 4], [1, 0, 5], [2, 2, 2], [2, 2, 1], [2, 2, 0], [2, 2, 3], [2, 2, 4], [2, 2, 5], [2, 1, 2], [2, 1, 1], [2, 1, 0], [2, 1, 3], [2, 1, 4], [2, 1, 5], [2, 0, 2], [2, 0, 1], [2, 0, 0], [2, 0, 3], [2, 0, 4], [2, 0, 5]], 32: [[0, 1, 0], [0, 1, 1], [0, 0, 0], [0, 0, 1], [1, 1, 0], [1, 1, 1], [1, 0, 0], [1, 0, 1], [2, 1, 0], [2, 1, 1], [2, 0, 0], [2, 0, 1]], 33: [[0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 0, 2], [0, 0, 1], [0, 0, 0], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 0, 2], [1, 0, 1], [1, 0, 0], [2, 1, 2], [2, 1, 1], [2, 1, 0], [2, 0, 2], [2, 0, 1], [2, 0, 0]], 34: [[0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 1, 3], [0, 1, 4], [0, 1, 5], [0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 0, 3], [0, 0, 4], [0, 0, 5], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 1, 3], [1, 1, 4], [1, 1, 5], [1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 0, 3], [1, 0, 4], [1, 0, 5], [2, 1, 2], [2, 1, 1], [2, 1, 0], [2, 1, 3], [2, 1, 4], [2, 1, 5], [2, 0, 2], [2, 0, 1], [2, 0, 0], [2, 0, 3], [2, 0, 4], [2, 0, 5]], 35: [[0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 1, 2], [0, 1, 1], [0, 1, 0], [1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 1, 2], [1, 1, 1], [1, 1, 0], [2, 0, 2], [2, 0, 1], [2, 0, 0], [2, 1, 2], [2, 1, 1], [2, 1, 0]], 36: [[0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 0, 3], [0, 0, 4], [0, 0, 5], [0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 1, 3], [0, 1, 4], [0, 1, 5], [1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 0, 3], [1, 0, 4], [1, 0, 5], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 1, 3], [1, 1, 4], [1, 1, 5], [2, 0, 2], [2, 0, 1], [2, 0, 0], [2, 0, 3], [2, 0, 4], [2, 0, 5], [2, 1, 2], [2, 1, 1], [2, 1, 0], [2, 1, 3], [2, 1, 4], [2, 1, 5]], 37: [[0, 2, 2], [0, 2, 1], [0, 2, 0], [0, 2, 3], [0, 2, 4], [0, 2, 5], [0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 1, 3], [0, 1, 4], [0, 1, 5], [0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 0, 3], [0, 0, 4], [0, 0, 5], [1, 2, 2], [1, 2, 1], [1, 2, 0], [1, 2, 3], [1, 2, 4], [1, 2, 5], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 1, 3], [1, 1, 4], [1, 1, 5], [1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 0, 3], [1, 0, 4], [1, 0, 5], [2, 2, 2], [2, 2, 1], [2, 2, 0], [2, 2, 3], [2, 2, 4], [2, 2, 5], [2, 1, 2], [2, 1, 1], [2, 1, 0], [2, 1, 3], [2, 1, 4], [2, 1, 5], [2, 0, 2], [2, 0, 1], [2, 0, 0], [2, 0, 3], [2, 0, 4], [2, 0, 5]], 38: [[1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 1, 2], [1, 1, 1], [1, 1, 0], [0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 1, 2], [0, 1, 1], [0, 1, 0]], 39: [[1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 0, 3], [1, 0, 4], [1, 0, 5], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 1, 3], [1, 1, 4], [1, 1, 5], [0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 0, 3], [0, 0, 4], [0, 0, 5], [0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 1, 3], [0, 1, 4], [0, 1, 5]], 40: [[1, 2, 2], [1, 2, 1], [1, 2, 0], [1, 2, 3], [1, 2, 4], [1, 2, 5], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 1, 3], [1, 1, 4], [1, 1, 5], [1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 0, 3], [1, 0, 4], [1, 0, 5], [0, 2, 2], [0, 2, 1], [0, 2, 0], [0, 2, 3], [0, 2, 4], [0, 2, 5], [0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 1, 3], [0, 1, 4], [0, 1, 5], [0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 0, 3], [0, 0, 4], [0, 0, 5]], 41: [[0, 2, 2], [0, 2, 1], [0, 2, 0], [0, 2, 3], [0, 2, 4], [0, 2, 5], [0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 1, 3], [0, 1, 4], [0, 1, 5], [0, 0, 2], [0, 0, 1], [0, 0, 0], [0, 0, 3], [0, 0, 4], [0, 0, 5], [1, 2, 2], [1, 2, 1], [1, 2, 0], [1, 2, 3], [1, 2, 4], [1, 2, 5], [1, 1, 2], [1, 1, 1], [1, 1, 0], [1, 1, 3], [1, 1, 4], [1, 1, 5], [1, 0, 2], [1, 0, 1], [1, 0, 0], [1, 0, 3], [1, 0, 4], [1, 0, 5]], 42: [[0, 0, 1, 0], [0, 0, 1, 1], [0, 0, 0, 0], [0, 0, 0, 1], [0, 1, 1, 0], [0, 1, 1, 1], [0, 1, 0, 0], [0, 1, 0, 1], [0, 2, 1, 0], [0, 2, 1, 1], [0, 2, 0, 0], [0, 2, 0, 1], [1, 0, 1, 0], [1, 0, 1, 1], [1, 0, 0, 0], [1, 0, 0, 1], [1, 1, 1, 0], [1, 1, 1, 1], [1, 1, 0, 0], [1, 1, 0, 1], [1, 2, 1, 0], [1, 2, 1, 1], [1, 2, 0, 0], [1, 2, 0, 1], [2, 0, 1, 0], [2, 0, 1, 1], [2, 0, 0, 0], [2, 0, 0, 1], [2, 1, 1, 0], [2, 1, 1, 1], [2, 1, 0, 0], [2, 1, 0, 1], [2, 2, 1, 0], [2, 2, 1, 1], [2, 2, 0, 0], [2, 2, 0, 1]], 43: [[0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 2, 1, 2], [0, 2, 1, 1], [0, 2, 1, 0], [0, 2, 0, 2], [0, 2, 0, 1], [0, 2, 0, 0], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 2, 1, 2], [1, 2, 1, 1], [1, 2, 1, 0], [1, 2, 0, 2], [1, 2, 0, 1], [1, 2, 0, 0], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 2, 1, 2], [2, 2, 1, 1], [2, 2, 1, 0], [2, 2, 0, 2], [2, 2, 0, 1], [2, 2, 0, 0]], 44: [[0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [0, 0, 1, 3], [0, 0, 1, 4], [0, 0, 1, 5], [0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 3], [0, 0, 0, 4], [0, 0, 0, 5], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 1, 3], [0, 1, 1, 4], [0, 1, 1, 5], [0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 0, 3], [0, 1, 0, 4], [0, 1, 0, 5], [0, 2, 1, 2], [0, 2, 1, 1], [0, 2, 1, 0], [0, 2, 1, 3], [0, 2, 1, 4], [0, 2, 1, 5], [0, 2, 0, 2], [0, 2, 0, 1], [0, 2, 0, 0], [0, 2, 0, 3], [0, 2, 0, 4], [0, 2, 0, 5], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 1, 3], [1, 0, 1, 4], [1, 0, 1, 5], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 0, 3], [1, 0, 0, 4], [1, 0, 0, 5], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 1, 3], [1, 1, 1, 4], [1, 1, 1, 5], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 0, 3], [1, 1, 0, 4], [1, 1, 0, 5], [1, 2, 1, 2], [1, 2, 1, 1], [1, 2, 1, 0], [1, 2, 1, 3], [1, 2, 1, 4], [1, 2, 1, 5], [1, 2, 0, 2], [1, 2, 0, 1], [1, 2, 0, 0], [1, 2, 0, 3], [1, 2, 0, 4], [1, 2, 0, 5], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0], [2, 0, 1, 3], [2, 0, 1, 4], [2, 0, 1, 5], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 0, 0, 3], [2, 0, 0, 4], [2, 0, 0, 5], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 1, 1, 3], [2, 1, 1, 4], [2, 1, 1, 5], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 1, 0, 3], [2, 1, 0, 4], [2, 1, 0, 5], [2, 2, 1, 2], [2, 2, 1, 1], [2, 2, 1, 0], [2, 2, 1, 3], [2, 2, 1, 4], [2, 2, 1, 5], [2, 2, 0, 2], [2, 2, 0, 1], [2, 2, 0, 0], [2, 2, 0, 3], [2, 2, 0, 4], [2, 2, 0, 5]], 45: [[0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 2, 0, 2], [0, 2, 0, 1], [0, 2, 0, 0], [0, 2, 1, 2], [0, 2, 1, 1], [0, 2, 1, 0], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 2, 0, 2], [1, 2, 0, 1], [1, 2, 0, 0], [1, 2, 1, 2], [1, 2, 1, 1], [1, 2, 1, 0], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 2, 0, 2], [2, 2, 0, 1], [2, 2, 0, 0], [2, 2, 1, 2], [2, 2, 1, 1], [2, 2, 1, 0]], 46: [[0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 3], [0, 0, 0, 4], [0, 0, 0, 5], [0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [0, 0, 1, 3], [0, 0, 1, 4], [0, 0, 1, 5], [0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 0, 3], [0, 1, 0, 4], [0, 1, 0, 5], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 1, 3], [0, 1, 1, 4], [0, 1, 1, 5], [0, 2, 0, 2], [0, 2, 0, 1], [0, 2, 0, 0], [0, 2, 0, 3], [0, 2, 0, 4], [0, 2, 0, 5], [0, 2, 1, 2], [0, 2, 1, 1], [0, 2, 1, 0], [0, 2, 1, 3], [0, 2, 1, 4], [0, 2, 1, 5], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 0, 3], [1, 0, 0, 4], [1, 0, 0, 5], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 1, 3], [1, 0, 1, 4], [1, 0, 1, 5], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 0, 3], [1, 1, 0, 4], [1, 1, 0, 5], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 1, 3], [1, 1, 1, 4], [1, 1, 1, 5], [1, 2, 0, 2], [1, 2, 0, 1], [1, 2, 0, 0], [1, 2, 0, 3], [1, 2, 0, 4], [1, 2, 0, 5], [1, 2, 1, 2], [1, 2, 1, 1], [1, 2, 1, 0], [1, 2, 1, 3], [1, 2, 1, 4], [1, 2, 1, 5], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 0, 0, 3], [2, 0, 0, 4], [2, 0, 0, 5], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0], [2, 0, 1, 3], [2, 0, 1, 4], [2, 0, 1, 5], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 1, 0, 3], [2, 1, 0, 4], [2, 1, 0, 5], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 1, 1, 3], [2, 1, 1, 4], [2, 1, 1, 5], [2, 2, 0, 2], [2, 2, 0, 1], [2, 2, 0, 0], [2, 2, 0, 3], [2, 2, 0, 4], [2, 2, 0, 5], [2, 2, 1, 2], [2, 2, 1, 1], [2, 2, 1, 0], [2, 2, 1, 3], [2, 2, 1, 4], [2, 2, 1, 5]], 47: [[0, 0, 2, 2], [0, 0, 2, 1], [0, 0, 2, 0], [0, 0, 2, 3], [0, 0, 2, 4], [0, 0, 2, 5], [0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [0, 0, 1, 3], [0, 0, 1, 4], [0, 0, 1, 5], [0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 3], [0, 0, 0, 4], [0, 0, 0, 5], [0, 1, 2, 2], [0, 1, 2, 1], [0, 1, 2, 0], [0, 1, 2, 3], [0, 1, 2, 4], [0, 1, 2, 5], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 1, 3], [0, 1, 1, 4], [0, 1, 1, 5], [0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 0, 3], [0, 1, 0, 4], [0, 1, 0, 5], [0, 2, 2, 2], [0, 2, 2, 1], [0, 2, 2, 0], [0, 2, 2, 3], [0, 2, 2, 4], [0, 2, 2, 5], [0, 2, 1, 2], [0, 2, 1, 1], [0, 2, 1, 0], [0, 2, 1, 3], [0, 2, 1, 4], [0, 2, 1, 5], [0, 2, 0, 2], [0, 2, 0, 1], [0, 2, 0, 0], [0, 2, 0, 3], [0, 2, 0, 4], [0, 2, 0, 5], [1, 0, 2, 2], [1, 0, 2, 1], [1, 0, 2, 0], [1, 0, 2, 3], [1, 0, 2, 4], [1, 0, 2, 5], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 1, 3], [1, 0, 1, 4], [1, 0, 1, 5], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 0, 3], [1, 0, 0, 4], [1, 0, 0, 5], [1, 1, 2, 2], [1, 1, 2, 1], [1, 1, 2, 0], [1, 1, 2, 3], [1, 1, 2, 4], [1, 1, 2, 5], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 1, 3], [1, 1, 1, 4], [1, 1, 1, 5], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 0, 3], [1, 1, 0, 4], [1, 1, 0, 5], [1, 2, 2, 2], [1, 2, 2, 1], [1, 2, 2, 0], [1, 2, 2, 3], [1, 2, 2, 4], [1, 2, 2, 5], [1, 2, 1, 2], [1, 2, 1, 1], [1, 2, 1, 0], [1, 2, 1, 3], [1, 2, 1, 4], [1, 2, 1, 5], [1, 2, 0, 2], [1, 2, 0, 1], [1, 2, 0, 0], [1, 2, 0, 3], [1, 2, 0, 4], [1, 2, 0, 5], [2, 0, 2, 2], [2, 0, 2, 1], [2, 0, 2, 0], [2, 0, 2, 3], [2, 0, 2, 4], [2, 0, 2, 5], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0], [2, 0, 1, 3], [2, 0, 1, 4], [2, 0, 1, 5], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 0, 0, 3], [2, 0, 0, 4], [2, 0, 0, 5], [2, 1, 2, 2], [2, 1, 2, 1], [2, 1, 2, 0], [2, 1, 2, 3], [2, 1, 2, 4], [2, 1, 2, 5], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 1, 1, 3], [2, 1, 1, 4], [2, 1, 1, 5], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 1, 0, 3], [2, 1, 0, 4], [2, 1, 0, 5], [2, 2, 2, 2], [2, 2, 2, 1], [2, 2, 2, 0], [2, 2, 2, 3], [2, 2, 2, 4], [2, 2, 2, 5], [2, 2, 1, 2], [2, 2, 1, 1], [2, 2, 1, 0], [2, 2, 1, 3], [2, 2, 1, 4], [2, 2, 1, 5], [2, 2, 0, 2], [2, 2, 0, 1], [2, 2, 0, 0], [2, 2, 0, 3], [2, 2, 0, 4], [2, 2, 0, 5]], 48: [[0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0]], 49: [[0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 0, 3], [0, 1, 0, 4], [0, 1, 0, 5], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 1, 3], [0, 1, 1, 4], [0, 1, 1, 5], [0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 3], [0, 0, 0, 4], [0, 0, 0, 5], [0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [0, 0, 1, 3], [0, 0, 1, 4], [0, 0, 1, 5], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 0, 3], [1, 1, 0, 4], [1, 1, 0, 5], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 1, 3], [1, 1, 1, 4], [1, 1, 1, 5], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 0, 3], [1, 0, 0, 4], [1, 0, 0, 5], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 1, 3], [1, 0, 1, 4], [1, 0, 1, 5], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 1, 0, 3], [2, 1, 0, 4], [2, 1, 0, 5], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 1, 1, 3], [2, 1, 1, 4], [2, 1, 1, 5], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 0, 0, 3], [2, 0, 0, 4], [2, 0, 0, 5], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0], [2, 0, 1, 3], [2, 0, 1, 4], [2, 0, 1, 5]], 50: [[0, 1, 2, 2], [0, 1, 2, 1], [0, 1, 2, 0], [0, 1, 2, 3], [0, 1, 2, 4], [0, 1, 2, 5], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 1, 3], [0, 1, 1, 4], [0, 1, 1, 5], [0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 0, 3], [0, 1, 0, 4], [0, 1, 0, 5], [0, 0, 2, 2], [0, 0, 2, 1], [0, 0, 2, 0], [0, 0, 2, 3], [0, 0, 2, 4], [0, 0, 2, 5], [0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [0, 0, 1, 3], [0, 0, 1, 4], [0, 0, 1, 5], [0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 3], [0, 0, 0, 4], [0, 0, 0, 5], [1, 1, 2, 2], [1, 1, 2, 1], [1, 1, 2, 0], [1, 1, 2, 3], [1, 1, 2, 4], [1, 1, 2, 5], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 1, 3], [1, 1, 1, 4], [1, 1, 1, 5], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 0, 3], [1, 1, 0, 4], [1, 1, 0, 5], [1, 0, 2, 2], [1, 0, 2, 1], [1, 0, 2, 0], [1, 0, 2, 3], [1, 0, 2, 4], [1, 0, 2, 5], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 1, 3], [1, 0, 1, 4], [1, 0, 1, 5], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 0, 3], [1, 0, 0, 4], [1, 0, 0, 5], [2, 1, 2, 2], [2, 1, 2, 1], [2, 1, 2, 0], [2, 1, 2, 3], [2, 1, 2, 4], [2, 1, 2, 5], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 1, 1, 3], [2, 1, 1, 4], [2, 1, 1, 5], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 1, 0, 3], [2, 1, 0, 4], [2, 1, 0, 5], [2, 0, 2, 2], [2, 0, 2, 1], [2, 0, 2, 0], [2, 0, 2, 3], [2, 0, 2, 4], [2, 0, 2, 5], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0], [2, 0, 1, 3], [2, 0, 1, 4], [2, 0, 1, 5], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 0, 0, 3], [2, 0, 0, 4], [2, 0, 0, 5]], 51: [[0, 0, 2, 2], [0, 0, 2, 1], [0, 0, 2, 0], [0, 0, 2, 3], [0, 0, 2, 4], [0, 0, 2, 5], [0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [0, 0, 1, 3], [0, 0, 1, 4], [0, 0, 1, 5], [0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 3], [0, 0, 0, 4], [0, 0, 0, 5], [0, 1, 2, 2], [0, 1, 2, 1], [0, 1, 2, 0], [0, 1, 2, 3], [0, 1, 2, 4], [0, 1, 2, 5], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 1, 3], [0, 1, 1, 4], [0, 1, 1, 5], [0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 0, 3], [0, 1, 0, 4], [0, 1, 0, 5], [1, 0, 2, 2], [1, 0, 2, 1], [1, 0, 2, 0], [1, 0, 2, 3], [1, 0, 2, 4], [1, 0, 2, 5], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 1, 3], [1, 0, 1, 4], [1, 0, 1, 5], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 0, 3], [1, 0, 0, 4], [1, 0, 0, 5], [1, 1, 2, 2], [1, 1, 2, 1], [1, 1, 2, 0], [1, 1, 2, 3], [1, 1, 2, 4], [1, 1, 2, 5], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 1, 3], [1, 1, 1, 4], [1, 1, 1, 5], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 0, 3], [1, 1, 0, 4], [1, 1, 0, 5], [2, 0, 2, 2], [2, 0, 2, 1], [2, 0, 2, 0], [2, 0, 2, 3], [2, 0, 2, 4], [2, 0, 2, 5], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0], [2, 0, 1, 3], [2, 0, 1, 4], [2, 0, 1, 5], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 0, 0, 3], [2, 0, 0, 4], [2, 0, 0, 5], [2, 1, 2, 2], [2, 1, 2, 1], [2, 1, 2, 0], [2, 1, 2, 3], [2, 1, 2, 4], [2, 1, 2, 5], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 1, 1, 3], [2, 1, 1, 4], [2, 1, 1, 5], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 1, 0, 3], [2, 1, 0, 4], [2, 1, 0, 5]], 52: [[0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0]], 53: [[0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 0, 3], [0, 1, 0, 4], [0, 1, 0, 5], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 1, 3], [0, 1, 1, 4], [0, 1, 1, 5], [0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 3], [0, 0, 0, 4], [0, 0, 0, 5], [0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [0, 0, 1, 3], [0, 0, 1, 4], [0, 0, 1, 5], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 0, 3], [1, 1, 0, 4], [1, 1, 0, 5], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 1, 3], [1, 1, 1, 4], [1, 1, 1, 5], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 0, 3], [1, 0, 0, 4], [1, 0, 0, 5], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 1, 3], [1, 0, 1, 4], [1, 0, 1, 5], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 1, 0, 3], [2, 1, 0, 4], [2, 1, 0, 5], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 1, 1, 3], [2, 1, 1, 4], [2, 1, 1, 5], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 0, 0, 3], [2, 0, 0, 4], [2, 0, 0, 5], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0], [2, 0, 1, 3], [2, 0, 1, 4], [2, 0, 1, 5]], 54: [[0, 1, 2, 2], [0, 1, 2, 1], [0, 1, 2, 0], [0, 1, 2, 3], [0, 1, 2, 4], [0, 1, 2, 5], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 1, 3], [0, 1, 1, 4], [0, 1, 1, 5], [0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 0, 3], [0, 1, 0, 4], [0, 1, 0, 5], [0, 0, 2, 2], [0, 0, 2, 1], [0, 0, 2, 0], [0, 0, 2, 3], [0, 0, 2, 4], [0, 0, 2, 5], [0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [0, 0, 1, 3], [0, 0, 1, 4], [0, 0, 1, 5], [0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 3], [0, 0, 0, 4], [0, 0, 0, 5], [1, 1, 2, 2], [1, 1, 2, 1], [1, 1, 2, 0], [1, 1, 2, 3], [1, 1, 2, 4], [1, 1, 2, 5], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 1, 3], [1, 1, 1, 4], [1, 1, 1, 5], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 0, 3], [1, 1, 0, 4], [1, 1, 0, 5], [1, 0, 2, 2], [1, 0, 2, 1], [1, 0, 2, 0], [1, 0, 2, 3], [1, 0, 2, 4], [1, 0, 2, 5], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 1, 3], [1, 0, 1, 4], [1, 0, 1, 5], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 0, 3], [1, 0, 0, 4], [1, 0, 0, 5], [2, 1, 2, 2], [2, 1, 2, 1], [2, 1, 2, 0], [2, 1, 2, 3], [2, 1, 2, 4], [2, 1, 2, 5], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 1, 1, 3], [2, 1, 1, 4], [2, 1, 1, 5], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 1, 0, 3], [2, 1, 0, 4], [2, 1, 0, 5], [2, 0, 2, 2], [2, 0, 2, 1], [2, 0, 2, 0], [2, 0, 2, 3], [2, 0, 2, 4], [2, 0, 2, 5], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0], [2, 0, 1, 3], [2, 0, 1, 4], [2, 0, 1, 5], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 0, 0, 3], [2, 0, 0, 4], [2, 0, 0, 5]], 55: [[0, 0, 2, 2], [0, 0, 2, 1], [0, 0, 2, 0], [0, 0, 2, 3], [0, 0, 2, 4], [0, 0, 2, 5], [0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [0, 0, 1, 3], [0, 0, 1, 4], [0, 0, 1, 5], [0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 3], [0, 0, 0, 4], [0, 0, 0, 5], [0, 1, 2, 2], [0, 1, 2, 1], [0, 1, 2, 0], [0, 1, 2, 3], [0, 1, 2, 4], [0, 1, 2, 5], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 1, 3], [0, 1, 1, 4], [0, 1, 1, 5], [0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 0, 3], [0, 1, 0, 4], [0, 1, 0, 5], [1, 0, 2, 2], [1, 0, 2, 1], [1, 0, 2, 0], [1, 0, 2, 3], [1, 0, 2, 4], [1, 0, 2, 5], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 1, 3], [1, 0, 1, 4], [1, 0, 1, 5], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 0, 3], [1, 0, 0, 4], [1, 0, 0, 5], [1, 1, 2, 2], [1, 1, 2, 1], [1, 1, 2, 0], [1, 1, 2, 3], [1, 1, 2, 4], [1, 1, 2, 5], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 1, 3], [1, 1, 1, 4], [1, 1, 1, 5], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 0, 3], [1, 1, 0, 4], [1, 1, 0, 5], [2, 0, 2, 2], [2, 0, 2, 1], [2, 0, 2, 0], [2, 0, 2, 3], [2, 0, 2, 4], [2, 0, 2, 5], [2, 0, 1, 2], [2, 0, 1, 1], [2, 0, 1, 0], [2, 0, 1, 3], [2, 0, 1, 4], [2, 0, 1, 5], [2, 0, 0, 2], [2, 0, 0, 1], [2, 0, 0, 0], [2, 0, 0, 3], [2, 0, 0, 4], [2, 0, 0, 5], [2, 1, 2, 2], [2, 1, 2, 1], [2, 1, 2, 0], [2, 1, 2, 3], [2, 1, 2, 4], [2, 1, 2, 5], [2, 1, 1, 2], [2, 1, 1, 1], [2, 1, 1, 0], [2, 1, 1, 3], [2, 1, 1, 4], [2, 1, 1, 5], [2, 1, 0, 2], [2, 1, 0, 1], [2, 1, 0, 0], [2, 1, 0, 3], [2, 1, 0, 4], [2, 1, 0, 5]], 56: [[1, 0, 2, 2], [1, 0, 2, 1], [1, 0, 2, 0], [1, 0, 2, 3], [1, 0, 2, 4], [1, 0, 2, 5], [1, 0, 1, 2], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 1, 3], [1, 0, 1, 4], [1, 0, 1, 5], [1, 0, 0, 2], [1, 0, 0, 1], [1, 0, 0, 0], [1, 0, 0, 3], [1, 0, 0, 4], [1, 0, 0, 5], [1, 1, 2, 2], [1, 1, 2, 1], [1, 1, 2, 0], [1, 1, 2, 3], [1, 1, 2, 4], [1, 1, 2, 5], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 1, 3], [1, 1, 1, 4], [1, 1, 1, 5], [1, 1, 0, 2], [1, 1, 0, 1], [1, 1, 0, 0], [1, 1, 0, 3], [1, 1, 0, 4], [1, 1, 0, 5], [0, 0, 2, 2], [0, 0, 2, 1], [0, 0, 2, 0], [0, 0, 2, 3], [0, 0, 2, 4], [0, 0, 2, 5], [0, 0, 1, 2], [0, 0, 1, 1], [0, 0, 1, 0], [0, 0, 1, 3], [0, 0, 1, 4], [0, 0, 1, 5], [0, 0, 0, 2], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 3], [0, 0, 0, 4], [0, 0, 0, 5], [0, 1, 2, 2], [0, 1, 2, 1], [0, 1, 2, 0], [0, 1, 2, 3], [0, 1, 2, 4], [0, 1, 2, 5], [0, 1, 1, 2], [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 1, 3], [0, 1, 1, 4], [0, 1, 1, 5], [0, 1, 0, 2], [0, 1, 0, 1], [0, 1, 0, 0], [0, 1, 0, 3], [0, 1, 0, 4], [0, 1, 0, 5]], 57: [[0, 0, 1, 0, 2], [0, 0, 1, 0, 1], [0, 0, 1, 0, 0], [0, 0, 1, 1, 2], [0, 0, 1, 1, 1], [0, 0, 1, 1, 0], [0, 0, 0, 0, 2], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0], [0, 0, 0, 1, 2], [0, 0, 0, 1, 1], [0, 0, 0, 1, 0], [0, 1, 1, 0, 2], [0, 1, 1, 0, 1], [0, 1, 1, 0, 0], [0, 1, 1, 1, 2], [0, 1, 1, 1, 1], [0, 1, 1, 1, 0], [0, 1, 0, 0, 2], [0, 1, 0, 0, 1], [0, 1, 0, 0, 0], [0, 1, 0, 1, 2], [0, 1, 0, 1, 1], [0, 1, 0, 1, 0], [0, 2, 1, 0, 2], [0, 2, 1, 0, 1], [0, 2, 1, 0, 0], [0, 2, 1, 1, 2], [0, 2, 1, 1, 1], [0, 2, 1, 1, 0], [0, 2, 0, 0, 2], [0, 2, 0, 0, 1], [0, 2, 0, 0, 0], [0, 2, 0, 1, 2], [0, 2, 0, 1, 1], [0, 2, 0, 1, 0], [1, 0, 1, 0, 2], [1, 0, 1, 0, 1], [1, 0, 1, 0, 0], [1, 0, 1, 1, 2], [1, 0, 1, 1, 1], [1, 0, 1, 1, 0], [1, 0, 0, 0, 2], [1, 0, 0, 0, 1], [1, 0, 0, 0, 0], [1, 0, 0, 1, 2], [1, 0, 0, 1, 1], [1, 0, 0, 1, 0], [1, 1, 1, 0, 2], [1, 1, 1, 0, 1], [1, 1, 1, 0, 0], [1, 1, 1, 1, 2], [1, 1, 1, 1, 1], [1, 1, 1, 1, 0], [1, 1, 0, 0, 2], [1, 1, 0, 0, 1], [1, 1, 0, 0, 0], [1, 1, 0, 1, 2], [1, 1, 0, 1, 1], [1, 1, 0, 1, 0], [1, 2, 1, 0, 2], [1, 2, 1, 0, 1], [1, 2, 1, 0, 0], [1, 2, 1, 1, 2], [1, 2, 1, 1, 1], [1, 2, 1, 1, 0], [1, 2, 0, 0, 2], [1, 2, 0, 0, 1], [1, 2, 0, 0, 0], [1, 2, 0, 1, 2], [1, 2, 0, 1, 1], [1, 2, 0, 1, 0], [2, 0, 1, 0, 2], [2, 0, 1, 0, 1], [2, 0, 1, 0, 0], [2, 0, 1, 1, 2], [2, 0, 1, 1, 1], [2, 0, 1, 1, 0], [2, 0, 0, 0, 2], [2, 0, 0, 0, 1], [2, 0, 0, 0, 0], [2, 0, 0, 1, 2], [2, 0, 0, 1, 1], [2, 0, 0, 1, 0], [2, 1, 1, 0, 2], [2, 1, 1, 0, 1], [2, 1, 1, 0, 0], [2, 1, 1, 1, 2], [2, 1, 1, 1, 1], [2, 1, 1, 1, 0], [2, 1, 0, 0, 2], [2, 1, 0, 0, 1], [2, 1, 0, 0, 0], [2, 1, 0, 1, 2], [2, 1, 0, 1, 1], [2, 1, 0, 1, 0], [2, 2, 1, 0, 2], [2, 2, 1, 0, 1], [2, 2, 1, 0, 0], [2, 2, 1, 1, 2], [2, 2, 1, 1, 1], [2, 2, 1, 1, 0], [2, 2, 0, 0, 2], [2, 2, 0, 0, 1], [2, 2, 0, 0, 0], [2, 2, 0, 1, 2], [2, 2, 0, 1, 1], [2, 2, 0, 1, 0]], 58: [[0, 0, 1, 0, 2], [0, 0, 1, 0, 1], [0, 0, 1, 0, 0], [0, 0, 1, 0, 3], [0, 0, 1, 0, 4], [0, 0, 1, 0, 5], [0, 0, 1, 1, 2], [0, 0, 1, 1, 1], [0, 0, 1, 1, 0], [0, 0, 1, 1, 3], [0, 0, 1, 1, 4], [0, 0, 1, 1, 5], [0, 0, 0, 0, 2], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 3], [0, 0, 0, 0, 4], [0, 0, 0, 0, 5], [0, 0, 0, 1, 2], [0, 0, 0, 1, 1], [0, 0, 0, 1, 0], [0, 0, 0, 1, 3], [0, 0, 0, 1, 4], [0, 0, 0, 1, 5], [0, 1, 1, 0, 2], [0, 1, 1, 0, 1], [0, 1, 1, 0, 0], [0, 1, 1, 0, 3], [0, 1, 1, 0, 4], [0, 1, 1, 0, 5], [0, 1, 1, 1, 2], [0, 1, 1, 1, 1], [0, 1, 1, 1, 0], [0, 1, 1, 1, 3], [0, 1, 1, 1, 4], [0, 1, 1, 1, 5], [0, 1, 0, 0, 2], [0, 1, 0, 0, 1], [0, 1, 0, 0, 0], [0, 1, 0, 0, 3], [0, 1, 0, 0, 4], [0, 1, 0, 0, 5], [0, 1, 0, 1, 2], [0, 1, 0, 1, 1], [0, 1, 0, 1, 0], [0, 1, 0, 1, 3], [0, 1, 0, 1, 4], [0, 1, 0, 1, 5], [0, 2, 1, 0, 2], [0, 2, 1, 0, 1], [0, 2, 1, 0, 0], [0, 2, 1, 0, 3], [0, 2, 1, 0, 4], [0, 2, 1, 0, 5], [0, 2, 1, 1, 2], [0, 2, 1, 1, 1], [0, 2, 1, 1, 0], [0, 2, 1, 1, 3], [0, 2, 1, 1, 4], [0, 2, 1, 1, 5], [0, 2, 0, 0, 2], [0, 2, 0, 0, 1], [0, 2, 0, 0, 0], [0, 2, 0, 0, 3], [0, 2, 0, 0, 4], [0, 2, 0, 0, 5], [0, 2, 0, 1, 2], [0, 2, 0, 1, 1], [0, 2, 0, 1, 0], [0, 2, 0, 1, 3], [0, 2, 0, 1, 4], [0, 2, 0, 1, 5], [1, 0, 1, 0, 2], [1, 0, 1, 0, 1], [1, 0, 1, 0, 0], [1, 0, 1, 0, 3], [1, 0, 1, 0, 4], [1, 0, 1, 0, 5], [1, 0, 1, 1, 2], [1, 0, 1, 1, 1], [1, 0, 1, 1, 0], [1, 0, 1, 1, 3], [1, 0, 1, 1, 4], [1, 0, 1, 1, 5], [1, 0, 0, 0, 2], [1, 0, 0, 0, 1], [1, 0, 0, 0, 0], [1, 0, 0, 0, 3], [1, 0, 0, 0, 4], [1, 0, 0, 0, 5], [1, 0, 0, 1, 2], [1, 0, 0, 1, 1], [1, 0, 0, 1, 0], [1, 0, 0, 1, 3], [1, 0, 0, 1, 4], [1, 0, 0, 1, 5], [1, 1, 1, 0, 2], [1, 1, 1, 0, 1], [1, 1, 1, 0, 0], [1, 1, 1, 0, 3], [1, 1, 1, 0, 4], [1, 1, 1, 0, 5], [1, 1, 1, 1, 2], [1, 1, 1, 1, 1], [1, 1, 1, 1, 0], [1, 1, 1, 1, 3], [1, 1, 1, 1, 4], [1, 1, 1, 1, 5], [1, 1, 0, 0, 2], [1, 1, 0, 0, 1], [1, 1, 0, 0, 0], [1, 1, 0, 0, 3], [1, 1, 0, 0, 4], [1, 1, 0, 0, 5], [1, 1, 0, 1, 2], [1, 1, 0, 1, 1], [1, 1, 0, 1, 0], [1, 1, 0, 1, 3], [1, 1, 0, 1, 4], [1, 1, 0, 1, 5], [1, 2, 1, 0, 2], [1, 2, 1, 0, 1], [1, 2, 1, 0, 0], [1, 2, 1, 0, 3], [1, 2, 1, 0, 4], [1, 2, 1, 0, 5], [1, 2, 1, 1, 2], [1, 2, 1, 1, 1], [1, 2, 1, 1, 0], [1, 2, 1, 1, 3], [1, 2, 1, 1, 4], [1, 2, 1, 1, 5], [1, 2, 0, 0, 2], [1, 2, 0, 0, 1], [1, 2, 0, 0, 0], [1, 2, 0, 0, 3], [1, 2, 0, 0, 4], [1, 2, 0, 0, 5], [1, 2, 0, 1, 2], [1, 2, 0, 1, 1], [1, 2, 0, 1, 0], [1, 2, 0, 1, 3], [1, 2, 0, 1, 4], [1, 2, 0, 1, 5], [2, 0, 1, 0, 2], [2, 0, 1, 0, 1], [2, 0, 1, 0, 0], [2, 0, 1, 0, 3], [2, 0, 1, 0, 4], [2, 0, 1, 0, 5], [2, 0, 1, 1, 2], [2, 0, 1, 1, 1], [2, 0, 1, 1, 0], [2, 0, 1, 1, 3], [2, 0, 1, 1, 4], [2, 0, 1, 1, 5], [2, 0, 0, 0, 2], [2, 0, 0, 0, 1], [2, 0, 0, 0, 0], [2, 0, 0, 0, 3], [2, 0, 0, 0, 4], [2, 0, 0, 0, 5], [2, 0, 0, 1, 2], [2, 0, 0, 1, 1], [2, 0, 0, 1, 0], [2, 0, 0, 1, 3], [2, 0, 0, 1, 4], [2, 0, 0, 1, 5], [2, 1, 1, 0, 2], [2, 1, 1, 0, 1], [2, 1, 1, 0, 0], [2, 1, 1, 0, 3], [2, 1, 1, 0, 4], [2, 1, 1, 0, 5], [2, 1, 1, 1, 2], [2, 1, 1, 1, 1], [2, 1, 1, 1, 0], [2, 1, 1, 1, 3], [2, 1, 1, 1, 4], [2, 1, 1, 1, 5], [2, 1, 0, 0, 2], [2, 1, 0, 0, 1], [2, 1, 0, 0, 0], [2, 1, 0, 0, 3], [2, 1, 0, 0, 4], [2, 1, 0, 0, 5], [2, 1, 0, 1, 2], [2, 1, 0, 1, 1], [2, 1, 0, 1, 0], [2, 1, 0, 1, 3], [2, 1, 0, 1, 4], [2, 1, 0, 1, 5], [2, 2, 1, 0, 2], [2, 2, 1, 0, 1], [2, 2, 1, 0, 0], [2, 2, 1, 0, 3], [2, 2, 1, 0, 4], [2, 2, 1, 0, 5], [2, 2, 1, 1, 2], [2, 2, 1, 1, 1], [2, 2, 1, 1, 0], [2, 2, 1, 1, 3], [2, 2, 1, 1, 4], [2, 2, 1, 1, 5], [2, 2, 0, 0, 2], [2, 2, 0, 0, 1], [2, 2, 0, 0, 0], [2, 2, 0, 0, 3], [2, 2, 0, 0, 4], [2, 2, 0, 0, 5], [2, 2, 0, 1, 2], [2, 2, 0, 1, 1], [2, 2, 0, 1, 0], [2, 2, 0, 1, 3], [2, 2, 0, 1, 4], [2, 2, 0, 1, 5]], 59: [[0, 0, 1, 2, 2], [0, 0, 1, 2, 1], [0, 0, 1, 2, 0], [0, 0, 1, 2, 3], [0, 0, 1, 2, 4], [0, 0, 1, 2, 5], [0, 0, 1, 1, 2], [0, 0, 1, 1, 1], [0, 0, 1, 1, 0], [0, 0, 1, 1, 3], [0, 0, 1, 1, 4], [0, 0, 1, 1, 5], [0, 0, 1, 0, 2], [0, 0, 1, 0, 1], [0, 0, 1, 0, 0], [0, 0, 1, 0, 3], [0, 0, 1, 0, 4], [0, 0, 1, 0, 5], [0, 0, 0, 2, 2], [0, 0, 0, 2, 1], [0, 0, 0, 2, 0], [0, 0, 0, 2, 3], [0, 0, 0, 2, 4], [0, 0, 0, 2, 5], [0, 0, 0, 1, 2], [0, 0, 0, 1, 1], [0, 0, 0, 1, 0], [0, 0, 0, 1, 3], [0, 0, 0, 1, 4], [0, 0, 0, 1, 5], [0, 0, 0, 0, 2], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 3], [0, 0, 0, 0, 4], [0, 0, 0, 0, 5], [0, 1, 1, 2, 2], [0, 1, 1, 2, 1], [0, 1, 1, 2, 0], [0, 1, 1, 2, 3], [0, 1, 1, 2, 4], [0, 1, 1, 2, 5], [0, 1, 1, 1, 2], [0, 1, 1, 1, 1], [0, 1, 1, 1, 0], [0, 1, 1, 1, 3], [0, 1, 1, 1, 4], [0, 1, 1, 1, 5], [0, 1, 1, 0, 2], [0, 1, 1, 0, 1], [0, 1, 1, 0, 0], [0, 1, 1, 0, 3], [0, 1, 1, 0, 4], [0, 1, 1, 0, 5], [0, 1, 0, 2, 2], [0, 1, 0, 2, 1], [0, 1, 0, 2, 0], [0, 1, 0, 2, 3], [0, 1, 0, 2, 4], [0, 1, 0, 2, 5], [0, 1, 0, 1, 2], [0, 1, 0, 1, 1], [0, 1, 0, 1, 0], [0, 1, 0, 1, 3], [0, 1, 0, 1, 4], [0, 1, 0, 1, 5], [0, 1, 0, 0, 2], [0, 1, 0, 0, 1], [0, 1, 0, 0, 0], [0, 1, 0, 0, 3], [0, 1, 0, 0, 4], [0, 1, 0, 0, 5], [0, 2, 1, 2, 2], [0, 2, 1, 2, 1], [0, 2, 1, 2, 0], [0, 2, 1, 2, 3], [0, 2, 1, 2, 4], [0, 2, 1, 2, 5], [0, 2, 1, 1, 2], [0, 2, 1, 1, 1], [0, 2, 1, 1, 0], [0, 2, 1, 1, 3], [0, 2, 1, 1, 4], [0, 2, 1, 1, 5], [0, 2, 1, 0, 2], [0, 2, 1, 0, 1], [0, 2, 1, 0, 0], [0, 2, 1, 0, 3], [0, 2, 1, 0, 4], [0, 2, 1, 0, 5], [0, 2, 0, 2, 2], [0, 2, 0, 2, 1], [0, 2, 0, 2, 0], [0, 2, 0, 2, 3], [0, 2, 0, 2, 4], [0, 2, 0, 2, 5], [0, 2, 0, 1, 2], [0, 2, 0, 1, 1], [0, 2, 0, 1, 0], [0, 2, 0, 1, 3], [0, 2, 0, 1, 4], [0, 2, 0, 1, 5], [0, 2, 0, 0, 2], [0, 2, 0, 0, 1], [0, 2, 0, 0, 0], [0, 2, 0, 0, 3], [0, 2, 0, 0, 4], [0, 2, 0, 0, 5], [1, 0, 1, 2, 2], [1, 0, 1, 2, 1], [1, 0, 1, 2, 0], [1, 0, 1, 2, 3], [1, 0, 1, 2, 4], [1, 0, 1, 2, 5], [1, 0, 1, 1, 2], [1, 0, 1, 1, 1], [1, 0, 1, 1, 0], [1, 0, 1, 1, 3], [1, 0, 1, 1, 4], [1, 0, 1, 1, 5], [1, 0, 1, 0, 2], [1, 0, 1, 0, 1], [1, 0, 1, 0, 0], [1, 0, 1, 0, 3], [1, 0, 1, 0, 4], [1, 0, 1, 0, 5], [1, 0, 0, 2, 2], [1, 0, 0, 2, 1], [1, 0, 0, 2, 0], [1, 0, 0, 2, 3], [1, 0, 0, 2, 4], [1, 0, 0, 2, 5], [1, 0, 0, 1, 2], [1, 0, 0, 1, 1], [1, 0, 0, 1, 0], [1, 0, 0, 1, 3], [1, 0, 0, 1, 4], [1, 0, 0, 1, 5], [1, 0, 0, 0, 2], [1, 0, 0, 0, 1], [1, 0, 0, 0, 0], [1, 0, 0, 0, 3], [1, 0, 0, 0, 4], [1, 0, 0, 0, 5], [1, 1, 1, 2, 2], [1, 1, 1, 2, 1], [1, 1, 1, 2, 0], [1, 1, 1, 2, 3], [1, 1, 1, 2, 4], [1, 1, 1, 2, 5], [1, 1, 1, 1, 2], [1, 1, 1, 1, 1], [1, 1, 1, 1, 0], [1, 1, 1, 1, 3], [1, 1, 1, 1, 4], [1, 1, 1, 1, 5], [1, 1, 1, 0, 2], [1, 1, 1, 0, 1], [1, 1, 1, 0, 0], [1, 1, 1, 0, 3], [1, 1, 1, 0, 4], [1, 1, 1, 0, 5], [1, 1, 0, 2, 2], [1, 1, 0, 2, 1], [1, 1, 0, 2, 0], [1, 1, 0, 2, 3], [1, 1, 0, 2, 4], [1, 1, 0, 2, 5], [1, 1, 0, 1, 2], [1, 1, 0, 1, 1], [1, 1, 0, 1, 0], [1, 1, 0, 1, 3], [1, 1, 0, 1, 4], [1, 1, 0, 1, 5], [1, 1, 0, 0, 2], [1, 1, 0, 0, 1], [1, 1, 0, 0, 0], [1, 1, 0, 0, 3], [1, 1, 0, 0, 4], [1, 1, 0, 0, 5], [1, 2, 1, 2, 2], [1, 2, 1, 2, 1], [1, 2, 1, 2, 0], [1, 2, 1, 2, 3], [1, 2, 1, 2, 4], [1, 2, 1, 2, 5], [1, 2, 1, 1, 2], [1, 2, 1, 1, 1], [1, 2, 1, 1, 0], [1, 2, 1, 1, 3], [1, 2, 1, 1, 4], [1, 2, 1, 1, 5], [1, 2, 1, 0, 2], [1, 2, 1, 0, 1], [1, 2, 1, 0, 0], [1, 2, 1, 0, 3], [1, 2, 1, 0, 4], [1, 2, 1, 0, 5], [1, 2, 0, 2, 2], [1, 2, 0, 2, 1], [1, 2, 0, 2, 0], [1, 2, 0, 2, 3], [1, 2, 0, 2, 4], [1, 2, 0, 2, 5], [1, 2, 0, 1, 2], [1, 2, 0, 1, 1], [1, 2, 0, 1, 0], [1, 2, 0, 1, 3], [1, 2, 0, 1, 4], [1, 2, 0, 1, 5], [1, 2, 0, 0, 2], [1, 2, 0, 0, 1], [1, 2, 0, 0, 0], [1, 2, 0, 0, 3], [1, 2, 0, 0, 4], [1, 2, 0, 0, 5], [2, 0, 1, 2, 2], [2, 0, 1, 2, 1], [2, 0, 1, 2, 0], [2, 0, 1, 2, 3], [2, 0, 1, 2, 4], [2, 0, 1, 2, 5], [2, 0, 1, 1, 2], [2, 0, 1, 1, 1], [2, 0, 1, 1, 0], [2, 0, 1, 1, 3], [2, 0, 1, 1, 4], [2, 0, 1, 1, 5], [2, 0, 1, 0, 2], [2, 0, 1, 0, 1], [2, 0, 1, 0, 0], [2, 0, 1, 0, 3], [2, 0, 1, 0, 4], [2, 0, 1, 0, 5], [2, 0, 0, 2, 2], [2, 0, 0, 2, 1], [2, 0, 0, 2, 0], [2, 0, 0, 2, 3], [2, 0, 0, 2, 4], [2, 0, 0, 2, 5], [2, 0, 0, 1, 2], [2, 0, 0, 1, 1], [2, 0, 0, 1, 0], [2, 0, 0, 1, 3], [2, 0, 0, 1, 4], [2, 0, 0, 1, 5], [2, 0, 0, 0, 2], [2, 0, 0, 0, 1], [2, 0, 0, 0, 0], [2, 0, 0, 0, 3], [2, 0, 0, 0, 4], [2, 0, 0, 0, 5], [2, 1, 1, 2, 2], [2, 1, 1, 2, 1], [2, 1, 1, 2, 0], [2, 1, 1, 2, 3], [2, 1, 1, 2, 4], [2, 1, 1, 2, 5], [2, 1, 1, 1, 2], [2, 1, 1, 1, 1], [2, 1, 1, 1, 0], [2, 1, 1, 1, 3], [2, 1, 1, 1, 4], [2, 1, 1, 1, 5], [2, 1, 1, 0, 2], [2, 1, 1, 0, 1], [2, 1, 1, 0, 0], [2, 1, 1, 0, 3], [2, 1, 1, 0, 4], [2, 1, 1, 0, 5], [2, 1, 0, 2, 2], [2, 1, 0, 2, 1], [2, 1, 0, 2, 0], [2, 1, 0, 2, 3], [2, 1, 0, 2, 4], [2, 1, 0, 2, 5], [2, 1, 0, 1, 2], [2, 1, 0, 1, 1], [2, 1, 0, 1, 0], [2, 1, 0, 1, 3], [2, 1, 0, 1, 4], [2, 1, 0, 1, 5], [2, 1, 0, 0, 2], [2, 1, 0, 0, 1], [2, 1, 0, 0, 0], [2, 1, 0, 0, 3], [2, 1, 0, 0, 4], [2, 1, 0, 0, 5], [2, 2, 1, 2, 2], [2, 2, 1, 2, 1], [2, 2, 1, 2, 0], [2, 2, 1, 2, 3], [2, 2, 1, 2, 4], [2, 2, 1, 2, 5], [2, 2, 1, 1, 2], [2, 2, 1, 1, 1], [2, 2, 1, 1, 0], [2, 2, 1, 1, 3], [2, 2, 1, 1, 4], [2, 2, 1, 1, 5], [2, 2, 1, 0, 2], [2, 2, 1, 0, 1], [2, 2, 1, 0, 0], [2, 2, 1, 0, 3], [2, 2, 1, 0, 4], [2, 2, 1, 0, 5], [2, 2, 0, 2, 2], [2, 2, 0, 2, 1], [2, 2, 0, 2, 0], [2, 2, 0, 2, 3], [2, 2, 0, 2, 4], [2, 2, 0, 2, 5], [2, 2, 0, 1, 2], [2, 2, 0, 1, 1], [2, 2, 0, 1, 0], [2, 2, 0, 1, 3], [2, 2, 0, 1, 4], [2, 2, 0, 1, 5], [2, 2, 0, 0, 2], [2, 2, 0, 0, 1], [2, 2, 0, 0, 0], [2, 2, 0, 0, 3], [2, 2, 0, 0, 4], [2, 2, 0, 0, 5]], 60: [[0, 0, 0, 2, 2], [0, 0, 0, 2, 1], [0, 0, 0, 2, 0], [0, 0, 0, 2, 3], [0, 0, 0, 2, 4], [0, 0, 0, 2, 5], [0, 0, 0, 1, 2], [0, 0, 0, 1, 1], [0, 0, 0, 1, 0], [0, 0, 0, 1, 3], [0, 0, 0, 1, 4], [0, 0, 0, 1, 5], [0, 0, 0, 0, 2], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 3], [0, 0, 0, 0, 4], [0, 0, 0, 0, 5], [0, 0, 1, 2, 2], [0, 0, 1, 2, 1], [0, 0, 1, 2, 0], [0, 0, 1, 2, 3], [0, 0, 1, 2, 4], [0, 0, 1, 2, 5], [0, 0, 1, 1, 2], [0, 0, 1, 1, 1], [0, 0, 1, 1, 0], [0, 0, 1, 1, 3], [0, 0, 1, 1, 4], [0, 0, 1, 1, 5], [0, 0, 1, 0, 2], [0, 0, 1, 0, 1], [0, 0, 1, 0, 0], [0, 0, 1, 0, 3], [0, 0, 1, 0, 4], [0, 0, 1, 0, 5], [0, 1, 0, 2, 2], [0, 1, 0, 2, 1], [0, 1, 0, 2, 0], [0, 1, 0, 2, 3], [0, 1, 0, 2, 4], [0, 1, 0, 2, 5], [0, 1, 0, 1, 2], [0, 1, 0, 1, 1], [0, 1, 0, 1, 0], [0, 1, 0, 1, 3], [0, 1, 0, 1, 4], [0, 1, 0, 1, 5], [0, 1, 0, 0, 2], [0, 1, 0, 0, 1], [0, 1, 0, 0, 0], [0, 1, 0, 0, 3], [0, 1, 0, 0, 4], [0, 1, 0, 0, 5], [0, 1, 1, 2, 2], [0, 1, 1, 2, 1], [0, 1, 1, 2, 0], [0, 1, 1, 2, 3], [0, 1, 1, 2, 4], [0, 1, 1, 2, 5], [0, 1, 1, 1, 2], [0, 1, 1, 1, 1], [0, 1, 1, 1, 0], [0, 1, 1, 1, 3], [0, 1, 1, 1, 4], [0, 1, 1, 1, 5], [0, 1, 1, 0, 2], [0, 1, 1, 0, 1], [0, 1, 1, 0, 0], [0, 1, 1, 0, 3], [0, 1, 1, 0, 4], [0, 1, 1, 0, 5], [0, 2, 0, 2, 2], [0, 2, 0, 2, 1], [0, 2, 0, 2, 0], [0, 2, 0, 2, 3], [0, 2, 0, 2, 4], [0, 2, 0, 2, 5], [0, 2, 0, 1, 2], [0, 2, 0, 1, 1], [0, 2, 0, 1, 0], [0, 2, 0, 1, 3], [0, 2, 0, 1, 4], [0, 2, 0, 1, 5], [0, 2, 0, 0, 2], [0, 2, 0, 0, 1], [0, 2, 0, 0, 0], [0, 2, 0, 0, 3], [0, 2, 0, 0, 4], [0, 2, 0, 0, 5], [0, 2, 1, 2, 2], [0, 2, 1, 2, 1], [0, 2, 1, 2, 0], [0, 2, 1, 2, 3], [0, 2, 1, 2, 4], [0, 2, 1, 2, 5], [0, 2, 1, 1, 2], [0, 2, 1, 1, 1], [0, 2, 1, 1, 0], [0, 2, 1, 1, 3], [0, 2, 1, 1, 4], [0, 2, 1, 1, 5], [0, 2, 1, 0, 2], [0, 2, 1, 0, 1], [0, 2, 1, 0, 0], [0, 2, 1, 0, 3], [0, 2, 1, 0, 4], [0, 2, 1, 0, 5], [1, 0, 0, 2, 2], [1, 0, 0, 2, 1], [1, 0, 0, 2, 0], [1, 0, 0, 2, 3], [1, 0, 0, 2, 4], [1, 0, 0, 2, 5], [1, 0, 0, 1, 2], [1, 0, 0, 1, 1], [1, 0, 0, 1, 0], [1, 0, 0, 1, 3], [1, 0, 0, 1, 4], [1, 0, 0, 1, 5], [1, 0, 0, 0, 2], [1, 0, 0, 0, 1], [1, 0, 0, 0, 0], [1, 0, 0, 0, 3], [1, 0, 0, 0, 4], [1, 0, 0, 0, 5], [1, 0, 1, 2, 2], [1, 0, 1, 2, 1], [1, 0, 1, 2, 0], [1, 0, 1, 2, 3], [1, 0, 1, 2, 4], [1, 0, 1, 2, 5], [1, 0, 1, 1, 2], [1, 0, 1, 1, 1], [1, 0, 1, 1, 0], [1, 0, 1, 1, 3], [1, 0, 1, 1, 4], [1, 0, 1, 1, 5], [1, 0, 1, 0, 2], [1, 0, 1, 0, 1], [1, 0, 1, 0, 0], [1, 0, 1, 0, 3], [1, 0, 1, 0, 4], [1, 0, 1, 0, 5], [1, 1, 0, 2, 2], [1, 1, 0, 2, 1], [1, 1, 0, 2, 0], [1, 1, 0, 2, 3], [1, 1, 0, 2, 4], [1, 1, 0, 2, 5], [1, 1, 0, 1, 2], [1, 1, 0, 1, 1], [1, 1, 0, 1, 0], [1, 1, 0, 1, 3], [1, 1, 0, 1, 4], [1, 1, 0, 1, 5], [1, 1, 0, 0, 2], [1, 1, 0, 0, 1], [1, 1, 0, 0, 0], [1, 1, 0, 0, 3], [1, 1, 0, 0, 4], [1, 1, 0, 0, 5], [1, 1, 1, 2, 2], [1, 1, 1, 2, 1], [1, 1, 1, 2, 0], [1, 1, 1, 2, 3], [1, 1, 1, 2, 4], [1, 1, 1, 2, 5], [1, 1, 1, 1, 2], [1, 1, 1, 1, 1], [1, 1, 1, 1, 0], [1, 1, 1, 1, 3], [1, 1, 1, 1, 4], [1, 1, 1, 1, 5], [1, 1, 1, 0, 2], [1, 1, 1, 0, 1], [1, 1, 1, 0, 0], [1, 1, 1, 0, 3], [1, 1, 1, 0, 4], [1, 1, 1, 0, 5], [1, 2, 0, 2, 2], [1, 2, 0, 2, 1], [1, 2, 0, 2, 0], [1, 2, 0, 2, 3], [1, 2, 0, 2, 4], [1, 2, 0, 2, 5], [1, 2, 0, 1, 2], [1, 2, 0, 1, 1], [1, 2, 0, 1, 0], [1, 2, 0, 1, 3], [1, 2, 0, 1, 4], [1, 2, 0, 1, 5], [1, 2, 0, 0, 2], [1, 2, 0, 0, 1], [1, 2, 0, 0, 0], [1, 2, 0, 0, 3], [1, 2, 0, 0, 4], [1, 2, 0, 0, 5], [1, 2, 1, 2, 2], [1, 2, 1, 2, 1], [1, 2, 1, 2, 0], [1, 2, 1, 2, 3], [1, 2, 1, 2, 4], [1, 2, 1, 2, 5], [1, 2, 1, 1, 2], [1, 2, 1, 1, 1], [1, 2, 1, 1, 0], [1, 2, 1, 1, 3], [1, 2, 1, 1, 4], [1, 2, 1, 1, 5], [1, 2, 1, 0, 2], [1, 2, 1, 0, 1], [1, 2, 1, 0, 0], [1, 2, 1, 0, 3], [1, 2, 1, 0, 4], [1, 2, 1, 0, 5], [2, 0, 0, 2, 2], [2, 0, 0, 2, 1], [2, 0, 0, 2, 0], [2, 0, 0, 2, 3], [2, 0, 0, 2, 4], [2, 0, 0, 2, 5], [2, 0, 0, 1, 2], [2, 0, 0, 1, 1], [2, 0, 0, 1, 0], [2, 0, 0, 1, 3], [2, 0, 0, 1, 4], [2, 0, 0, 1, 5], [2, 0, 0, 0, 2], [2, 0, 0, 0, 1], [2, 0, 0, 0, 0], [2, 0, 0, 0, 3], [2, 0, 0, 0, 4], [2, 0, 0, 0, 5], [2, 0, 1, 2, 2], [2, 0, 1, 2, 1], [2, 0, 1, 2, 0], [2, 0, 1, 2, 3], [2, 0, 1, 2, 4], [2, 0, 1, 2, 5], [2, 0, 1, 1, 2], [2, 0, 1, 1, 1], [2, 0, 1, 1, 0], [2, 0, 1, 1, 3], [2, 0, 1, 1, 4], [2, 0, 1, 1, 5], [2, 0, 1, 0, 2], [2, 0, 1, 0, 1], [2, 0, 1, 0, 0], [2, 0, 1, 0, 3], [2, 0, 1, 0, 4], [2, 0, 1, 0, 5], [2, 1, 0, 2, 2], [2, 1, 0, 2, 1], [2, 1, 0, 2, 0], [2, 1, 0, 2, 3], [2, 1, 0, 2, 4], [2, 1, 0, 2, 5], [2, 1, 0, 1, 2], [2, 1, 0, 1, 1], [2, 1, 0, 1, 0], [2, 1, 0, 1, 3], [2, 1, 0, 1, 4], [2, 1, 0, 1, 5], [2, 1, 0, 0, 2], [2, 1, 0, 0, 1], [2, 1, 0, 0, 0], [2, 1, 0, 0, 3], [2, 1, 0, 0, 4], [2, 1, 0, 0, 5], [2, 1, 1, 2, 2], [2, 1, 1, 2, 1], [2, 1, 1, 2, 0], [2, 1, 1, 2, 3], [2, 1, 1, 2, 4], [2, 1, 1, 2, 5], [2, 1, 1, 1, 2], [2, 1, 1, 1, 1], [2, 1, 1, 1, 0], [2, 1, 1, 1, 3], [2, 1, 1, 1, 4], [2, 1, 1, 1, 5], [2, 1, 1, 0, 2], [2, 1, 1, 0, 1], [2, 1, 1, 0, 0], [2, 1, 1, 0, 3], [2, 1, 1, 0, 4], [2, 1, 1, 0, 5], [2, 2, 0, 2, 2], [2, 2, 0, 2, 1], [2, 2, 0, 2, 0], [2, 2, 0, 2, 3], [2, 2, 0, 2, 4], [2, 2, 0, 2, 5], [2, 2, 0, 1, 2], [2, 2, 0, 1, 1], [2, 2, 0, 1, 0], [2, 2, 0, 1, 3], [2, 2, 0, 1, 4], [2, 2, 0, 1, 5], [2, 2, 0, 0, 2], [2, 2, 0, 0, 1], [2, 2, 0, 0, 0], [2, 2, 0, 0, 3], [2, 2, 0, 0, 4], [2, 2, 0, 0, 5], [2, 2, 1, 2, 2], [2, 2, 1, 2, 1], [2, 2, 1, 2, 0], [2, 2, 1, 2, 3], [2, 2, 1, 2, 4], [2, 2, 1, 2, 5], [2, 2, 1, 1, 2], [2, 2, 1, 1, 1], [2, 2, 1, 1, 0], [2, 2, 1, 1, 3], [2, 2, 1, 1, 4], [2, 2, 1, 1, 5], [2, 2, 1, 0, 2], [2, 2, 1, 0, 1], [2, 2, 1, 0, 0], [2, 2, 1, 0, 3], [2, 2, 1, 0, 4], [2, 2, 1, 0, 5]], 61: [[0, 1, 0, 2, 2], [0, 1, 0, 2, 1], [0, 1, 0, 2, 0], [0, 1, 0, 2, 3], [0, 1, 0, 2, 4], [0, 1, 0, 2, 5], [0, 1, 0, 1, 2], [0, 1, 0, 1, 1], [0, 1, 0, 1, 0], [0, 1, 0, 1, 3], [0, 1, 0, 1, 4], [0, 1, 0, 1, 5], [0, 1, 0, 0, 2], [0, 1, 0, 0, 1], [0, 1, 0, 0, 0], [0, 1, 0, 0, 3], [0, 1, 0, 0, 4], [0, 1, 0, 0, 5], [0, 1, 1, 2, 2], [0, 1, 1, 2, 1], [0, 1, 1, 2, 0], [0, 1, 1, 2, 3], [0, 1, 1, 2, 4], [0, 1, 1, 2, 5], [0, 1, 1, 1, 2], [0, 1, 1, 1, 1], [0, 1, 1, 1, 0], [0, 1, 1, 1, 3], [0, 1, 1, 1, 4], [0, 1, 1, 1, 5], [0, 1, 1, 0, 2], [0, 1, 1, 0, 1], [0, 1, 1, 0, 0], [0, 1, 1, 0, 3], [0, 1, 1, 0, 4], [0, 1, 1, 0, 5], [0, 0, 0, 2, 2], [0, 0, 0, 2, 1], [0, 0, 0, 2, 0], [0, 0, 0, 2, 3], [0, 0, 0, 2, 4], [0, 0, 0, 2, 5], [0, 0, 0, 1, 2], [0, 0, 0, 1, 1], [0, 0, 0, 1, 0], [0, 0, 0, 1, 3], [0, 0, 0, 1, 4], [0, 0, 0, 1, 5], [0, 0, 0, 0, 2], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 3], [0, 0, 0, 0, 4], [0, 0, 0, 0, 5], [0, 0, 1, 2, 2], [0, 0, 1, 2, 1], [0, 0, 1, 2, 0], [0, 0, 1, 2, 3], [0, 0, 1, 2, 4], [0, 0, 1, 2, 5], [0, 0, 1, 1, 2], [0, 0, 1, 1, 1], [0, 0, 1, 1, 0], [0, 0, 1, 1, 3], [0, 0, 1, 1, 4], [0, 0, 1, 1, 5], [0, 0, 1, 0, 2], [0, 0, 1, 0, 1], [0, 0, 1, 0, 0], [0, 0, 1, 0, 3], [0, 0, 1, 0, 4], [0, 0, 1, 0, 5], [1, 1, 0, 2, 2], [1, 1, 0, 2, 1], [1, 1, 0, 2, 0], [1, 1, 0, 2, 3], [1, 1, 0, 2, 4], [1, 1, 0, 2, 5], [1, 1, 0, 1, 2], [1, 1, 0, 1, 1], [1, 1, 0, 1, 0], [1, 1, 0, 1, 3], [1, 1, 0, 1, 4], [1, 1, 0, 1, 5], [1, 1, 0, 0, 2], [1, 1, 0, 0, 1], [1, 1, 0, 0, 0], [1, 1, 0, 0, 3], [1, 1, 0, 0, 4], [1, 1, 0, 0, 5], [1, 1, 1, 2, 2], [1, 1, 1, 2, 1], [1, 1, 1, 2, 0], [1, 1, 1, 2, 3], [1, 1, 1, 2, 4], [1, 1, 1, 2, 5], [1, 1, 1, 1, 2], [1, 1, 1, 1, 1], [1, 1, 1, 1, 0], [1, 1, 1, 1, 3], [1, 1, 1, 1, 4], [1, 1, 1, 1, 5], [1, 1, 1, 0, 2], [1, 1, 1, 0, 1], [1, 1, 1, 0, 0], [1, 1, 1, 0, 3], [1, 1, 1, 0, 4], [1, 1, 1, 0, 5], [1, 0, 0, 2, 2], [1, 0, 0, 2, 1], [1, 0, 0, 2, 0], [1, 0, 0, 2, 3], [1, 0, 0, 2, 4], [1, 0, 0, 2, 5], [1, 0, 0, 1, 2], [1, 0, 0, 1, 1], [1, 0, 0, 1, 0], [1, 0, 0, 1, 3], [1, 0, 0, 1, 4], [1, 0, 0, 1, 5], [1, 0, 0, 0, 2], [1, 0, 0, 0, 1], [1, 0, 0, 0, 0], [1, 0, 0, 0, 3], [1, 0, 0, 0, 4], [1, 0, 0, 0, 5], [1, 0, 1, 2, 2], [1, 0, 1, 2, 1], [1, 0, 1, 2, 0], [1, 0, 1, 2, 3], [1, 0, 1, 2, 4], [1, 0, 1, 2, 5], [1, 0, 1, 1, 2], [1, 0, 1, 1, 1], [1, 0, 1, 1, 0], [1, 0, 1, 1, 3], [1, 0, 1, 1, 4], [1, 0, 1, 1, 5], [1, 0, 1, 0, 2], [1, 0, 1, 0, 1], [1, 0, 1, 0, 0], [1, 0, 1, 0, 3], [1, 0, 1, 0, 4], [1, 0, 1, 0, 5], [2, 1, 0, 2, 2], [2, 1, 0, 2, 1], [2, 1, 0, 2, 0], [2, 1, 0, 2, 3], [2, 1, 0, 2, 4], [2, 1, 0, 2, 5], [2, 1, 0, 1, 2], [2, 1, 0, 1, 1], [2, 1, 0, 1, 0], [2, 1, 0, 1, 3], [2, 1, 0, 1, 4], [2, 1, 0, 1, 5], [2, 1, 0, 0, 2], [2, 1, 0, 0, 1], [2, 1, 0, 0, 0], [2, 1, 0, 0, 3], [2, 1, 0, 0, 4], [2, 1, 0, 0, 5], [2, 1, 1, 2, 2], [2, 1, 1, 2, 1], [2, 1, 1, 2, 0], [2, 1, 1, 2, 3], [2, 1, 1, 2, 4], [2, 1, 1, 2, 5], [2, 1, 1, 1, 2], [2, 1, 1, 1, 1], [2, 1, 1, 1, 0], [2, 1, 1, 1, 3], [2, 1, 1, 1, 4], [2, 1, 1, 1, 5], [2, 1, 1, 0, 2], [2, 1, 1, 0, 1], [2, 1, 1, 0, 0], [2, 1, 1, 0, 3], [2, 1, 1, 0, 4], [2, 1, 1, 0, 5], [2, 0, 0, 2, 2], [2, 0, 0, 2, 1], [2, 0, 0, 2, 0], [2, 0, 0, 2, 3], [2, 0, 0, 2, 4], [2, 0, 0, 2, 5], [2, 0, 0, 1, 2], [2, 0, 0, 1, 1], [2, 0, 0, 1, 0], [2, 0, 0, 1, 3], [2, 0, 0, 1, 4], [2, 0, 0, 1, 5], [2, 0, 0, 0, 2], [2, 0, 0, 0, 1], [2, 0, 0, 0, 0], [2, 0, 0, 0, 3], [2, 0, 0, 0, 4], [2, 0, 0, 0, 5], [2, 0, 1, 2, 2], [2, 0, 1, 2, 1], [2, 0, 1, 2, 0], [2, 0, 1, 2, 3], [2, 0, 1, 2, 4], [2, 0, 1, 2, 5], [2, 0, 1, 1, 2], [2, 0, 1, 1, 1], [2, 0, 1, 1, 0], [2, 0, 1, 1, 3], [2, 0, 1, 1, 4], [2, 0, 1, 1, 5], [2, 0, 1, 0, 2], [2, 0, 1, 0, 1], [2, 0, 1, 0, 0], [2, 0, 1, 0, 3], [2, 0, 1, 0, 4], [2, 0, 1, 0, 5]], 62: [[0, 1, 0, 2, 2], [0, 1, 0, 2, 1], [0, 1, 0, 2, 0], [0, 1, 0, 2, 3], [0, 1, 0, 2, 4], [0, 1, 0, 2, 5], [0, 1, 0, 1, 2], [0, 1, 0, 1, 1], [0, 1, 0, 1, 0], [0, 1, 0, 1, 3], [0, 1, 0, 1, 4], [0, 1, 0, 1, 5], [0, 1, 0, 0, 2], [0, 1, 0, 0, 1], [0, 1, 0, 0, 0], [0, 1, 0, 0, 3], [0, 1, 0, 0, 4], [0, 1, 0, 0, 5], [0, 1, 1, 2, 2], [0, 1, 1, 2, 1], [0, 1, 1, 2, 0], [0, 1, 1, 2, 3], [0, 1, 1, 2, 4], [0, 1, 1, 2, 5], [0, 1, 1, 1, 2], [0, 1, 1, 1, 1], [0, 1, 1, 1, 0], [0, 1, 1, 1, 3], [0, 1, 1, 1, 4], [0, 1, 1, 1, 5], [0, 1, 1, 0, 2], [0, 1, 1, 0, 1], [0, 1, 1, 0, 0], [0, 1, 1, 0, 3], [0, 1, 1, 0, 4], [0, 1, 1, 0, 5], [0, 0, 0, 2, 2], [0, 0, 0, 2, 1], [0, 0, 0, 2, 0], [0, 0, 0, 2, 3], [0, 0, 0, 2, 4], [0, 0, 0, 2, 5], [0, 0, 0, 1, 2], [0, 0, 0, 1, 1], [0, 0, 0, 1, 0], [0, 0, 0, 1, 3], [0, 0, 0, 1, 4], [0, 0, 0, 1, 5], [0, 0, 0, 0, 2], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 3], [0, 0, 0, 0, 4], [0, 0, 0, 0, 5], [0, 0, 1, 2, 2], [0, 0, 1, 2, 1], [0, 0, 1, 2, 0], [0, 0, 1, 2, 3], [0, 0, 1, 2, 4], [0, 0, 1, 2, 5], [0, 0, 1, 1, 2], [0, 0, 1, 1, 1], [0, 0, 1, 1, 0], [0, 0, 1, 1, 3], [0, 0, 1, 1, 4], [0, 0, 1, 1, 5], [0, 0, 1, 0, 2], [0, 0, 1, 0, 1], [0, 0, 1, 0, 0], [0, 0, 1, 0, 3], [0, 0, 1, 0, 4], [0, 0, 1, 0, 5], [1, 1, 0, 2, 2], [1, 1, 0, 2, 1], [1, 1, 0, 2, 0], [1, 1, 0, 2, 3], [1, 1, 0, 2, 4], [1, 1, 0, 2, 5], [1, 1, 0, 1, 2], [1, 1, 0, 1, 1], [1, 1, 0, 1, 0], [1, 1, 0, 1, 3], [1, 1, 0, 1, 4], [1, 1, 0, 1, 5], [1, 1, 0, 0, 2], [1, 1, 0, 0, 1], [1, 1, 0, 0, 0], [1, 1, 0, 0, 3], [1, 1, 0, 0, 4], [1, 1, 0, 0, 5], [1, 1, 1, 2, 2], [1, 1, 1, 2, 1], [1, 1, 1, 2, 0], [1, 1, 1, 2, 3], [1, 1, 1, 2, 4], [1, 1, 1, 2, 5], [1, 1, 1, 1, 2], [1, 1, 1, 1, 1], [1, 1, 1, 1, 0], [1, 1, 1, 1, 3], [1, 1, 1, 1, 4], [1, 1, 1, 1, 5], [1, 1, 1, 0, 2], [1, 1, 1, 0, 1], [1, 1, 1, 0, 0], [1, 1, 1, 0, 3], [1, 1, 1, 0, 4], [1, 1, 1, 0, 5], [1, 0, 0, 2, 2], [1, 0, 0, 2, 1], [1, 0, 0, 2, 0], [1, 0, 0, 2, 3], [1, 0, 0, 2, 4], [1, 0, 0, 2, 5], [1, 0, 0, 1, 2], [1, 0, 0, 1, 1], [1, 0, 0, 1, 0], [1, 0, 0, 1, 3], [1, 0, 0, 1, 4], [1, 0, 0, 1, 5], [1, 0, 0, 0, 2], [1, 0, 0, 0, 1], [1, 0, 0, 0, 0], [1, 0, 0, 0, 3], [1, 0, 0, 0, 4], [1, 0, 0, 0, 5], [1, 0, 1, 2, 2], [1, 0, 1, 2, 1], [1, 0, 1, 2, 0], [1, 0, 1, 2, 3], [1, 0, 1, 2, 4], [1, 0, 1, 2, 5], [1, 0, 1, 1, 2], [1, 0, 1, 1, 1], [1, 0, 1, 1, 0], [1, 0, 1, 1, 3], [1, 0, 1, 1, 4], [1, 0, 1, 1, 5], [1, 0, 1, 0, 2], [1, 0, 1, 0, 1], [1, 0, 1, 0, 0], [1, 0, 1, 0, 3], [1, 0, 1, 0, 4], [1, 0, 1, 0, 5], [2, 1, 0, 2, 2], [2, 1, 0, 2, 1], [2, 1, 0, 2, 0], [2, 1, 0, 2, 3], [2, 1, 0, 2, 4], [2, 1, 0, 2, 5], [2, 1, 0, 1, 2], [2, 1, 0, 1, 1], [2, 1, 0, 1, 0], [2, 1, 0, 1, 3], [2, 1, 0, 1, 4], [2, 1, 0, 1, 5], [2, 1, 0, 0, 2], [2, 1, 0, 0, 1], [2, 1, 0, 0, 0], [2, 1, 0, 0, 3], [2, 1, 0, 0, 4], [2, 1, 0, 0, 5], [2, 1, 1, 2, 2], [2, 1, 1, 2, 1], [2, 1, 1, 2, 0], [2, 1, 1, 2, 3], [2, 1, 1, 2, 4], [2, 1, 1, 2, 5], [2, 1, 1, 1, 2], [2, 1, 1, 1, 1], [2, 1, 1, 1, 0], [2, 1, 1, 1, 3], [2, 1, 1, 1, 4], [2, 1, 1, 1, 5], [2, 1, 1, 0, 2], [2, 1, 1, 0, 1], [2, 1, 1, 0, 0], [2, 1, 1, 0, 3], [2, 1, 1, 0, 4], [2, 1, 1, 0, 5], [2, 0, 0, 2, 2], [2, 0, 0, 2, 1], [2, 0, 0, 2, 0], [2, 0, 0, 2, 3], [2, 0, 0, 2, 4], [2, 0, 0, 2, 5], [2, 0, 0, 1, 2], [2, 0, 0, 1, 1], [2, 0, 0, 1, 0], [2, 0, 0, 1, 3], [2, 0, 0, 1, 4], [2, 0, 0, 1, 5], [2, 0, 0, 0, 2], [2, 0, 0, 0, 1], [2, 0, 0, 0, 0], [2, 0, 0, 0, 3], [2, 0, 0, 0, 4], [2, 0, 0, 0, 5], [2, 0, 1, 2, 2], [2, 0, 1, 2, 1], [2, 0, 1, 2, 0], [2, 0, 1, 2, 3], [2, 0, 1, 2, 4], [2, 0, 1, 2, 5], [2, 0, 1, 1, 2], [2, 0, 1, 1, 1], [2, 0, 1, 1, 0], [2, 0, 1, 1, 3], [2, 0, 1, 1, 4], [2, 0, 1, 1, 5], [2, 0, 1, 0, 2], [2, 0, 1, 0, 1], [2, 0, 1, 0, 0], [2, 0, 1, 0, 3], [2, 0, 1, 0, 4], [2, 0, 1, 0, 5]], 63: [[0, 0, 1, 0, 2, 2], [0, 0, 1, 0, 2, 1], [0, 0, 1, 0, 2, 0], [0, 0, 1, 0, 2, 3], [0, 0, 1, 0, 2, 4], [0, 0, 1, 0, 2, 5], [0, 0, 1, 0, 1, 2], [0, 0, 1, 0, 1, 1], [0, 0, 1, 0, 1, 0], [0, 0, 1, 0, 1, 3], [0, 0, 1, 0, 1, 4], [0, 0, 1, 0, 1, 5], [0, 0, 1, 0, 0, 2], [0, 0, 1, 0, 0, 1], [0, 0, 1, 0, 0, 0], [0, 0, 1, 0, 0, 3], [0, 0, 1, 0, 0, 4], [0, 0, 1, 0, 0, 5], [0, 0, 1, 1, 2, 2], [0, 0, 1, 1, 2, 1], [0, 0, 1, 1, 2, 0], [0, 0, 1, 1, 2, 3], [0, 0, 1, 1, 2, 4], [0, 0, 1, 1, 2, 5], [0, 0, 1, 1, 1, 2], [0, 0, 1, 1, 1, 1], [0, 0, 1, 1, 1, 0], [0, 0, 1, 1, 1, 3], [0, 0, 1, 1, 1, 4], [0, 0, 1, 1, 1, 5], [0, 0, 1, 1, 0, 2], [0, 0, 1, 1, 0, 1], [0, 0, 1, 1, 0, 0], [0, 0, 1, 1, 0, 3], [0, 0, 1, 1, 0, 4], [0, 0, 1, 1, 0, 5], [0, 0, 0, 0, 2, 2], [0, 0, 0, 0, 2, 1], [0, 0, 0, 0, 2, 0], [0, 0, 0, 0, 2, 3], [0, 0, 0, 0, 2, 4], [0, 0, 0, 0, 2, 5], [0, 0, 0, 0, 1, 2], [0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 3], [0, 0, 0, 0, 1, 4], [0, 0, 0, 0, 1, 5], [0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 3], [0, 0, 0, 0, 0, 4], [0, 0, 0, 0, 0, 5], [0, 0, 0, 1, 2, 2], [0, 0, 0, 1, 2, 1], [0, 0, 0, 1, 2, 0], [0, 0, 0, 1, 2, 3], [0, 0, 0, 1, 2, 4], [0, 0, 0, 1, 2, 5], [0, 0, 0, 1, 1, 2], [0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 0], [0, 0, 0, 1, 1, 3], [0, 0, 0, 1, 1, 4], [0, 0, 0, 1, 1, 5], [0, 0, 0, 1, 0, 2], [0, 0, 0, 1, 0, 1], [0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 3], [0, 0, 0, 1, 0, 4], [0, 0, 0, 1, 0, 5], [0, 1, 1, 0, 2, 2], [0, 1, 1, 0, 2, 1], [0, 1, 1, 0, 2, 0], [0, 1, 1, 0, 2, 3], [0, 1, 1, 0, 2, 4], [0, 1, 1, 0, 2, 5], [0, 1, 1, 0, 1, 2], [0, 1, 1, 0, 1, 1], [0, 1, 1, 0, 1, 0], [0, 1, 1, 0, 1, 3], [0, 1, 1, 0, 1, 4], [0, 1, 1, 0, 1, 5], [0, 1, 1, 0, 0, 2], [0, 1, 1, 0, 0, 1], [0, 1, 1, 0, 0, 0], [0, 1, 1, 0, 0, 3], [0, 1, 1, 0, 0, 4], [0, 1, 1, 0, 0, 5], [0, 1, 1, 1, 2, 2], [0, 1, 1, 1, 2, 1], [0, 1, 1, 1, 2, 0], [0, 1, 1, 1, 2, 3], [0, 1, 1, 1, 2, 4], [0, 1, 1, 1, 2, 5], [0, 1, 1, 1, 1, 2], [0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 0], [0, 1, 1, 1, 1, 3], [0, 1, 1, 1, 1, 4], [0, 1, 1, 1, 1, 5], [0, 1, 1, 1, 0, 2], [0, 1, 1, 1, 0, 1], [0, 1, 1, 1, 0, 0], [0, 1, 1, 1, 0, 3], [0, 1, 1, 1, 0, 4], [0, 1, 1, 1, 0, 5], [0, 1, 0, 0, 2, 2], [0, 1, 0, 0, 2, 1], [0, 1, 0, 0, 2, 0], [0, 1, 0, 0, 2, 3], [0, 1, 0, 0, 2, 4], [0, 1, 0, 0, 2, 5], [0, 1, 0, 0, 1, 2], [0, 1, 0, 0, 1, 1], [0, 1, 0, 0, 1, 0], [0, 1, 0, 0, 1, 3], [0, 1, 0, 0, 1, 4], [0, 1, 0, 0, 1, 5], [0, 1, 0, 0, 0, 2], [0, 1, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 3], [0, 1, 0, 0, 0, 4], [0, 1, 0, 0, 0, 5], [0, 1, 0, 1, 2, 2], [0, 1, 0, 1, 2, 1], [0, 1, 0, 1, 2, 0], [0, 1, 0, 1, 2, 3], [0, 1, 0, 1, 2, 4], [0, 1, 0, 1, 2, 5], [0, 1, 0, 1, 1, 2], [0, 1, 0, 1, 1, 1], [0, 1, 0, 1, 1, 0], [0, 1, 0, 1, 1, 3], [0, 1, 0, 1, 1, 4], [0, 1, 0, 1, 1, 5], [0, 1, 0, 1, 0, 2], [0, 1, 0, 1, 0, 1], [0, 1, 0, 1, 0, 0], [0, 1, 0, 1, 0, 3], [0, 1, 0, 1, 0, 4], [0, 1, 0, 1, 0, 5], [0, 2, 1, 0, 2, 2], [0, 2, 1, 0, 2, 1], [0, 2, 1, 0, 2, 0], [0, 2, 1, 0, 2, 3], [0, 2, 1, 0, 2, 4], [0, 2, 1, 0, 2, 5], [0, 2, 1, 0, 1, 2], [0, 2, 1, 0, 1, 1], [0, 2, 1, 0, 1, 0], [0, 2, 1, 0, 1, 3], [0, 2, 1, 0, 1, 4], [0, 2, 1, 0, 1, 5], [0, 2, 1, 0, 0, 2], [0, 2, 1, 0, 0, 1], [0, 2, 1, 0, 0, 0], [0, 2, 1, 0, 0, 3], [0, 2, 1, 0, 0, 4], [0, 2, 1, 0, 0, 5], [0, 2, 1, 1, 2, 2], [0, 2, 1, 1, 2, 1], [0, 2, 1, 1, 2, 0], [0, 2, 1, 1, 2, 3], [0, 2, 1, 1, 2, 4], [0, 2, 1, 1, 2, 5], [0, 2, 1, 1, 1, 2], [0, 2, 1, 1, 1, 1], [0, 2, 1, 1, 1, 0], [0, 2, 1, 1, 1, 3], [0, 2, 1, 1, 1, 4], [0, 2, 1, 1, 1, 5], [0, 2, 1, 1, 0, 2], [0, 2, 1, 1, 0, 1], [0, 2, 1, 1, 0, 0], [0, 2, 1, 1, 0, 3], [0, 2, 1, 1, 0, 4], [0, 2, 1, 1, 0, 5], [0, 2, 0, 0, 2, 2], [0, 2, 0, 0, 2, 1], [0, 2, 0, 0, 2, 0], [0, 2, 0, 0, 2, 3], [0, 2, 0, 0, 2, 4], [0, 2, 0, 0, 2, 5], [0, 2, 0, 0, 1, 2], [0, 2, 0, 0, 1, 1], [0, 2, 0, 0, 1, 0], [0, 2, 0, 0, 1, 3], [0, 2, 0, 0, 1, 4], [0, 2, 0, 0, 1, 5], [0, 2, 0, 0, 0, 2], [0, 2, 0, 0, 0, 1], [0, 2, 0, 0, 0, 0], [0, 2, 0, 0, 0, 3], [0, 2, 0, 0, 0, 4], [0, 2, 0, 0, 0, 5], [0, 2, 0, 1, 2, 2], [0, 2, 0, 1, 2, 1], [0, 2, 0, 1, 2, 0], [0, 2, 0, 1, 2, 3], [0, 2, 0, 1, 2, 4], [0, 2, 0, 1, 2, 5], [0, 2, 0, 1, 1, 2], [0, 2, 0, 1, 1, 1], [0, 2, 0, 1, 1, 0], [0, 2, 0, 1, 1, 3], [0, 2, 0, 1, 1, 4], [0, 2, 0, 1, 1, 5], [0, 2, 0, 1, 0, 2], [0, 2, 0, 1, 0, 1], [0, 2, 0, 1, 0, 0], [0, 2, 0, 1, 0, 3], [0, 2, 0, 1, 0, 4], [0, 2, 0, 1, 0, 5], [1, 0, 1, 0, 2, 2], [1, 0, 1, 0, 2, 1], [1, 0, 1, 0, 2, 0], [1, 0, 1, 0, 2, 3], [1, 0, 1, 0, 2, 4], [1, 0, 1, 0, 2, 5], [1, 0, 1, 0, 1, 2], [1, 0, 1, 0, 1, 1], [1, 0, 1, 0, 1, 0], [1, 0, 1, 0, 1, 3], [1, 0, 1, 0, 1, 4], [1, 0, 1, 0, 1, 5], [1, 0, 1, 0, 0, 2], [1, 0, 1, 0, 0, 1], [1, 0, 1, 0, 0, 0], [1, 0, 1, 0, 0, 3], [1, 0, 1, 0, 0, 4], [1, 0, 1, 0, 0, 5], [1, 0, 1, 1, 2, 2], [1, 0, 1, 1, 2, 1], [1, 0, 1, 1, 2, 0], [1, 0, 1, 1, 2, 3], [1, 0, 1, 1, 2, 4], [1, 0, 1, 1, 2, 5], [1, 0, 1, 1, 1, 2], [1, 0, 1, 1, 1, 1], [1, 0, 1, 1, 1, 0], [1, 0, 1, 1, 1, 3], [1, 0, 1, 1, 1, 4], [1, 0, 1, 1, 1, 5], [1, 0, 1, 1, 0, 2], [1, 0, 1, 1, 0, 1], [1, 0, 1, 1, 0, 0], [1, 0, 1, 1, 0, 3], [1, 0, 1, 1, 0, 4], [1, 0, 1, 1, 0, 5], [1, 0, 0, 0, 2, 2], [1, 0, 0, 0, 2, 1], [1, 0, 0, 0, 2, 0], [1, 0, 0, 0, 2, 3], [1, 0, 0, 0, 2, 4], [1, 0, 0, 0, 2, 5], [1, 0, 0, 0, 1, 2], [1, 0, 0, 0, 1, 1], [1, 0, 0, 0, 1, 0], [1, 0, 0, 0, 1, 3], [1, 0, 0, 0, 1, 4], [1, 0, 0, 0, 1, 5], [1, 0, 0, 0, 0, 2], [1, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 3], [1, 0, 0, 0, 0, 4], [1, 0, 0, 0, 0, 5], [1, 0, 0, 1, 2, 2], [1, 0, 0, 1, 2, 1], [1, 0, 0, 1, 2, 0], [1, 0, 0, 1, 2, 3], [1, 0, 0, 1, 2, 4], [1, 0, 0, 1, 2, 5], [1, 0, 0, 1, 1, 2], [1, 0, 0, 1, 1, 1], [1, 0, 0, 1, 1, 0], [1, 0, 0, 1, 1, 3], [1, 0, 0, 1, 1, 4], [1, 0, 0, 1, 1, 5], [1, 0, 0, 1, 0, 2], [1, 0, 0, 1, 0, 1], [1, 0, 0, 1, 0, 0], [1, 0, 0, 1, 0, 3], [1, 0, 0, 1, 0, 4], [1, 0, 0, 1, 0, 5], [1, 1, 1, 0, 2, 2], [1, 1, 1, 0, 2, 1], [1, 1, 1, 0, 2, 0], [1, 1, 1, 0, 2, 3], [1, 1, 1, 0, 2, 4], [1, 1, 1, 0, 2, 5], [1, 1, 1, 0, 1, 2], [1, 1, 1, 0, 1, 1], [1, 1, 1, 0, 1, 0], [1, 1, 1, 0, 1, 3], [1, 1, 1, 0, 1, 4], [1, 1, 1, 0, 1, 5], [1, 1, 1, 0, 0, 2], [1, 1, 1, 0, 0, 1], [1, 1, 1, 0, 0, 0], [1, 1, 1, 0, 0, 3], [1, 1, 1, 0, 0, 4], [1, 1, 1, 0, 0, 5], [1, 1, 1, 1, 2, 2], [1, 1, 1, 1, 2, 1], [1, 1, 1, 1, 2, 0], [1, 1, 1, 1, 2, 3], [1, 1, 1, 1, 2, 4], [1, 1, 1, 1, 2, 5], [1, 1, 1, 1, 1, 2], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 3], [1, 1, 1, 1, 1, 4], [1, 1, 1, 1, 1, 5], [1, 1, 1, 1, 0, 2], [1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 0, 3], [1, 1, 1, 1, 0, 4], [1, 1, 1, 1, 0, 5], [1, 1, 0, 0, 2, 2], [1, 1, 0, 0, 2, 1], [1, 1, 0, 0, 2, 0], [1, 1, 0, 0, 2, 3], [1, 1, 0, 0, 2, 4], [1, 1, 0, 0, 2, 5], [1, 1, 0, 0, 1, 2], [1, 1, 0, 0, 1, 1], [1, 1, 0, 0, 1, 0], [1, 1, 0, 0, 1, 3], [1, 1, 0, 0, 1, 4], [1, 1, 0, 0, 1, 5], [1, 1, 0, 0, 0, 2], [1, 1, 0, 0, 0, 1], [1, 1, 0, 0, 0, 0], [1, 1, 0, 0, 0, 3], [1, 1, 0, 0, 0, 4], [1, 1, 0, 0, 0, 5], [1, 1, 0, 1, 2, 2], [1, 1, 0, 1, 2, 1], [1, 1, 0, 1, 2, 0], [1, 1, 0, 1, 2, 3], [1, 1, 0, 1, 2, 4], [1, 1, 0, 1, 2, 5], [1, 1, 0, 1, 1, 2], [1, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0], [1, 1, 0, 1, 1, 3], [1, 1, 0, 1, 1, 4], [1, 1, 0, 1, 1, 5], [1, 1, 0, 1, 0, 2], [1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 0], [1, 1, 0, 1, 0, 3], [1, 1, 0, 1, 0, 4], [1, 1, 0, 1, 0, 5], [1, 2, 1, 0, 2, 2], [1, 2, 1, 0, 2, 1], [1, 2, 1, 0, 2, 0], [1, 2, 1, 0, 2, 3], [1, 2, 1, 0, 2, 4], [1, 2, 1, 0, 2, 5], [1, 2, 1, 0, 1, 2], [1, 2, 1, 0, 1, 1], [1, 2, 1, 0, 1, 0], [1, 2, 1, 0, 1, 3], [1, 2, 1, 0, 1, 4], [1, 2, 1, 0, 1, 5], [1, 2, 1, 0, 0, 2], [1, 2, 1, 0, 0, 1], [1, 2, 1, 0, 0, 0], [1, 2, 1, 0, 0, 3], [1, 2, 1, 0, 0, 4], [1, 2, 1, 0, 0, 5], [1, 2, 1, 1, 2, 2], [1, 2, 1, 1, 2, 1], [1, 2, 1, 1, 2, 0], [1, 2, 1, 1, 2, 3], [1, 2, 1, 1, 2, 4], [1, 2, 1, 1, 2, 5], [1, 2, 1, 1, 1, 2], [1, 2, 1, 1, 1, 1], [1, 2, 1, 1, 1, 0], [1, 2, 1, 1, 1, 3], [1, 2, 1, 1, 1, 4], [1, 2, 1, 1, 1, 5], [1, 2, 1, 1, 0, 2], [1, 2, 1, 1, 0, 1], [1, 2, 1, 1, 0, 0], [1, 2, 1, 1, 0, 3], [1, 2, 1, 1, 0, 4], [1, 2, 1, 1, 0, 5], [1, 2, 0, 0, 2, 2], [1, 2, 0, 0, 2, 1], [1, 2, 0, 0, 2, 0], [1, 2, 0, 0, 2, 3], [1, 2, 0, 0, 2, 4], [1, 2, 0, 0, 2, 5], [1, 2, 0, 0, 1, 2], [1, 2, 0, 0, 1, 1], [1, 2, 0, 0, 1, 0], [1, 2, 0, 0, 1, 3], [1, 2, 0, 0, 1, 4], [1, 2, 0, 0, 1, 5], [1, 2, 0, 0, 0, 2], [1, 2, 0, 0, 0, 1], [1, 2, 0, 0, 0, 0], [1, 2, 0, 0, 0, 3], [1, 2, 0, 0, 0, 4], [1, 2, 0, 0, 0, 5], [1, 2, 0, 1, 2, 2], [1, 2, 0, 1, 2, 1], [1, 2, 0, 1, 2, 0], [1, 2, 0, 1, 2, 3], [1, 2, 0, 1, 2, 4], [1, 2, 0, 1, 2, 5], [1, 2, 0, 1, 1, 2], [1, 2, 0, 1, 1, 1], [1, 2, 0, 1, 1, 0], [1, 2, 0, 1, 1, 3], [1, 2, 0, 1, 1, 4], [1, 2, 0, 1, 1, 5], [1, 2, 0, 1, 0, 2], [1, 2, 0, 1, 0, 1], [1, 2, 0, 1, 0, 0], [1, 2, 0, 1, 0, 3], [1, 2, 0, 1, 0, 4], [1, 2, 0, 1, 0, 5], [2, 0, 1, 0, 2, 2], [2, 0, 1, 0, 2, 1], [2, 0, 1, 0, 2, 0], [2, 0, 1, 0, 2, 3], [2, 0, 1, 0, 2, 4], [2, 0, 1, 0, 2, 5], [2, 0, 1, 0, 1, 2], [2, 0, 1, 0, 1, 1], [2, 0, 1, 0, 1, 0], [2, 0, 1, 0, 1, 3], [2, 0, 1, 0, 1, 4], [2, 0, 1, 0, 1, 5], [2, 0, 1, 0, 0, 2], [2, 0, 1, 0, 0, 1], [2, 0, 1, 0, 0, 0], [2, 0, 1, 0, 0, 3], [2, 0, 1, 0, 0, 4], [2, 0, 1, 0, 0, 5], [2, 0, 1, 1, 2, 2], [2, 0, 1, 1, 2, 1], [2, 0, 1, 1, 2, 0], [2, 0, 1, 1, 2, 3], [2, 0, 1, 1, 2, 4], [2, 0, 1, 1, 2, 5], [2, 0, 1, 1, 1, 2], [2, 0, 1, 1, 1, 1], [2, 0, 1, 1, 1, 0], [2, 0, 1, 1, 1, 3], [2, 0, 1, 1, 1, 4], [2, 0, 1, 1, 1, 5], [2, 0, 1, 1, 0, 2], [2, 0, 1, 1, 0, 1], [2, 0, 1, 1, 0, 0], [2, 0, 1, 1, 0, 3], [2, 0, 1, 1, 0, 4], [2, 0, 1, 1, 0, 5], [2, 0, 0, 0, 2, 2], [2, 0, 0, 0, 2, 1], [2, 0, 0, 0, 2, 0], [2, 0, 0, 0, 2, 3], [2, 0, 0, 0, 2, 4], [2, 0, 0, 0, 2, 5], [2, 0, 0, 0, 1, 2], [2, 0, 0, 0, 1, 1], [2, 0, 0, 0, 1, 0], [2, 0, 0, 0, 1, 3], [2, 0, 0, 0, 1, 4], [2, 0, 0, 0, 1, 5], [2, 0, 0, 0, 0, 2], [2, 0, 0, 0, 0, 1], [2, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 3], [2, 0, 0, 0, 0, 4], [2, 0, 0, 0, 0, 5], [2, 0, 0, 1, 2, 2], [2, 0, 0, 1, 2, 1], [2, 0, 0, 1, 2, 0], [2, 0, 0, 1, 2, 3], [2, 0, 0, 1, 2, 4], [2, 0, 0, 1, 2, 5], [2, 0, 0, 1, 1, 2], [2, 0, 0, 1, 1, 1], [2, 0, 0, 1, 1, 0], [2, 0, 0, 1, 1, 3], [2, 0, 0, 1, 1, 4], [2, 0, 0, 1, 1, 5], [2, 0, 0, 1, 0, 2], [2, 0, 0, 1, 0, 1], [2, 0, 0, 1, 0, 0], [2, 0, 0, 1, 0, 3], [2, 0, 0, 1, 0, 4], [2, 0, 0, 1, 0, 5], [2, 1, 1, 0, 2, 2], [2, 1, 1, 0, 2, 1], [2, 1, 1, 0, 2, 0], [2, 1, 1, 0, 2, 3], [2, 1, 1, 0, 2, 4], [2, 1, 1, 0, 2, 5], [2, 1, 1, 0, 1, 2], [2, 1, 1, 0, 1, 1], [2, 1, 1, 0, 1, 0], [2, 1, 1, 0, 1, 3], [2, 1, 1, 0, 1, 4], [2, 1, 1, 0, 1, 5], [2, 1, 1, 0, 0, 2], [2, 1, 1, 0, 0, 1], [2, 1, 1, 0, 0, 0], [2, 1, 1, 0, 0, 3], [2, 1, 1, 0, 0, 4], [2, 1, 1, 0, 0, 5], [2, 1, 1, 1, 2, 2], [2, 1, 1, 1, 2, 1], [2, 1, 1, 1, 2, 0], [2, 1, 1, 1, 2, 3], [2, 1, 1, 1, 2, 4], [2, 1, 1, 1, 2, 5], [2, 1, 1, 1, 1, 2], [2, 1, 1, 1, 1, 1], [2, 1, 1, 1, 1, 0], [2, 1, 1, 1, 1, 3], [2, 1, 1, 1, 1, 4], [2, 1, 1, 1, 1, 5], [2, 1, 1, 1, 0, 2], [2, 1, 1, 1, 0, 1], [2, 1, 1, 1, 0, 0], [2, 1, 1, 1, 0, 3], [2, 1, 1, 1, 0, 4], [2, 1, 1, 1, 0, 5], [2, 1, 0, 0, 2, 2], [2, 1, 0, 0, 2, 1], [2, 1, 0, 0, 2, 0], [2, 1, 0, 0, 2, 3], [2, 1, 0, 0, 2, 4], [2, 1, 0, 0, 2, 5], [2, 1, 0, 0, 1, 2], [2, 1, 0, 0, 1, 1], [2, 1, 0, 0, 1, 0], [2, 1, 0, 0, 1, 3], [2, 1, 0, 0, 1, 4], [2, 1, 0, 0, 1, 5], [2, 1, 0, 0, 0, 2], [2, 1, 0, 0, 0, 1], [2, 1, 0, 0, 0, 0], [2, 1, 0, 0, 0, 3], [2, 1, 0, 0, 0, 4], [2, 1, 0, 0, 0, 5], [2, 1, 0, 1, 2, 2], [2, 1, 0, 1, 2, 1], [2, 1, 0, 1, 2, 0], [2, 1, 0, 1, 2, 3], [2, 1, 0, 1, 2, 4], [2, 1, 0, 1, 2, 5], [2, 1, 0, 1, 1, 2], [2, 1, 0, 1, 1, 1], [2, 1, 0, 1, 1, 0], [2, 1, 0, 1, 1, 3], [2, 1, 0, 1, 1, 4], [2, 1, 0, 1, 1, 5], [2, 1, 0, 1, 0, 2], [2, 1, 0, 1, 0, 1], [2, 1, 0, 1, 0, 0], [2, 1, 0, 1, 0, 3], [2, 1, 0, 1, 0, 4], [2, 1, 0, 1, 0, 5], [2, 2, 1, 0, 2, 2], [2, 2, 1, 0, 2, 1], [2, 2, 1, 0, 2, 0], [2, 2, 1, 0, 2, 3], [2, 2, 1, 0, 2, 4], [2, 2, 1, 0, 2, 5], [2, 2, 1, 0, 1, 2], [2, 2, 1, 0, 1, 1], [2, 2, 1, 0, 1, 0], [2, 2, 1, 0, 1, 3], [2, 2, 1, 0, 1, 4], [2, 2, 1, 0, 1, 5], [2, 2, 1, 0, 0, 2], [2, 2, 1, 0, 0, 1], [2, 2, 1, 0, 0, 0], [2, 2, 1, 0, 0, 3], [2, 2, 1, 0, 0, 4], [2, 2, 1, 0, 0, 5], [2, 2, 1, 1, 2, 2], [2, 2, 1, 1, 2, 1], [2, 2, 1, 1, 2, 0], [2, 2, 1, 1, 2, 3], [2, 2, 1, 1, 2, 4], [2, 2, 1, 1, 2, 5], [2, 2, 1, 1, 1, 2], [2, 2, 1, 1, 1, 1], [2, 2, 1, 1, 1, 0], [2, 2, 1, 1, 1, 3], [2, 2, 1, 1, 1, 4], [2, 2, 1, 1, 1, 5], [2, 2, 1, 1, 0, 2], [2, 2, 1, 1, 0, 1], [2, 2, 1, 1, 0, 0], [2, 2, 1, 1, 0, 3], [2, 2, 1, 1, 0, 4], [2, 2, 1, 1, 0, 5], [2, 2, 0, 0, 2, 2], [2, 2, 0, 0, 2, 1], [2, 2, 0, 0, 2, 0], [2, 2, 0, 0, 2, 3], [2, 2, 0, 0, 2, 4], [2, 2, 0, 0, 2, 5], [2, 2, 0, 0, 1, 2], [2, 2, 0, 0, 1, 1], [2, 2, 0, 0, 1, 0], [2, 2, 0, 0, 1, 3], [2, 2, 0, 0, 1, 4], [2, 2, 0, 0, 1, 5], [2, 2, 0, 0, 0, 2], [2, 2, 0, 0, 0, 1], [2, 2, 0, 0, 0, 0], [2, 2, 0, 0, 0, 3], [2, 2, 0, 0, 0, 4], [2, 2, 0, 0, 0, 5], [2, 2, 0, 1, 2, 2], [2, 2, 0, 1, 2, 1], [2, 2, 0, 1, 2, 0], [2, 2, 0, 1, 2, 3], [2, 2, 0, 1, 2, 4], [2, 2, 0, 1, 2, 5], [2, 2, 0, 1, 1, 2], [2, 2, 0, 1, 1, 1], [2, 2, 0, 1, 1, 0], [2, 2, 0, 1, 1, 3], [2, 2, 0, 1, 1, 4], [2, 2, 0, 1, 1, 5], [2, 2, 0, 1, 0, 2], [2, 2, 0, 1, 0, 1], [2, 2, 0, 1, 0, 0], [2, 2, 0, 1, 0, 3], [2, 2, 0, 1, 0, 4], [2, 2, 0, 1, 0, 5]]} {0: [], 1: ['stay'], 2: ['age'], 3: ['charge'], 4: ['sex'], 5: ['#prior'], 6: ['race'], 7: ['stay', 'age'], 8: ['stay', 'charge'], 9: ['stay', 'sex'], 10: ['stay', '#prior'], 11: ['stay', 'race'], 12: ['age', 'charge'], 13: ['age', 'sex'], 14: ['age', '#prior'], 15: ['age', 'race'], 16: ['charge', 'sex'], 17: ['charge', '#prior'], 18: ['charge', 'race'], 19: ['sex', '#prior'], 20: ['sex', 'race'], 21: ['#prior', 'race'], 22: ['stay', 'age', 'charge'], 23: ['stay', 'age', 'sex'], 24: ['stay', 'age', '#prior'], 25: ['stay', 'age', 'race'], 26: ['stay', 'charge', 'sex'], 27: ['stay', 'charge', '#prior'], 28: ['stay', 'charge', 'race'], 29: ['stay', 'sex', '#prior'], 30: ['stay', 'sex', 'race'], 31: ['stay', '#prior', 'race'], 32: ['age', 'charge', 'sex'], 33: ['age', 'charge', '#prior'], 34: ['age', 'charge', 'race'], 35: ['age', 'sex', '#prior'], 36: ['age', 'sex', 'race'], 37: ['age', '#prior', 'race'], 38: ['charge', 'sex', '#prior'], 39: ['charge', 'sex', 'race'], 40: ['charge', '#prior', 'race'], 41: ['sex', '#prior', 'race'], 42: ['stay', 'age', 'charge', 'sex'], 43: ['stay', 'age', 'charge', '#prior'], 44: ['stay', 'age', 'charge', 'race'], 45: ['stay', 'age', 'sex', '#prior'], 46: ['stay', 'age', 'sex', 'race'], 47: ['stay', 'age', '#prior', 'race'], 48: ['stay', 'charge', 'sex', '#prior'], 49: ['stay', 'charge', 'sex', 'race'], 50: ['stay', 'charge', '#prior', 'race'], 51: ['stay', 'sex', '#prior', 'race'], 52: ['age', 'charge', 'sex', '#prior'], 53: ['age', 'charge', 'sex', 'race'], 54: ['age', 'charge', '#prior', 'race'], 55: ['age', 'sex', '#prior', 'race'], 56: ['charge', 'sex', '#prior', 'race'], 57: ['stay', 'age', 'charge', 'sex', '#prior'], 58: ['stay', 'age', 'charge', 'sex', 'race'], 59: ['stay', 'age', 'charge', '#prior', 'race'], 60: ['stay', 'age', 'sex', '#prior', 'race'], 61: ['stay', 'charge', 'sex', '#prior', 'race'], 62: ['age', 'charge', 'sex', '#prior', 'race'], 63: ['stay', 'age', 'charge', 'sex', '#prior', 'race']}\n",
            "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
            "[63, 62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Algorithm Lattice\n"
      ],
      "metadata": {
        "id": "SGdoCnWLlkc4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bebc14d-a1e7-4a96-bd75-a62580cb6751",
        "id": "QfMMRp-S4vTL"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/////////////\n",
            "63\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1], [0, 1, 0, 1, 2, 1], [1, 1, 0, 0, 1, 1]]\n",
            "[[0, 1, 0, 0, 2, 1], [0, 1, 1, 0, 2, 1], [0, 1, 1, 0, 2, 2], [0, 2, 0, 0, 1, 1], [0, 2, 1, 0, 0, 1], [1, 1, 0, 0, 2, 1], [1, 1, 0, 0, 2, 2], [2, 1, 0, 0, 2, 1]]\n",
            "started pref sampling\n",
            "0.432 3 40 9.97206703910615\n",
            "1.050420168067227 8 32 12.4918032786885\n",
            "0.9322429906542056 28 83 25.5538089480048\n",
            "1.8057553956834533 27 22 4.53589743589744\n",
            "1.306878306878307 17 18 2.82798165137617\n",
            "updated 104 positive records\n",
            "1.2645348837209303 187 74 41.2554557124519\n",
            "1.3547008547008548 75 38 9.98911070780409\n",
            "0.8894230769230769 23 8 8.40712468193384\n",
            "1.0424710424710424 92 30 29.7315689981096\n",
            "0.6716417910447762 22 18 5.92857142857143\n",
            "2.3655172413793104 85 20 11.1987704918033\n",
            "1.8256880733944953 28 6 6.03246753246753\n",
            "2.7304347826086954 25 8 0.846153846153846\n",
            "updated 218 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2400\n",
            "1    1921\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "62\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 0, 1, 2]]\n",
            "[[0, 0, 0, 2, 2], [1, 0, 0, 2, 2], [1, 0, 1, 1, 2], [1, 0, 1, 2, 1], [1, 1, 0, 2, 1], [2, 0, 0, 1, 2], [2, 0, 0, 2, 1], [2, 1, 0, 1, 1]]\n",
            "started pref sampling\n",
            "0.7397769516728625 26 64 12.2692307692308\n",
            "updated 24 positive records\n",
            "0.9867256637168141 31 19 6.16703786191537\n",
            "1.1546391752577319 79 53 8.26315789473684\n",
            "0.6598984771573604 25 18 7.90519877675841\n",
            "1.3177966101694916 47 22 7.76965265082269\n",
            "1.0979228486646884 92 58 13.4992927864214\n",
            "0.8843537414965986 38 25 8.43321299638989\n",
            "1.4310344827586208 39 5 13.0992907801418\n",
            "0.9383886255924171 35 17 9.82640586797066\n",
            "updated 142 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2459\n",
            "1    1862\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "61\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 0, 1]]\n",
            "[[1, 0, 0, 1, 1], [1, 0, 0, 2, 1], [1, 0, 0, 2, 2], [1, 1, 0, 2, 1], [2, 0, 0, 2, 1]]\n",
            "started pref sampling\n",
            "0.6231454005934718 13 46 9.65082266910421\n",
            "updated 18 positive records\n",
            "1.0946745562130178 55 34 8.48870056497175\n",
            "1.5914396887159532 102 48 9.88288288288296\n",
            "1.2722772277227723 35 17 5.88453159041394\n",
            "1.3311688311688312 34 16 5.44846796657383\n",
            "1.509009009009009 42 17 6.51526032315977\n",
            "updated 66 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2483\n",
            "1    1838\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "60\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1, 0, 1], [1, 0, 0, 2, 1]]\n",
            "[[0, 0, 0, 2, 1], [0, 1, 1, 1, 2], [0, 2, 1, 0, 1], [1, 1, 0, 2, 1], [1, 2, 0, 1, 1], [2, 1, 0, 2, 1]]\n",
            "started pref sampling\n",
            "0.5329153605015674 12 57 11.9877300613497\n",
            "1.3759398496240602 15 28 9.90189873417721\n",
            "updated 40 positive records\n",
            "0.882183908045977 46 37 7.09770992366412\n",
            "0.4892086330935252 24 30 6.26086956521739\n",
            "0.5365853658536586 22 25 5.58730158730159\n",
            "1.2107142857142856 98 43 20.7802907915992\n",
            "1.0548780487804879 31 15 7.38575667655786\n",
            "1.3306772908366533 26 8 6.58803418803421\n",
            "updated 102 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2514\n",
            "1    1807\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "59\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 0, 0, 3], [0, 2, 0, 1, 2], [1, 0, 0, 2, 1], [1, 1, 1, 2, 1]]\n",
            "[[0, 2, 1, 1, 1], [1, 1, 0, 2, 1]]\n",
            "started pref sampling\n",
            "0.5928853754940712 5 27 6.91066997518610\n",
            "0.8834586466165414 16 31 6.04590818363273\n",
            "1.3305084745762712 18 21 4.26545454545455\n",
            "1.401639344262295 7 24 11.0921501706484\n",
            "updated 54 positive records\n",
            "0.7288888888888889 26 25 4.49871465295630\n",
            "1.0888888888888888 88 41 20.7553191489362\n",
            "updated 48 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2511\n",
            "1    1810\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "58\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 0, 0, 0], [0, 1, 1, 0, 0], [1, 0, 0, 0, 1]]\n",
            "[[0, 2, 0, 0, 3], [0, 2, 0, 1, 1], [0, 2, 1, 0, 2], [1, 2, 0, 0, 1]]\n",
            "started pref sampling\n",
            "0.815742397137746 17 33 5.46305418719212\n",
            "0.5416666666666666 7 30 6.00000000000000\n",
            "1.0252100840336134 18 27 4.78008298755187\n",
            "updated 30 positive records\n",
            "0.9213483146067416 20 11 5.13450292397661\n",
            "0.7923076923076923 29 26 4.68669527896996\n",
            "0.547945205479452 23 19 8.13274336283186\n",
            "1.024822695035461 42 30 5.55866900175131\n",
            "updated 44 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2518\n",
            "1    1803\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "57\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 0, 0, 1], [2, 0, 0, 0, 2]]\n",
            "[[0, 1, 0, 1, 2], [0, 1, 1, 0, 2], [0, 2, 0, 0, 2], [1, 2, 0, 0, 1], [2, 1, 0, 0, 2]]\n",
            "started pref sampling\n",
            "1.0108695652173914 11 33 11.1189189189189\n",
            "1.179245283018868 12 19 4.77489177489177\n",
            "updated 30 positive records\n",
            "0.9033333333333333 42 32 6.87915936952715\n",
            "0.7032755298651252 81 79 14.9366515837104\n",
            "1.0298850574712644 22 16 2.72027180067950\n",
            "0.8925233644859814 43 28 9.51604938271605\n",
            "1.1354166666666667 35 17 7.35121951219512\n",
            "updated 76 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2541\n",
            "1    1780\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "56\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1, 2], [0, 1, 2, 1]]\n",
            "[[0, 1, 2, 2]]\n",
            "started pref sampling\n",
            "0.7888198757763976 18 50 11.9861111111111\n",
            "1.103896103896104 29 46 10.3518518518519\n",
            "updated 42 positive records\n",
            "0.7217741935483871 25 14 8.65105386416862\n",
            "updated 16 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2528\n",
            "1    1793\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "55\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 1, 0]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.6704805491990846 22 18 5.94520547945205\n",
            "updated 10 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2533\n",
            "1    1788\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "54\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 1, 2], [0, 1, 2, 1], [2, 0, 1, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.6422287390029325 52 52 11.3285714285714\n",
            "0.7699115044247787 23 21 3.86000000000000\n",
            "0.8188775510204082 113 99 17.5553997194951\n",
            "updated 62 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2564\n",
            "1    1757\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "53\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 0, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.7455947136563876 398 379 66.1205047318611\n",
            "updated 132 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2630\n",
            "1    1691\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "52\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 0, 0, 2], [2, 1, 0, 0]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.8342696629213483 34 26 6.71056661562021\n",
            "0.4530612244897959 45 57 13.1966292134831\n",
            "updated 38 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2649\n",
            "1    1672\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "51\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 2, 1], [1, 0, 2, 2]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.7301255230125523 118 93 28.9564691656590\n",
            "0.9707792207792207 40 28 6.50411861614498\n",
            "updated 68 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2683\n",
            "1    1638\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "50\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 2, 2], [1, 1, 2, 1]]\n",
            "[[0, 0, 2, 2], [1, 0, 2, 1]]\n",
            "started pref sampling\n",
            "1.0337078651685394 25 40 8.03867403314917\n",
            "0.8558951965065502 5 29 10.6800000000000\n",
            "updated 36 positive records\n",
            "0.6017441860465116 73 77 16.6479128856624\n",
            "0.6327433628318584 100 93 25.2059620596206\n",
            "updated 82 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2706\n",
            "1    1615\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "49\n",
            "The sets of need pos and neg are\n",
            "[[1, 1, 0, 1]]\n",
            "[[1, 1, 0, 2]]\n",
            "started pref sampling\n",
            "0.6534839924670434 11 43 10.3416856492027\n",
            "updated 20 positive records\n",
            "0.5162907268170426 30 27 10.5917355371901\n",
            "updated 20 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2706\n",
            "1    1615\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "48\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 1, 2], [1, 1, 0, 1], [2, 0, 0, 2]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.5522935779816514 46 46 13.2671394799055\n",
            "0.5725190839694656 41 41 11.1456310679612\n",
            "0.6365384615384615 46 39 12.9388954171563\n",
            "updated 72 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2742\n",
            "1    1579\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "47\n",
            "The sets of need pos and neg are\n",
            "[[0, 2, 0, 0], [1, 0, 2, 1]]\n",
            "[[0, 0, 2, 1], [0, 2, 0, 3], [1, 1, 0, 2], [1, 1, 2, 1], [2, 1, 2, 1]]\n",
            "started pref sampling\n",
            "0.5517241379310345 6 27 5.73333333333333\n",
            "0.8587570621468926 7 55 21.6443768996960\n",
            "updated 52 positive records\n",
            "0.4725897920604915 41 53 10.8331193838254\n",
            "0.51875 16 15 5.41152263374486\n",
            "0.4804270462633452 15 18 4.29086538461539\n",
            "0.5623678646934461 72 67 21.9675236806495\n",
            "0.6024096385542169 19 18 5.09022556390977\n",
            "updated 90 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2761\n",
            "1    1560\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "46\n",
            "The sets of need pos and neg are\n",
            "[[0, 0, 1, 1], [1, 0, 0, 1]]\n",
            "[[1, 0, 1, 1], [1, 1, 0, 2], [1, 1, 1, 1]]\n",
            "started pref sampling\n",
            "0.5518134715025906 7 32 6.86811352253757\n",
            "0.6543535620052771 7 46 13.9633173843700\n",
            "updated 38 positive records\n",
            "0.4230769230769231 30 2 20.4864864864865\n",
            "0.5629496402877698 59 66 13.9769850402762\n",
            "0.6394557823129252 17 15 4.51867219917012\n",
            "updated 74 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2779\n",
            "1    1542\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "45\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 0, 2]]\n",
            "[[1, 0, 0, 1]]\n",
            "started pref sampling\n",
            "0.6423841059602649 7 34 9.03629032258065\n",
            "updated 18 positive records\n",
            "0.5961538461538461 37 39 8.61445783132530\n",
            "updated 16 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2778\n",
            "1    1543\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "44\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 0, 1, 1], [1, 2, 0, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.4527027027027027 20 26 5.66511627906977\n",
            "0.6501305483028721 40 40 8.48101265822785\n",
            "updated 26 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2791\n",
            "1    1530\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "43\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 0, 1], [1, 2, 0, 0], [2, 0, 0, 2]]\n",
            "[[0, 1, 1, 2], [1, 0, 0, 2], [1, 0, 1, 1]]\n",
            "started pref sampling\n",
            "0.7991803278688525 8 41 13.7653758542141\n",
            "0.7355371900826446 10 23 3.98571428571429\n",
            "0.7279411764705882 9 23 4.48085106382979\n",
            "updated 40 positive records\n",
            "0.4355044699872286 75 97 22.8185053380783\n",
            "0.5164835164835165 23 23 7.33333333333333\n",
            "0.3463687150837989 19 26 7.42323651452282\n",
            "updated 72 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2807\n",
            "1    1514\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "42\n",
            "The sets of need pos and neg are\n",
            "[[1, 1, 0, 1]]\n",
            "[[1, 0, 1, 0]]\n",
            "started pref sampling\n",
            "0.7306590257879656 9 29 7.04304635761590\n",
            "updated 14 positive records\n",
            "0.29476584022038566 15 25 5.89361702127659\n",
            "updated 10 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2805\n",
            "1    1516\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "41\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 2, 3], [1, 2, 1], [1, 2, 2]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.47750865051903113 22 24 7.13348946135831\n",
            "0.4578313253012048 49 48 18.5371900826446\n",
            "0.5197215777262181 24 22 8.26870229007634\n",
            "updated 66 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2838\n",
            "1    1483\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "40\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.5161812297734628 160 191 40.5026680896478\n",
            "updated 80 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2878\n",
            "1    1443\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "39\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[0, 0, 0]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.5599730458221024 57 62 14.2833693304536\n",
            "updated 28 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2892\n",
            "1    1429\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "38\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 2]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.2922201138519924 26 13 17.1806167400881\n",
            "updated 34 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2909\n",
            "1    1412\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "37\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2909\n",
            "1    1412\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "36\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2909\n",
            "1    1412\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "35\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[2, 1, 1]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.5964523281596452 29 32 6.20972222222223\n",
            "updated 12 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2915\n",
            "1    1406\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "34\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2915\n",
            "1    1406\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "33\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2915\n",
            "1    1406\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "32\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2915\n",
            "1    1406\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "31\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 1]]\n",
            "[[1, 1, 2], [2, 1, 1]]\n",
            "started pref sampling\n",
            "0.4755905511811024 2 63 18.9498399146211\n",
            "updated 36 positive records\n",
            "0.5513307984790875 63 71 15.3774509803921\n",
            "0.6332737030411449 17 17 3.81708652792990\n",
            "updated 36 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2915\n",
            "1    1406\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "30\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 2]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.3953488372093023 19 25 6.53333333333333\n",
            "updated 12 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2921\n",
            "1    1400\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "29\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[[1, 1, 0]]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "0.2698019801980198 23 20 13.8635477582846\n",
            "updated 26 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2934\n",
            "1    1387\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "28\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2934\n",
            "1    1387\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "27\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2934\n",
            "1    1387\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "26\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2934\n",
            "1    1387\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "25\n",
            "The sets of need pos and neg are\n",
            "[[1, 0, 1]]\n",
            "[]\n",
            "started pref sampling\n",
            "0.5054945054945055 9 67 16.5182481751825\n",
            "updated 32 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "24\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "23\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "22\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "21\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "20\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "19\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "18\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "17\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "16\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "15\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "14\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "13\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "12\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "11\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "10\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "9\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "8\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2918\n",
            "1    1403\n",
            "Name: class, dtype: int64\n",
            "model accuracy\n",
            "best 0.6211624158832897\n",
            "fpr and fnr\n",
            "0.058823529411764705\n",
            "0.9097472924187726\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#get all of the candidate groups possible with the combos and names\n",
        "filter_count =30\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "# for a in [all_names_lst[0]]: # leaf\n",
        "# for a in [all_names_lst[-1:x]]: # top\n",
        "  print(\"/////////////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  # print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started pref sampling\")\n",
        "  new_train_data = pref_sampling_opt(new_train_data, names, compas_y, need_pos, need_neg)\n",
        "  # print(new_train_data)\n",
        "  print(new_train_data['class'].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n",
        "grid_new = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = param, cv = 6)\n",
        "grid_new.fit(new_train_x, new_train_label)\n",
        "print(\"model accuracy\")\n",
        "print(\"best\", grid_new.best_score_)\n",
        "test_predict = grid_new.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "# print(pref_sampling_mod(train_x, train_set, train_label, names, compas_y, need_pos, need_neg))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #get all of the candidate groups possible with the combos and names\n",
        "# import random\n",
        "# new_train_data = copy.deepcopy(train_set)\n",
        "# import csv\n",
        "\n",
        "# with open('time_data.csv', 'a', newline='') as file:\n",
        "#   writer = csv.writer(file)\n",
        "#   writer.writerow([\"Dataset\",\"Algorithm\",\"Attribute_names\",\"NumAttr\",\"IdTime\",\"AlgoTime\"])\n",
        "# #iterate over all the names to get the temp2 df for each name\n",
        "# # for a in [all_names_lst[0]]:\n",
        "# # # for a in [all_names_lst[0]]: # leaf\n",
        "# # # for a in [all_names_lst[-1:x]]: # top\n",
        "# #   print(\"/////////////\")\n",
        "# #   print(all_names[a])\n",
        "#   for c in range(2,len(columns_compas)+1):\n",
        "#     list_write = []\n",
        "#     list_write.append(\"COMPAS\")\n",
        "#     list_write.append(\"Pref_opt\")\n",
        "\n",
        "#     val_names = random.sample(columns_compas, k=c)\n",
        "#     print(val_names)\n",
        "#     list_write.append(val_names)\n",
        "#     list_write.append(len(val_names))\n",
        "#     temp2, names = get_temp(new_train_data, val_names, compas_y)\n",
        "#     temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "#     temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "#     lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "#     start = time.time()\n",
        "#     need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "#     end = time.time()\n",
        "#     excute_time = end - start\n",
        "#     print(\"id time\", excute_time)\n",
        "#     list_write.append(excute_time)\n",
        "#     # print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "#     # print(\"The sets of need pos and neg are\")\n",
        "#     # print(need_pos)\n",
        "#     # print(need_neg)\n",
        "#     new_train_data['skewed'] = 0\n",
        "#     new_train_data[\"diff\"] = 0\n",
        "#     print(\"started pref sampling\")\n",
        "#     start1 = time.time()\n",
        "#     new_train_data = pref_sampling_opt(new_train_data, names, compas_y, need_pos, need_neg)\n",
        "#     end1 = time.time()\n",
        "#     excute_time1 = end1 - start1\n",
        "#     print(\"pref_sample time\", excute_time1)\n",
        "#     list_write.append(excute_time1)\n",
        "#     # print(new_train_data)\n",
        "#     # print(new_train_data['class'].value_counts())\n",
        "#     writer.writerow(list_write)"
      ],
      "metadata": {
        "id": "E4eg1CiZE8Uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0434af88-220e-485a-a38e-c3557181ded8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BVIPRKUMyJk",
        "outputId": "babd8ef1-1904-4905-d515-aa8d3e98a2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1020\n",
              "1     831\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Lattice"
      ],
      "metadata": {
        "id": "euVPjcb_lqe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"newwww\")\n",
        "print(\"dt\")\n",
        "griddt.fit(new_train_x, new_train_label)\n",
        "print(\"best\", griddt.best_score_)\n",
        "\n",
        "test_predict = griddt.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label,test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Lattice\",\"DT\")\n",
        "\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label,test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridlg.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridlg.best_score_)\n",
        "test_predict = gridlg.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label,test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Lattice\",\"LG\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "clf.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = clf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "accuracy = accuracy_score(test_label, test_predict)\n",
        "print(\"accuracy\")\n",
        "print(accuracy)\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Preferential Sampling-Lattice\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0kyJ79tFVUV",
        "outputId": "958fa055-0658-440f-9892-1df8431eb340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "newwww\n",
            "dt\n",
            "best 0.6753066795118818\n",
            "fpr and fnr\n",
            "0.0\n",
            "1.0\n",
            "accuracy\n",
            "0.5510534846029174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0.8613400089486869\n",
            "accuracy is  0.5510534846029174\n",
            "['COMPAS', 'Preferential Sampling-Lattice', 'DT', 0, 0, 0.8613400089486869, 0.5510534846029174]\n",
            "\n",
            "rf\n",
            "best 0.6387417041318775\n",
            "fpr and fnr\n",
            "0.0696078431372549\n",
            "0.9121540312876053\n",
            "accuracy\n",
            "0.5521339816315505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30472896327769233\n",
            "0.589635534178638\n",
            "0.825726219798547\n",
            "accuracy is  0.5521339816315505\n",
            "['COMPAS', 'Preferential Sampling-Lattice', 'RF', 0.30472896327769233, 0.589635534178638, 0.825726219798547, 0.5521339816315505]\n",
            "\n",
            "logistic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.67530668        nan 0.67530668        nan 0.67530668\n",
            "        nan 0.67530668        nan 0.67530668]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best 0.6753066795118818\n",
            "fpr and fnr\n",
            "0.0\n",
            "1.0\n",
            "accuracy\n",
            "0.5510534846029174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0.8613400089486869\n",
            "accuracy is  0.5510534846029174\n",
            "['COMPAS', 'Preferential Sampling-Lattice', 'LG', 0, 0, 0.8613400089486869, 0.5510534846029174]\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.05196078431372549\n",
            "0.9217809867629362\n",
            "accuracy\n",
            "0.5575364667747164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21684282600467258\n",
            "0.5069323916536446\n",
            "0.7949139586381534\n",
            "accuracy is  0.5575364667747164\n",
            "['COMPAS', 'Preferential Sampling-Lattice', 'SVM', 0.21684282600467258, 0.5069323916536446, 0.7949139586381534, 0.5575364667747164]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d,d1,d2 = div_results(\"COMPAS\",\"Preferential Sampling-Lattice\",\"DT\")\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridl.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridl.best_score_)\n",
        "test_predict = gridl.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Lattice\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "svc.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = svc.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Preferential Sampling-Lattice\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDvLtC3BlDpa",
        "outputId": "33783aaa-358a-46f4-991d-02aa8b5c1013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.19650015623325476\n",
            "0.6485365202315879\n",
            "0.8610501835706659\n",
            "accuracy is  0.5591572123176661\n",
            "['COMPAS', 'Preferential Sampling-Lattice', 'DT', 0.19650015623325476, 0.6485365202315879, 0.8610501835706659, 0.5591572123176661]\n",
            "\n",
            "rf\n",
            "best 0.6213874762418452\n",
            "fpr and fnr\n",
            "0.043137254901960784\n",
            "0.9350180505415162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.19236531691020695\n",
            "0.45120683201997236\n",
            "0.8260659546827515\n",
            "accuracy is  0.5564559697460832\n",
            "['COMPAS', 'Preferential Sampling-Lattice', 'RF', 0.19236531691020695, 0.45120683201997236, 0.8260659546827515, 0.5564559697460832]\n",
            "\n",
            "logistic\n",
            "best 0.6753066086197154\n",
            "fpr and fnr\n",
            "0.0\n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0.8613400089486869\n",
            "accuracy is  0.5510534846029174\n",
            "['COMPAS', 'Preferential Sampling-Lattice', 'L', 0, 0, 0.8613400089486869, 0.5510534846029174]\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.05196078431372549\n",
            "0.9217809867629362\n",
            "0.21684282600467258\n",
            "0.5069323916536446\n",
            "0.7949139586381534\n",
            "accuracy is  0.5575364667747164\n",
            "['COMPAS', 'Preferential Sampling-Lattice', 'SVM', 0.21684282600467258, 0.5069323916536446, 0.7949139586381534, 0.5575364667747164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Algorithm Leaf"
      ],
      "metadata": {
        "id": "FaHdC0EaqzZz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x-kS0DqRq2_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd6f639-3481-42cf-9332-40576f4b8a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a62ce9-a14d-4f98-c1c8-08c6b838f0e4",
        "id": "nh523URuq7AD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/////////////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1], [0, 2, 0], [1, 0, 0], [1, 1, 1], [1, 3, 0], [2, 2, 1]]\n",
            "[[1, 1, 0], [2, 1, 0], [2, 2, 0], [2, 3, 0]]\n",
            "started pref sampling\n",
            "0.6494382022471911 13 39 7.47411444141689\n",
            "0.7466487935656837 99 242 46.7689946277821\n",
            "0.949119373776908 39 70 14.0773092369478\n",
            "0.9986577181208054 91 146 27.4204163868368\n",
            "0.9566929133858267 62 105 19.6519114688129\n",
            "0.7109826589595376 15 37 6.60810810810811\n",
            "updated 238 positive records\n",
            "0.8915906788247214 601 495 84.4065345474024\n",
            "1.1191895113230035 297 160 55.6484814398204\n",
            "0.8922518159806295 105 86 14.9379398592450\n",
            "1.1797235023041475 39 25 4.36152219873150\n",
            "updated 314 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2381\n",
            "1    1940\n",
            "Name: class, dtype: int64\n",
            "model accuracy\n",
            "best 0.5098284918066471\n",
            "fpr and fnr\n",
            "0.10098039215686275\n",
            "0.8158844765342961\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in [all_names_lst[0]]:\n",
        "# for a in [all_names_lst[0]]: # leaf\n",
        "# for a in [all_names_lst[-1:x]]: # top\n",
        "  print(\"/////////////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  # print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started pref sampling\")\n",
        "  new_train_data = pref_sampling_opt(new_train_data, names, compas_y, need_pos, need_neg)\n",
        "  # print(new_train_data)\n",
        "  print(new_train_data['class'].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n",
        "grid_new = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = param, cv = 6)\n",
        "grid_new.fit(new_train_x, new_train_label)\n",
        "print(\"model accuracy\")\n",
        "print(\"best\", grid_new.best_score_)\n",
        "test_predict = grid_new.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "# print(pref_sampling_mod(train_x, train_set, train_label, names, compas_y, need_pos, need_neg))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Leaf"
      ],
      "metadata": {
        "id": "27rcEGB9rhrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set['predicted'] = test_predict\n",
        "# d, d2, d3 = div_results()"
      ],
      "metadata": {
        "id": "F1iW-8AYrlzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e051808-39d1-4318-cf7d-f6c1789f58b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d,d1,d2 = div_results(\"COMPAS\",\"Preferential Sampling-Leaf\",\"DT\")\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Leaf\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridl.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridl.best_score_)\n",
        "test_predict = gridl.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Leaf\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "svc.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = svc.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Preferential Sampling-Leaf\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-1zYQIWsDdn",
        "outputId": "34cced90-75b3-4625-881f-ab9fbc6e3cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5047859655944719\n",
            "0.24051395772019024\n",
            "0.09887802846359563\n",
            "accuracy is  0.5780659103187467\n",
            "['COMPAS', 'Preferential Sampling-Leaf', 'DT', 0.5047859655944719, 0.24051395772019024, 0.09887802846359563, 0.5780659103187467]\n",
            "\n",
            "rf\n",
            "best 0.5227914547696102\n",
            "fpr and fnr\n",
            "0.16568627450980392\n",
            "0.7773766546329723\n",
            "0.5388584428537804\n",
            "0.3483051325024953\n",
            "0.11255556810589926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is  0.5596974608319827\n",
            "['COMPAS', 'Preferential Sampling-Leaf', 'RF', 0.5388584428537804, 0.3483051325024953, 0.11255556810589926, 0.5596974608319827]\n",
            "\n",
            "logistic\n",
            "best 0.5345947629321416\n",
            "fpr and fnr\n",
            "0.0803921568627451\n",
            "0.8279181708784596\n",
            "0.4816722778874921\n",
            "0.22479409120253085\n",
            "0.09414946758815373\n",
            "accuracy is  0.5840086439762291\n",
            "['COMPAS', 'Preferential Sampling-Leaf', 'L', 0.4816722778874921, 0.22479409120253085, 0.09414946758815373, 0.5840086439762291]\n",
            "\n",
            "svm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fpr and fnr\n",
            "0.10098039215686275\n",
            "0.8158844765342961\n",
            "0.5047859655944719\n",
            "0.24051395772019024\n",
            "0.09887802846359563\n",
            "accuracy is  0.5780659103187467\n",
            "['COMPAS', 'Preferential Sampling-Leaf', 'SVM', 0.5047859655944719, 0.24051395772019024, 0.09887802846359563, 0.5780659103187467]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Algorithm Top"
      ],
      "metadata": {
        "id": "vM1zX7q-ruBj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d8bbc2-9f5d-4f41-f02f-208c62dd0c07",
        "id": "Mzp7XkuksXyD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/////////////\n",
            "1\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2343\n",
            "1    1978\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "2\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2343\n",
            "1    1978\n",
            "Name: class, dtype: int64\n",
            "/////////////\n",
            "3\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started pref sampling\n",
            "updated 0 positive records\n",
            "updated 0 negative records\n",
            "The new dataset contains 4321 rows.\n",
            "0    2343\n",
            "1    1978\n",
            "Name: class, dtype: int64\n",
            "model accuracy\n",
            "best 0.6051783145836545\n",
            "fpr and fnr\n",
            "0.3509803921568627\n",
            "0.4608904933814681\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "all_names_lst_top = find_top(all_names)\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst_top:\n",
        "# for a in [all_names_lst[0]]: # leaf\n",
        "# for a in [all_names_lst[-1:x]]: # top\n",
        "  print(\"/////////////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  # print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started pref sampling\")\n",
        "  new_train_data = pref_sampling_opt(new_train_data, names, compas_y, need_pos, need_neg)\n",
        "  # print(new_train_data)\n",
        "  print(new_train_data['class'].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n",
        "grid_new = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = param, cv = 6)\n",
        "grid_new.fit(new_train_x, new_train_label)\n",
        "print(\"model accuracy\")\n",
        "print(\"best\", grid_new.best_score_)\n",
        "test_predict = grid_new.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "# print(pref_sampling_mod(train_x, train_set, train_label, names, compas_y, need_pos, need_neg))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Top"
      ],
      "metadata": {
        "id": "kVRTFfXmr2NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set['predicted'] = test_predict\n",
        "# d, d2, d3 = div_results()"
      ],
      "metadata": {
        "id": "cwVjX5PNsj8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bdf0896-2a88-4ec8-8700-9ee22b4a13ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d,d1,d2 = div_results(\"COMPAS\",\"Preferential Sampling-Top\",\"DT\")\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Top\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridl.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridl.best_score_)\n",
        "test_predict = gridl.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Preferential Sampling-Top\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "svc.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = svc.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Preferential Sampling-Top\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cjoGWE-sFf9",
        "outputId": "b8a12074-fb51-40e3-fcf0-5f9d7b3c9678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0452612894198687\n",
            "0.5367298655917477\n",
            "0.06840316723975033\n",
            "accuracy is  0.5996758508914101\n",
            "['COMPAS', 'Preferential Sampling-Top', 'DT', 1.0452612894198687, 0.5367298655917477, 0.06840316723975033, 0.5996758508914101]\n",
            "\n",
            "rf\n",
            "best 0.604946833102173\n",
            "fpr and fnr\n",
            "0.3509803921568627\n",
            "0.4608904933814681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0452612894198687\n",
            "0.5367298655917477\n",
            "0.06840316723975033\n",
            "accuracy is  0.5996758508914101\n",
            "['COMPAS', 'Preferential Sampling-Top', 'RF', 1.0452612894198687, 0.5367298655917477, 0.06840316723975033, 0.5996758508914101]\n",
            "\n",
            "logistic\n",
            "best 0.5975435994246674\n",
            "fpr and fnr\n",
            "0.38333333333333336\n",
            "0.4332129963898917\n",
            "1.0149613181916723\n",
            "0.5583832084813722\n",
            "0.0746544058565157\n",
            "accuracy is  0.5942733657482442\n",
            "['COMPAS', 'Preferential Sampling-Top', 'L', 1.0149613181916723, 0.5583832084813722, 0.0746544058565157, 0.5942733657482442]\n",
            "\n",
            "svm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fpr and fnr\n",
            "0.3509803921568627\n",
            "0.4608904933814681\n",
            "1.0452612894198687\n",
            "0.5367298655917477\n",
            "0.06840316723975033\n",
            "accuracy is  0.5996758508914101\n",
            "['COMPAS', 'Preferential Sampling-Top', 'SVM', 1.0452612894198687, 0.5367298655917477, 0.06840316723975033, 0.5996758508914101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Duplication"
      ],
      "metadata": {
        "id": "JeNaCEQ26n7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def round_int(x):\n",
        "    if x in [float(\"-inf\"),float(\"inf\")]: return 0\n",
        "    return int(round(x))\n",
        "\n",
        "\n",
        "def make_duplicate(d, group_lst, diff, label_y, names, need_positive_or_negative):\n",
        "    #print(\"make samples\")\n",
        "    selected = copy.deepcopy(d)\n",
        "    print(\"names \", names, group_lst)\n",
        "    for i in range(len(group_lst)):\n",
        "        att_name = names[i]\n",
        "        selected = selected[(selected[att_name] == group_lst[i])]\n",
        "    selected = selected[(selected[label_y] == need_positive_or_negative)]\n",
        "    # print(\"=============\")\n",
        "    # print(group_lst, names)\n",
        "    # print(selected)\n",
        "    if len(selected) == 0:\n",
        "        return pd.DataFrame()\n",
        "    # print(len(temp))\n",
        "    # randomly generated diff samples:\n",
        "    # print(len(selected), diff)\n",
        "    while(len(selected) < diff):\n",
        "        # duplicate the dataframe\n",
        "        select_copy = selected.copy(deep=True)\n",
        "        selected = pd.concat([selected, select_copy])\n",
        "        # print(len(selected))\n",
        "        #generated = temp\n",
        "        # the number needed is more than the not needed numbers.\n",
        "    #print(len(temp))\n",
        "    generated = selected.sample(n = diff, replace = False, axis = 0)\n",
        "    # print(generated)\n",
        "    return generated\n",
        "\n",
        "\n",
        "def naive_duplicate(d, temp2, names, need_pos, need_neg, label_y):\n",
        "    # add more records for all groups\n",
        "    # The smote algorithm to boost the coverage\n",
        "    for r in need_pos:\n",
        "        # print(\"adding more positive\")\n",
        "    # add more positive records\n",
        "        # determine how many points to add\n",
        "        print(\"pos_vals\", r)\n",
        "        diff = compute_diff_add(r, temp2, names, label_y, 1)\n",
        "        diff = round_int(diff)\n",
        "        # add more records\n",
        "        print(\"Adding \" + str(diff) +\" positive records\")\n",
        "        samples_to_add = make_duplicate(d, r, diff, label_y, names, need_positive_or_negative = 1)\n",
        "        d = pd.concat([d, samples_to_add], ignore_index=True)\n",
        "    for k in need_neg:\n",
        "        print(\"neg_vals\", k)\n",
        "        # print(\"adding more negative\")\n",
        "        diff = compute_diff_add(k, temp2, names, label_y, need_positive_or_negative = 0)\n",
        "        diff = round_int(diff)\n",
        "        print(\"Adding \" + str(diff) +\" negative records\")\n",
        "        samples_to_add = make_duplicate(d, k, diff, label_y, names, need_positive_or_negative = 0)\n",
        "        d = pd.concat([d, samples_to_add], ignore_index=True)\n",
        "    return d"
      ],
      "metadata": {
        "id": "F-x05Dlbuc62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442f8beb-064a-49d6-a507-a2555038b21a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Algorithm Lattice"
      ],
      "metadata": {
        "id": "H_HqjDkKtclY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  # start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  # end = time.time()\n",
        "  # excute_time = end - start\n",
        "  # print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started duplication\")\n",
        "  new_train_data = naive_duplicate(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  # new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "  # new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "  # new_train_label = new_train_label[compas_y]\n",
        "  # new_train_label = new_train_label.astype('int')\n",
        "  # grid_new = DecisionTreeClassifier(criterion=\"entropy\",max_depth=6, random_state=17)\n",
        "  # grid_new.fit(new_train_x, new_train_label)\n",
        "  # test_predict = grid_new.predict(test_x)\n",
        "  # print(\"new trainset length\", len(new_train_x))\n",
        "  # print(\"fpr and fnr\")\n",
        "  # print(fpr_onegroup(list(test_label), test_predict))\n",
        "  # print(fnr_onegroup(list(test_label), test_predict))\n",
        "  print(\"class\", new_train_data['class'].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n",
        "grid_new = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = param, cv = 6)\n",
        "grid_new.fit(new_train_x, new_train_label)\n",
        "print(\"model accuracy\")\n",
        "print(\"best\", grid_new.best_score_)\n",
        "test_predict = grid_new.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptgbqFIO8PDF",
        "outputId": "e7f0010f-4266-4a68-9cf7-d0fb0976f643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1], [0, 2, 0], [1, 0, 0], [1, 1, 1], [1, 3, 0], [2, 2, 1]]\n",
            "[[1, 1, 0], [2, 1, 0], [2, 2, 0], [2, 3, 0]]\n",
            "started duplication\n",
            "pos_vals [0, 1, 1]\n",
            "0.6494382022471911 13 39 12.3280898876405\n",
            "0.6494382022471911 13 39 12.3280898876405\n",
            "Adding 12 positive records\n",
            "names  ['age', 'race', 'sex'] [0, 1, 1]\n",
            "pos_vals [0, 2, 0]\n",
            "0.7466487935656837 99 242 81.6890080428956\n",
            "0.7466487935656837 99 242 81.6890080428956\n",
            "Adding 82 positive records\n",
            "names  ['age', 'race', 'sex'] [0, 2, 0]\n",
            "pos_vals [1, 0, 0]\n",
            "0.949119373776908 39 70 27.4383561643836\n",
            "0.949119373776908 39 70 27.4383561643836\n",
            "Adding 27 positive records\n",
            "names  ['age', 'race', 'sex'] [1, 0, 0]\n",
            "pos_vals [1, 1, 1]\n",
            "0.9986577181208054 91 146 54.8040268456376\n",
            "0.9986577181208054 91 146 54.8040268456376\n",
            "Adding 55 positive records\n",
            "names  ['age', 'race', 'sex'] [1, 1, 1]\n",
            "pos_vals [1, 3, 0]\n",
            "0.9566929133858267 62 105 38.4527559055118\n",
            "0.9566929133858267 62 105 38.4527559055118\n",
            "Adding 38 positive records\n",
            "names  ['age', 'race', 'sex'] [1, 3, 0]\n",
            "pos_vals [2, 2, 1]\n",
            "0.7109826589595376 15 37 11.3063583815029\n",
            "0.7109826589595376 15 37 11.3063583815029\n",
            "Adding 11 positive records\n",
            "names  ['age', 'race', 'sex'] [2, 2, 1]\n",
            "neg_vals [1, 1, 0]\n",
            "0.8915906788247214 601 495 179.076136363637\n",
            "Adding 179 negative records\n",
            "names  ['age', 'race', 'sex'] [1, 1, 0]\n",
            "neg_vals [2, 1, 0]\n",
            "1.1191895113230035 297 160 105.370607028755\n",
            "Adding 105 negative records\n",
            "names  ['age', 'race', 'sex'] [2, 1, 0]\n",
            "neg_vals [2, 2, 0]\n",
            "0.8922518159806295 105 86 31.6797829036634\n",
            "Adding 32 negative records\n",
            "names  ['age', 'race', 'sex'] [2, 2, 0]\n",
            "neg_vals [2, 3, 0]\n",
            "1.1797235023041475 39 25 8.05859375000000\n",
            "Adding 8 negative records\n",
            "names  ['age', 'race', 'sex'] [2, 3, 0]\n",
            "class 0    2667\n",
            "1    2203\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "6\n",
            "The sets of need pos and neg are\n",
            "[[0, 1], [3, 1]]\n",
            "[]\n",
            "started duplication\n",
            "pos_vals [0, 1]\n",
            "0.7222222222222222 8 34 16.5555555555556\n",
            "0.7222222222222222 8 34 16.5555555555556\n",
            "Adding 17 positive records\n",
            "names  ['race', 'sex'] [0, 1]\n",
            "pos_vals [3, 1]\n",
            "0.7300435413642961 16 40 13.2017416545718\n",
            "0.7300435413642961 16 40 13.2017416545718\n",
            "Adding 13 positive records\n",
            "names  ['race', 'sex'] [3, 1]\n",
            "class 0    2667\n",
            "1    2233\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "5\n",
            "The sets of need pos and neg are\n",
            "[[0, 1]]\n",
            "[]\n",
            "started duplication\n",
            "pos_vals [0, 1]\n",
            "0.7563959955506118 57 129 40.5750834260290\n",
            "0.7563959955506118 57 129 40.5750834260290\n",
            "Adding 41 positive records\n",
            "names  ['age', 'sex'] [0, 1]\n",
            "class 0    2667\n",
            "1    2274\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "4\n",
            "The sets of need pos and neg are\n",
            "[[0, 0]]\n",
            "[]\n",
            "started duplication\n",
            "pos_vals [0, 0]\n",
            "0.7835497835497836 15 41 17.1255411255411\n",
            "0.7835497835497836 15 41 17.1255411255411\n",
            "Adding 17 positive records\n",
            "names  ['age', 'race'] [0, 0]\n",
            "class 0    2667\n",
            "1    2291\n",
            "Name: class, dtype: int64\n",
            "model accuracy\n",
            "best 0.4485469715113312\n",
            "fpr and fnr\n",
            "0.12549019607843137\n",
            "0.8086642599277978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set['predicted'] = test_predict"
      ],
      "metadata": {
        "id": "wid4ViElCw6i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1aff2d7-7a95-4ad9-db3a-b8f6b3c0598d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Lattice\n"
      ],
      "metadata": {
        "id": "QuQ3lc7aU9NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # run divexplorer to find unfair groups\n",
        "# class_map={'N': 0, 'P': 1}\n",
        "# from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "\n",
        "# #min_sup=0.1\n",
        "\n",
        "# min_sup = 0.05\n",
        "\n",
        "# fp_diver=FP_DivergenceExplorer(test_set,\"class\", \"predicted\", class_map=class_map)\n",
        "# FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "# from divexplorer.FP_Divergence import FP_Divergence\n",
        "# fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "# # fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "# INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "\n",
        "# K=10\n",
        "# pd.options.display.max_rows = 200\n",
        "# d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "# # summerization\n",
        "# eps=0.01\n",
        "\n",
        "# d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ].head(K)\n",
        "\n",
        "# d\n",
        "# d, d2, d3 = div_results()"
      ],
      "metadata": {
        "id": "uVcvdRuMQu26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6adbc7-a5c3-4fcc-8c80-bd256f69cb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d,d1,d2 = div_results(\"COMPAS\",\"Duplication-Lattice\",\"DT\")\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridl.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridl.best_score_)\n",
        "test_predict = gridl.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Lattice\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "svc.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = svc.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Duplication-Lattice\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTqA6ic3sHXO",
        "outputId": "c262f4d1-3755-451f-a30a-c00ebab044c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4582842586203094\n",
            "0.281571814849661\n",
            "0.09147507691463526\n",
            "accuracy is  0.5678011885467315\n",
            "['COMPAS', 'Duplication-Lattice', 'DT', 0.4582842586203094, 0.281571814849661, 0.09147507691463526, 0.5678011885467315]\n",
            "\n",
            "rf\n",
            "best 0.45036124424561286\n",
            "fpr and fnr\n",
            "0.19019607843137254\n",
            "0.7701564380264742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5279496979733478\n",
            "0.39781172576903745\n",
            "0.13551481655629663\n",
            "accuracy is  0.5494327390599676\n",
            "['COMPAS', 'Duplication-Lattice', 'RF', 0.5279496979733478, 0.39781172576903745, 0.13551481655629663, 0.5494327390599676]\n",
            "\n",
            "logistic\n",
            "best 0.4713332220761565\n",
            "fpr and fnr\n",
            "0.11274509803921569\n",
            "0.8002406738868832\n",
            "0.43759270252932214\n",
            "0.2949963369845978\n",
            "0.10107463047264303\n",
            "accuracy is  0.5786061588330632\n",
            "['COMPAS', 'Duplication-Lattice', 'L', 0.43759270252932214, 0.2949963369845978, 0.10107463047264303, 0.5786061588330632]\n",
            "\n",
            "svm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fpr and fnr\n",
            "0.12549019607843137\n",
            "0.8086642599277978\n",
            "0.4582842586203094\n",
            "0.281571814849661\n",
            "0.09147507691463526\n",
            "accuracy is  0.5678011885467315\n",
            "['COMPAS', 'Duplication-Lattice', 'SVM', 0.4582842586203094, 0.281571814849661, 0.09147507691463526, 0.5678011885467315]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fairness_score_computation(d, metrics):\n",
        "    sum_of_score = 0\n",
        "    for idx, row in d.iterrows():\n",
        "      sum_of_score += row['support'] * row[metrics]\n",
        "    return sum_of_score\n",
        "\n",
        "print(fairness_score_computation(d, 'd_fpr'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7whA1nLnvev0",
        "outputId": "6f63b6fa-2122-476b-e170-9447ace6f420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4582842586203094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Algorithm Leaf"
      ],
      "metadata": {
        "id": "cJ4Kag3MuFuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in [all_names_lst[0]]:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  # start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  # end = time.time()\n",
        "  # excute_time = end - start\n",
        "  # print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started duplication\")\n",
        "  new_train_data = naive_duplicate(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  # new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "  # new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "  # new_train_label = new_train_label[compas_y]\n",
        "  # new_train_label = new_train_label.astype('int')\n",
        "  # grid_new = DecisionTreeClassifier(criterion=\"entropy\",max_depth=6, random_state=17)\n",
        "  # grid_new.fit(new_train_x, new_train_label)\n",
        "  # test_predict = grid_new.predict(test_x)\n",
        "  # print(\"new trainset length\", len(new_train_x))\n",
        "  # print(\"fpr and fnr\")\n",
        "  # print(fpr_onegroup(list(test_label), test_predict))\n",
        "  # print(fnr_onegroup(list(test_label), test_predict))\n",
        "  print(\"class\", new_train_data['class'].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n",
        "grid_new = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = param, cv = 6)\n",
        "grid_new.fit(new_train_x, new_train_label)\n",
        "print(\"model accuracy\")\n",
        "print(\"best\", grid_new.best_score_)\n",
        "test_predict = grid_new.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc306e9-4cbb-4031-dded-c26ce16644ce",
        "id": "XWAzykiouMXt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "7\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1], [0, 2, 0], [1, 0, 0], [1, 1, 1], [1, 3, 0], [2, 2, 1]]\n",
            "[[1, 1, 0], [2, 1, 0], [2, 2, 0], [2, 3, 0]]\n",
            "started duplication\n",
            "pos_vals [0, 1, 1]\n",
            "0.6494382022471911 13 39 12.3280898876405\n",
            "0.6494382022471911 13 39 12.3280898876405\n",
            "Adding 12 positive records\n",
            "names  ['age', 'race', 'sex'] [0, 1, 1]\n",
            "pos_vals [0, 2, 0]\n",
            "0.7466487935656837 99 242 81.6890080428956\n",
            "0.7466487935656837 99 242 81.6890080428956\n",
            "Adding 82 positive records\n",
            "names  ['age', 'race', 'sex'] [0, 2, 0]\n",
            "pos_vals [1, 0, 0]\n",
            "0.949119373776908 39 70 27.4383561643836\n",
            "0.949119373776908 39 70 27.4383561643836\n",
            "Adding 27 positive records\n",
            "names  ['age', 'race', 'sex'] [1, 0, 0]\n",
            "pos_vals [1, 1, 1]\n",
            "0.9986577181208054 91 146 54.8040268456376\n",
            "0.9986577181208054 91 146 54.8040268456376\n",
            "Adding 55 positive records\n",
            "names  ['age', 'race', 'sex'] [1, 1, 1]\n",
            "pos_vals [1, 3, 0]\n",
            "0.9566929133858267 62 105 38.4527559055118\n",
            "0.9566929133858267 62 105 38.4527559055118\n",
            "Adding 38 positive records\n",
            "names  ['age', 'race', 'sex'] [1, 3, 0]\n",
            "pos_vals [2, 2, 1]\n",
            "0.7109826589595376 15 37 11.3063583815029\n",
            "0.7109826589595376 15 37 11.3063583815029\n",
            "Adding 11 positive records\n",
            "names  ['age', 'race', 'sex'] [2, 2, 1]\n",
            "neg_vals [1, 1, 0]\n",
            "0.8915906788247214 601 495 179.076136363637\n",
            "Adding 179 negative records\n",
            "names  ['age', 'race', 'sex'] [1, 1, 0]\n",
            "neg_vals [2, 1, 0]\n",
            "1.1191895113230035 297 160 105.370607028755\n",
            "Adding 105 negative records\n",
            "names  ['age', 'race', 'sex'] [2, 1, 0]\n",
            "neg_vals [2, 2, 0]\n",
            "0.8922518159806295 105 86 31.6797829036634\n",
            "Adding 32 negative records\n",
            "names  ['age', 'race', 'sex'] [2, 2, 0]\n",
            "neg_vals [2, 3, 0]\n",
            "1.1797235023041475 39 25 8.05859375000000\n",
            "Adding 8 negative records\n",
            "names  ['age', 'race', 'sex'] [2, 3, 0]\n",
            "class 0    2667\n",
            "1    2203\n",
            "Name: class, dtype: int64\n",
            "model accuracy\n",
            "best 0.4771615755447976\n",
            "fpr and fnr\n",
            "0.10098039215686275\n",
            "0.8158844765342961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Leaf"
      ],
      "metadata": {
        "id": "MyiaC-BPuT-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set['predicted'] = test_predict\n",
        "# d,d2,d3 = div_results()"
      ],
      "metadata": {
        "id": "tIpq68mRuWVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e8d45d1-8e3d-440f-d3d4-1de6b36b7ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d,d1,d2 = div_results(\"COMPAS\",\"Duplication-Leaf\",\"DT\")\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Leaf\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridl.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridl.best_score_)\n",
        "test_predict = gridl.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Leaf\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "svc.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = svc.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Duplication-Leaf\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVCnBjPxsJgg",
        "outputId": "bd4bfada-db4b-4fb7-d072-1661558611da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5047859655944719\n",
            "0.24051395772019024\n",
            "0.09887802846359563\n",
            "accuracy is  0.5780659103187467\n",
            "['COMPAS', 'Duplication-Leaf', 'DT', 0.5047859655944719, 0.24051395772019024, 0.09887802846359563, 0.5780659103187467]\n",
            "\n",
            "rf\n",
            "best 0.47551953942000286\n",
            "fpr and fnr\n",
            "0.16568627450980392\n",
            "0.7773766546329723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5388584428537804\n",
            "0.3483051325024953\n",
            "0.11255556810589926\n",
            "accuracy is  0.5596974608319827\n",
            "['COMPAS', 'Duplication-Leaf', 'RF', 0.5388584428537804, 0.3483051325024953, 0.11255556810589926, 0.5596974608319827]\n",
            "\n",
            "logistic\n",
            "best 0.5365340383357732\n",
            "fpr and fnr\n",
            "0.0803921568627451\n",
            "0.8279181708784596\n",
            "0.4816722778874921\n",
            "0.22479409120253085\n",
            "0.09414946758815373\n",
            "accuracy is  0.5840086439762291\n",
            "['COMPAS', 'Duplication-Leaf', 'L', 0.4816722778874921, 0.22479409120253085, 0.09414946758815373, 0.5840086439762291]\n",
            "\n",
            "svm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fpr and fnr\n",
            "0.10098039215686275\n",
            "0.8158844765342961\n",
            "0.5047859655944719\n",
            "0.24051395772019024\n",
            "0.09887802846359563\n",
            "accuracy is  0.5780659103187467\n",
            "['COMPAS', 'Duplication-Leaf', 'SVM', 0.5047859655944719, 0.24051395772019024, 0.09887802846359563, 0.5780659103187467]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Algorithm Top"
      ],
      "metadata": {
        "id": "7Ud6LiPvubLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "all_names_lst_top = find_top(all_names)\n",
        "for a in all_names_lst_top:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  # start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  # end = time.time()\n",
        "  # excute_time = end - start\n",
        "  # print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started duplication\")\n",
        "  new_train_data = naive_duplicate(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  # new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "  # new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "  # new_train_label = new_train_label[compas_y]\n",
        "  # new_train_label = new_train_label.astype('int')\n",
        "  # grid_new = DecisionTreeClassifier(criterion=\"entropy\",max_depth=6, random_state=17)\n",
        "  # grid_new.fit(new_train_x, new_train_label)\n",
        "  # test_predict = grid_new.predict(test_x)\n",
        "  # print(\"new trainset length\", len(new_train_x))\n",
        "  # print(\"fpr and fnr\")\n",
        "  # print(fpr_onegroup(list(test_label), test_predict))\n",
        "  # print(fnr_onegroup(list(test_label), test_predict))\n",
        "  print(\"class\", new_train_data['class'].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n",
        "grid_new = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = param, cv = 6)\n",
        "grid_new.fit(new_train_x, new_train_label)\n",
        "print(\"model accuracy\")\n",
        "print(\"best\", grid_new.best_score_)\n",
        "test_predict = grid_new.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a8d8219-407b-4b3e-f6c8-34d18ee24c5d",
        "id": "itgAs3JCuj6B"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "class 0    2343\n",
            "1    1978\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "2\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "class 0    2343\n",
            "1    1978\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "3\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "class 0    2343\n",
            "1    1978\n",
            "Name: class, dtype: int64\n",
            "model accuracy\n",
            "best 0.6051783145836545\n",
            "fpr and fnr\n",
            "0.3509803921568627\n",
            "0.4608904933814681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Top"
      ],
      "metadata": {
        "id": "WtQcykniuqUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set['predicted'] = test_predict\n",
        "# d,d2,d3 = div_results()"
      ],
      "metadata": {
        "id": "rXyGMq6Fuunb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3b292e-db94-4bf8-87fa-ba372ca18c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d,d1,d2 = div_results(\"COMPAS\",\"Duplication-Top\",\"DT\")\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Top\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridl.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridl.best_score_)\n",
        "test_predict = gridl.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Duplication-Top\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "svc.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = svc.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Duplication-Top\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PXEjrEDsOEl",
        "outputId": "cbe0b0ea-bb17-47d4-9974-b3dc84c5dba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0452612894198687\n",
            "0.5367298655917477\n",
            "0.06840316723975033\n",
            "accuracy is  0.5996758508914101\n",
            "['COMPAS', 'Duplication-Top', 'DT', 1.0452612894198687, 0.5367298655917477, 0.06840316723975033, 0.5996758508914101]\n",
            "\n",
            "rf\n",
            "best 0.604946833102173\n",
            "fpr and fnr\n",
            "0.3509803921568627\n",
            "0.4608904933814681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0452612894198687\n",
            "0.5367298655917477\n",
            "0.06840316723975033\n",
            "accuracy is  0.5996758508914101\n",
            "['COMPAS', 'Duplication-Top', 'RF', 1.0452612894198687, 0.5367298655917477, 0.06840316723975033, 0.5996758508914101]\n",
            "\n",
            "logistic\n",
            "best 0.5975435994246674\n",
            "fpr and fnr\n",
            "0.38333333333333336\n",
            "0.4332129963898917\n",
            "1.0149613181916723\n",
            "0.5583832084813722\n",
            "0.0746544058565157\n",
            "accuracy is  0.5942733657482442\n",
            "['COMPAS', 'Duplication-Top', 'L', 1.0149613181916723, 0.5583832084813722, 0.0746544058565157, 0.5942733657482442]\n",
            "\n",
            "svm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fpr and fnr\n",
            "0.3509803921568627\n",
            "0.4608904933814681\n",
            "1.0452612894198687\n",
            "0.5367298655917477\n",
            "0.06840316723975033\n",
            "accuracy is  0.5996758508914101\n",
            "['COMPAS', 'Duplication-Top', 'SVM', 1.0452612894198687, 0.5367298655917477, 0.06840316723975033, 0.5996758508914101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Down-sampling"
      ],
      "metadata": {
        "id": "2SfzogxQ-Q5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def round_int(x):\n",
        "    if x in [float(\"-inf\"),float(\"inf\")]: return 0\n",
        "    return int(round(x))\n",
        "\n",
        "\n",
        "def make_remove(d, group_lst, diff, names, label_y, need_positive_or_negative):\n",
        "    #print(\"make samples\")\n",
        "    temp = copy.deepcopy(d)\n",
        "    for i in range(len(group_lst)):\n",
        "        att_name = names[i]\n",
        "        temp = temp[(temp[att_name] == group_lst[i])]\n",
        "    temp = temp[(temp[label_y] == need_positive_or_negative)]\n",
        "    # randomly generated diff samples\n",
        "        #generated = temp\n",
        "        # the number needed is more than the not needed numbers.\n",
        "    # print(len(temp))\n",
        "    # print(diff)\n",
        "    if(diff>len(temp)):\n",
        "        diff = len(temp)\n",
        "    generated = temp.sample(n = diff, replace = False, axis = 0)\n",
        "    #print(generated.index)\n",
        "    return generated.index\n",
        "\n",
        "\n",
        "def naive_downsampling(d, temp2, names, need_pos, need_neg, label_y):\n",
        "    # add more records for all groups\n",
        "    # The smote algorithm to boost the coverage\n",
        "    for r in need_pos:\n",
        "        print(\"removing more negative\")\n",
        "    # add more positive records\n",
        "        # determine how many points to add\n",
        "        print(r)\n",
        "        diff = compute_diff_remove(r, temp2, names, label_y, need_positive_or_negative = 1)\n",
        "        diff = round_int(diff)\n",
        "        # add more records\n",
        "        print(\"Removed \" + str(diff) +\" negative records\")\n",
        "        samples_to_remove = make_remove(d, r, diff, names, label_y, need_positive_or_negative = 0)\n",
        "        d.drop(index  = samples_to_remove, inplace = True)\n",
        "        # print(len(d))\n",
        "    for k in need_neg:\n",
        "        print(k)\n",
        "        diff = compute_diff_remove(k, temp2, names, label_y, need_positive_or_negative = 0)\n",
        "        diff = round_int(diff)\n",
        "        print(\"Removed \" + str(diff) +\" positive records\")\n",
        "        samples_to_remove = make_remove(d, k, diff, names, label_y, need_positive_or_negative = 1)\n",
        "        d.drop(index  = samples_to_remove, inplace = True)\n",
        "    return d"
      ],
      "metadata": {
        "id": "h9m0e5GbVL-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068726c0-8b41-4f47-c800-3e9336a68fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Algorithm Lattice"
      ],
      "metadata": {
        "id": "DcUYj8wJwrHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  # print(temp_g)\n",
        "  # print(temp2, names)\n",
        "  # print(temp)\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  # print(\"started duplication\")\n",
        "  new_train_data = naive_downsampling(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  print(new_train_data['class'].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n",
        "grid_new = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = param, cv = 6)\n",
        "grid_new.fit(new_train_x, new_train_label)\n",
        "print(\"model accuracy\")\n",
        "print(\"best\", grid_new.best_score_)\n",
        "test_predict = grid_new.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "# new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "# new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "# new_train_label = new_train_label[compas_y]\n",
        "# new_train_label = new_train_label.astype('int')\n",
        "# grid_new = DecisionTreeClassifier(criterion=\"entropy\",max_depth=6, random_state=17)\n",
        "# grid_new.fit(new_train_x, new_train_label)\n",
        "# test_predict = grid_new.predict(test_x)\n",
        "# print(\"new trainset length\", len(new_train_x))\n",
        "# print(\"fpr\", fpr_onegroup(list(test_label), test_predict))\n",
        "# print(\"fnr\", fnr_onegroup(list(test_label), test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTfYbyt4pcRq",
        "outputId": "01e99502-367a-43b3-d1e8-40610305a470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "7\n",
            "The time to compute unfair group is 0.06691884994506836\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1], [0, 2, 0], [1, 0, 0], [1, 1, 1], [1, 3, 0], [2, 2, 1]]\n",
            "[[1, 1, 0], [2, 1, 0], [2, 2, 0], [2, 3, 0]]\n",
            "removing more negative\n",
            "[0, 1, 1]\n",
            "0.6494382022471911 13 39 18.9826989619377\n",
            "Removed 19 negative records\n",
            "removing more negative\n",
            "[0, 2, 0]\n",
            "0.7466487935656837 99 242 109.407540394973\n",
            "Removed 109 negative records\n",
            "removing more negative\n",
            "[1, 0, 0]\n",
            "0.949119373776908 39 70 28.9092783505155\n",
            "Removed 29 negative records\n",
            "removing more negative\n",
            "[1, 1, 1]\n",
            "0.9986577181208054 91 146 54.8776881720430\n",
            "Removed 55 negative records\n",
            "removing more negative\n",
            "[1, 3, 0]\n",
            "0.9566929133858267 62 105 40.1934156378601\n",
            "Removed 40 negative records\n",
            "removing more negative\n",
            "[2, 2, 1]\n",
            "0.7109826589595376 15 37 15.9024390243902\n",
            "Removed 16 negative records\n",
            "[1, 1, 0]\n",
            "0.8915906788247214 601 495 159.662613981763\n",
            "Removed 160 positive records\n",
            "[2, 1, 0]\n",
            "1.1191895113230035 297 160 117.929678188319\n",
            "Removed 118 positive records\n",
            "[2, 2, 0]\n",
            "0.8922518159806295 105 86 28.2663438256659\n",
            "Removed 28 positive records\n",
            "[2, 3, 0]\n",
            "1.1797235023041475 39 25 9.50691244239633\n",
            "Removed 10 positive records\n",
            "0    2075\n",
            "1    1662\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "6\n",
            "The time to compute unfair group is 0.02099156379699707\n",
            "The sets of need pos and neg are\n",
            "[[0, 1]]\n",
            "[]\n",
            "removing more negative\n",
            "[0, 1]\n",
            "0.684931506849315 8 34 22.3200000000000\n",
            "Removed 22 negative records\n",
            "0    2053\n",
            "1    1662\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "5\n",
            "The time to compute unfair group is 0.015951156616210938\n",
            "The sets of need pos and neg are\n",
            "[[0, 1]]\n",
            "[]\n",
            "removing more negative\n",
            "[0, 1]\n",
            "0.7193732193732194 42 105 46.6158415841584\n",
            "Removed 47 negative records\n",
            "0    2006\n",
            "1    1662\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "4\n",
            "The time to compute unfair group is 0.031915903091430664\n",
            "The sets of need pos and neg are\n",
            "[[0, 0], [0, 3]]\n",
            "[]\n",
            "removing more negative\n",
            "[0, 0]\n",
            "0.7648305084745762 15 36 16.3878116343490\n",
            "Removed 16 negative records\n",
            "removing more negative\n",
            "[0, 3]\n",
            "0.7683168316831683 23 55 25.0644329896907\n",
            "Removed 25 negative records\n",
            "0    1965\n",
            "1    1662\n",
            "Name: class, dtype: int64\n",
            "model accuracy\n",
            "best 0.5409364566799847\n",
            "fpr and fnr\n",
            "0.12549019607843137\n",
            "0.8074608904933814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Lattice"
      ],
      "metadata": {
        "id": "xhS42vuGsI2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set['predicted'] = test_predict\n",
        "# d,d2,d3 = div_results()\n",
        "\n",
        "# # run divexplorer to find unfair groups\n",
        "# class_map={'N': 0, 'P': 1}\n",
        "# from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "\n",
        "# #min_sup=0.1\n",
        "\n",
        "# min_sup = 0.05\n",
        "\n",
        "# fp_diver=FP_DivergenceExplorer(test_set,\"class\", \"predicted\", class_map=class_map)\n",
        "# FP_fm=fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[\"d_fpr\", \"d_fnr\", \"d_accuracy\"])\n",
        "# from divexplorer.FP_Divergence import FP_Divergence\n",
        "# fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fpr\")\n",
        "# # fp_divergence_fpr=FP_Divergence(FP_fm, \"d_fnr\")\n",
        "# INFO_VIZ=[\"support\", \"itemsets\",  fp_divergence_fpr.metric, fp_divergence_fpr.t_value_col]\n",
        "\n",
        "# K=10\n",
        "# pd.options.display.max_rows = 200\n",
        "# d = fp_divergence_fpr.getDivergence(th_redundancy=0)[INFO_VIZ].head(K)\n",
        "# # summerization\n",
        "# eps=0.01\n",
        "\n",
        "# d = fp_divergence_fpr.getDivergence(th_redundancy=eps)[INFO_VIZ].head(K)\n",
        "\n",
        "# d\n"
      ],
      "metadata": {
        "id": "El4mFbYwr-4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8d7b1c-93e0-400c-bbb2-5701a3a121dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d,d1,d2 = div_results(\"COMPAS\",\"Downsampling-Lattice\",\"DT\")\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Downsampling-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridl.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridl.best_score_)\n",
        "test_predict = gridl.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Downsampling-Lattice\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "svc.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = svc.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Downsampling-Lattice\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbzCpafMsVko",
        "outputId": "bdc18030-7f0b-47d9-b7fe-f21bc0e06a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4582842586203094\n",
            "0.27949120059219384\n",
            "0.09082858828189001\n",
            "accuracy is  0.5683414370610481\n",
            "['COMPAS', 'Downsampling-Lattice', 'DT', 0.4582842586203094, 0.27949120059219384, 0.09082858828189001, 0.5683414370610481]\n",
            "\n",
            "rf\n",
            "best 0.5401090982066298\n",
            "fpr and fnr\n",
            "0.19019607843137254\n",
            "0.7701564380264742\n",
            "0.5279496979733478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.39781172576903745\n",
            "0.13551481655629663\n",
            "accuracy is  0.5494327390599676\n",
            "['COMPAS', 'Downsampling-Lattice', 'RF', 0.5279496979733478, 0.39781172576903745, 0.13551481655629663, 0.5494327390599676]\n",
            "\n",
            "logistic\n",
            "best 0.5387348804115812\n",
            "fpr and fnr\n",
            "0.10980392156862745\n",
            "0.8014440433212996\n",
            "0.44113356816151356\n",
            "0.29451281751711306\n",
            "0.10137233629900864\n",
            "accuracy is  0.5796866558616964\n",
            "['COMPAS', 'Downsampling-Lattice', 'L', 0.44113356816151356, 0.29451281751711306, 0.10137233629900864, 0.5796866558616964]\n",
            "\n",
            "svm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fpr and fnr\n",
            "0.12549019607843137\n",
            "0.8086642599277978\n",
            "0.4582842586203094\n",
            "0.281571814849661\n",
            "0.09147507691463526\n",
            "accuracy is  0.5678011885467315\n",
            "['COMPAS', 'Downsampling-Lattice', 'SVM', 0.4582842586203094, 0.281571814849661, 0.09147507691463526, 0.5678011885467315]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Algorithm Leaf"
      ],
      "metadata": {
        "id": "YqfnIjDrwk9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in [all_names_lst[0]]:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  # print(temp_g)\n",
        "  # print(temp2, names)\n",
        "  # print(temp)\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  # print(\"started duplication\")\n",
        "  new_train_data = naive_downsampling(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  print(new_train_data['class'].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n",
        "grid_new = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = param, cv = 6)\n",
        "grid_new.fit(new_train_x, new_train_label)\n",
        "print(\"model accuracy\")\n",
        "print(\"best\", grid_new.best_score_)\n",
        "test_predict = grid_new.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "# new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "# new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "# new_train_label = new_train_label[compas_y]\n",
        "# new_train_label = new_train_label.astype('int')\n",
        "# grid_new = DecisionTreeClassifier(criterion=\"entropy\",max_depth=6, random_state=17)\n",
        "# grid_new.fit(new_train_x, new_train_label)\n",
        "# test_predict = grid_new.predict(test_x)\n",
        "# print(\"new trainset length\", len(new_train_x))\n",
        "# print(\"fpr\", fpr_onegroup(list(test_label), test_predict))\n",
        "# print(\"fnr\", fnr_onegroup(list(test_label), test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bcbe144-2842-4fef-bd31-c739d6301d0d",
        "id": "IvmlKdUqwl_1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "7\n",
            "The time to compute unfair group is 0.08417701721191406\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1], [0, 2, 0], [1, 0, 0], [1, 1, 1], [1, 3, 0], [2, 2, 1]]\n",
            "[[1, 1, 0], [2, 1, 0], [2, 2, 0], [2, 3, 0]]\n",
            "removing more negative\n",
            "[0, 1, 1]\n",
            "0.6494382022471911 13 39 18.9826989619377\n",
            "Removed 19 negative records\n",
            "removing more negative\n",
            "[0, 2, 0]\n",
            "0.7466487935656837 99 242 109.407540394973\n",
            "Removed 109 negative records\n",
            "removing more negative\n",
            "[1, 0, 0]\n",
            "0.949119373776908 39 70 28.9092783505155\n",
            "Removed 29 negative records\n",
            "removing more negative\n",
            "[1, 1, 1]\n",
            "0.9986577181208054 91 146 54.8776881720430\n",
            "Removed 55 negative records\n",
            "removing more negative\n",
            "[1, 3, 0]\n",
            "0.9566929133858267 62 105 40.1934156378601\n",
            "Removed 40 negative records\n",
            "removing more negative\n",
            "[2, 2, 1]\n",
            "0.7109826589595376 15 37 15.9024390243902\n",
            "Removed 16 negative records\n",
            "[1, 1, 0]\n",
            "0.8915906788247214 601 495 159.662613981763\n",
            "Removed 160 positive records\n",
            "[2, 1, 0]\n",
            "1.1191895113230035 297 160 117.929678188319\n",
            "Removed 118 positive records\n",
            "[2, 2, 0]\n",
            "0.8922518159806295 105 86 28.2663438256659\n",
            "Removed 28 positive records\n",
            "[2, 3, 0]\n",
            "1.1797235023041475 39 25 9.50691244239633\n",
            "Removed 10 positive records\n",
            "0    2075\n",
            "1    1662\n",
            "Name: class, dtype: int64\n",
            "model accuracy\n",
            "best 0.5450870438135152\n",
            "fpr and fnr\n",
            "0.10098039215686275\n",
            "0.8158844765342961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Leaf"
      ],
      "metadata": {
        "id": "5-O26rF9xYc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set['predicted'] = test_predict\n",
        "# d,d2,d3 = div_results()"
      ],
      "metadata": {
        "id": "fsPaBOa7xYMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1421698-64d3-434f-e4fa-cf062ecef91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d,d1,d2 = div_results(\"COMPAS\",\"Downsampling-Leaf\",\"DT\")\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Downsampling-Leaf\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridl.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridl.best_score_)\n",
        "test_predict = gridl.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Downsampling-Leaf\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "svc.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = svc.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Downsampling-Leaf\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HWsJpa-sgzZ",
        "outputId": "d8675c39-b292-41c2-b007-aa4710b5826e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5047859655944719\n",
            "0.24051395772019024\n",
            "0.09887802846359563\n",
            "accuracy is  0.5780659103187467\n",
            "['COMPAS', 'Downsampling-Leaf', 'DT', 0.5047859655944719, 0.24051395772019024, 0.09887802846359563, 0.5780659103187467]\n",
            "\n",
            "rf\n",
            "best 0.5450870438135151\n",
            "fpr and fnr\n",
            "0.10098039215686275\n",
            "0.8158844765342961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5047859655944719\n",
            "0.24051395772019024\n",
            "0.09887802846359563\n",
            "accuracy is  0.5780659103187467\n",
            "['COMPAS', 'Downsampling-Leaf', 'RF', 0.5047859655944719, 0.24051395772019024, 0.09887802846359563, 0.5780659103187467]\n",
            "\n",
            "logistic\n",
            "best 0.5592657490034563\n",
            "fpr and fnr\n",
            "0.0803921568627451\n",
            "0.8279181708784596\n",
            "0.4816722778874921\n",
            "0.22479409120253085\n",
            "0.09414946758815373\n",
            "accuracy is  0.5840086439762291\n",
            "['COMPAS', 'Downsampling-Leaf', 'L', 0.4816722778874921, 0.22479409120253085, 0.09414946758815373, 0.5840086439762291]\n",
            "\n",
            "svm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fpr and fnr\n",
            "0.10098039215686275\n",
            "0.8158844765342961\n",
            "0.5047859655944719\n",
            "0.24051395772019024\n",
            "0.09887802846359563\n",
            "accuracy is  0.5780659103187467\n",
            "['COMPAS', 'Downsampling-Leaf', 'SVM', 0.5047859655944719, 0.24051395772019024, 0.09887802846359563, 0.5780659103187467]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Algorithm Top"
      ],
      "metadata": {
        "id": "lEjc2orXxeJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "all_names_lst_top = find_top(all_names)\n",
        "for a in all_names_lst_top:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  # print(temp_g)\n",
        "  # print(temp2, names)\n",
        "  # print(temp)\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  # print(\"started duplication\")\n",
        "  new_train_data = naive_downsampling(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  print(new_train_data['class'].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n",
        "grid_new = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = param, cv = 6)\n",
        "grid_new.fit(new_train_x, new_train_label)\n",
        "print(\"model accuracy\")\n",
        "print(\"best\", grid_new.best_score_)\n",
        "test_predict = grid_new.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "# new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "# new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "# new_train_label = new_train_label[compas_y]\n",
        "# new_train_label = new_train_label.astype('int')\n",
        "# grid_new = DecisionTreeClassifier(criterion=\"entropy\",max_depth=6, random_state=17)\n",
        "# grid_new.fit(new_train_x, new_train_label)\n",
        "# test_predict = grid_new.predict(test_x)\n",
        "# print(\"new trainset length\", len(new_train_x))\n",
        "# print(\"fpr\", fpr_onegroup(list(test_label), test_predict))\n",
        "# print(\"fnr\", fnr_onegroup(list(test_label), test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d824940-0960-4969-e661-e80a97fca2ec",
        "id": "g1ttSPisxj-R"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "1\n",
            "The time to compute unfair group is 0.0064160823822021484\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2343\n",
            "1    1978\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "2\n",
            "The time to compute unfair group is 0.006841897964477539\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2343\n",
            "1    1978\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "3\n",
            "The time to compute unfair group is 0.007475614547729492\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2343\n",
            "1    1978\n",
            "Name: class, dtype: int64\n",
            "model accuracy\n",
            "best 0.6051783145836545\n",
            "fpr and fnr\n",
            "0.3509803921568627\n",
            "0.4608904933814681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Top"
      ],
      "metadata": {
        "id": "YQOAJrGyxrsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set['predicted'] = test_predict\n",
        "# d,d2,d3 = div_results()"
      ],
      "metadata": {
        "id": "6mK6lI8exuxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "306bf13f-dfa8-4ddc-fc51-f653cb677206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d,d1,d2 = div_results(\"COMPAS\",\"Downsampling-Top\",\"DT\")\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Downsampling-Top\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridl.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridl.best_score_)\n",
        "test_predict = gridl.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Downsampling-Top\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "svc.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = svc.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Downsampling-Top\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyrmV-7cshtA",
        "outputId": "92fa07ca-3858-4033-99b9-c36c0e1a8204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0452612894198687\n",
            "0.5367298655917477\n",
            "0.06840316723975033\n",
            "accuracy is  0.5996758508914101\n",
            "['COMPAS', 'Downsampling-Top', 'DT', 1.0452612894198687, 0.5367298655917477, 0.06840316723975033, 0.5996758508914101]\n",
            "\n",
            "rf\n",
            "best 0.604946833102173\n",
            "fpr and fnr\n",
            "0.3509803921568627\n",
            "0.4608904933814681\n",
            "1.0452612894198687\n",
            "0.5367298655917477\n",
            "0.06840316723975033\n",
            "accuracy is "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.5996758508914101\n",
            "['COMPAS', 'Downsampling-Top', 'RF', 1.0452612894198687, 0.5367298655917477, 0.06840316723975033, 0.5996758508914101]\n",
            "\n",
            "logistic\n",
            "best 0.5975435994246674\n",
            "fpr and fnr\n",
            "0.38333333333333336\n",
            "0.4332129963898917\n",
            "1.0149613181916723\n",
            "0.5583832084813722\n",
            "0.0746544058565157\n",
            "accuracy is "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.5942733657482442\n",
            "['COMPAS', 'Downsampling-Top', 'L', 1.0149613181916723, 0.5583832084813722, 0.0746544058565157, 0.5942733657482442]\n",
            "\n",
            "svm\n",
            "fpr and fnr\n",
            "0.3509803921568627\n",
            "0.4608904933814681\n",
            "1.0452612894198687\n",
            "0.5367298655917477\n",
            "0.06840316723975033\n",
            "accuracy is  0.5996758508914101\n",
            "['COMPAS', 'Downsampling-Top', 'SVM', 1.0452612894198687, 0.5367298655917477, 0.06840316723975033, 0.5996758508914101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Massaging"
      ],
      "metadata": {
        "id": "YWbCzMkrnT-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "def round_int(x):\n",
        "    if x in [float(\"-inf\"),float(\"inf\")]: return 0\n",
        "    return int(round(x))\n",
        "\n",
        "def get_depromotion(d, diff, group_lst, names, label_y, flag_depro):\n",
        "    # double check\n",
        "    print(\"start depromotion\")\n",
        "    # print(len(d))\n",
        "    print(names)\n",
        "    # input_test = d.drop(columns = [label_y])\n",
        "    # COMPAS COLUMNS = ]]\n",
        "    # input_test = pd.DataFrame(train_set, columns = names)\n",
        "    input_test = pd.DataFrame(d, columns = columns_compas)\n",
        "    # should it be d instead?\n",
        "    # print(group_lst, names)\n",
        "    clf = MultinomialNB()\n",
        "    # temp_train_label = pd.DataFrame(train_set, columns = [label_y])\n",
        "    temp_train_label = pd.DataFrame(d, columns = [label_y])\n",
        "    temp_train_label = temp_train_label[label_y]\n",
        "    temp_train_label = temp_train_label.astype('int')\n",
        "    clf = clf.fit(input_test, temp_train_label)\n",
        "    prob  = clf.predict_proba(input_test)[:,0]\n",
        "    select = copy.deepcopy(d)\n",
        "    select['prob'] = prob # the higher the probablity is, the more likely for it to be 0\n",
        "    # filter out those belongs to this group\n",
        "    for i in range(len(group_lst)):\n",
        "        att_name = names[i]\n",
        "        select = select[(select[att_name] == group_lst[i])]\n",
        "    select = select[(select[label_y] == flag_depro)]\n",
        "    # rank them according to the probability\n",
        "    # filp the records and remove the records from d\n",
        "    if (flag_depro == 0):\n",
        "        select.sort_values(by=\"prob\", ascending=True, inplace=True)\n",
        "        select[label_y] = 1\n",
        "    else:\n",
        "        select.sort_values(by=\"prob\", ascending=False, inplace=True)\n",
        "        select[label_y] = 0\n",
        "    head = select.head(diff)\n",
        "    index_list = []\n",
        "    index_list = list(head.index)\n",
        "    d.drop(index_list,inplace = True)\n",
        "    head.drop(columns = ['prob'],inplace = True)\n",
        "    #print(head.head())\n",
        "    #print(d.head())\n",
        "    return head\n",
        "\n",
        "\n",
        "\n",
        "def naive_massaging(d, temp2, names, need_pos, need_neg,label_y):\n",
        "    # add more records for all groups\n",
        "    # The smote algorithm to boost the coverage\n",
        "    for r in need_pos:\n",
        "        print(\"adding more positive\")\n",
        "    # add more positive records\n",
        "        # determine how many points to add\n",
        "        print(r)\n",
        "        diff = compute_diff_add_and_remove(r, temp2, 1, label_y, names)\n",
        "        diff =  round_int(diff)\n",
        "        # add more records\n",
        "        #0 for promotion\n",
        "        samples_to_add = get_depromotion(d, diff, r, names, label_y, flag_depro = 0)\n",
        "        print(\"Changed \" + str(len(samples_to_add)) +\" records\")\n",
        "        d = pd.concat([d, samples_to_add])\n",
        "        print(len(d))\n",
        "    for k in need_neg:\n",
        "        print(k)\n",
        "        print(\"adding more negative\")\n",
        "        diff = compute_diff_add_and_remove(k, temp2, 0, label_y, names)\n",
        "        diff =  round_int(diff)\n",
        "        #1 for demotion\n",
        "        samples_to_add = get_depromotion(d, diff, k, names, label_y, flag_depro = 1)\n",
        "        print(\"Changed \" + str(len(samples_to_add)) +\" records\")\n",
        "        d = pd.concat([d, samples_to_add])\n",
        "        print(len(d))\n",
        "    return d"
      ],
      "metadata": {
        "id": "tINoeYnSnWn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be6f009-3850-40f0-e7d7-971823fdae84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Algorithm Lattice"
      ],
      "metadata": {
        "id": "B6JgxVuTx8cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  # print(temp_g)\n",
        "  # print(temp2, names)\n",
        "  # print(temp)\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  # print(\"started duplication\")\n",
        "  new_train_data = naive_massaging(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  # print(new_train_data)\n",
        "  # new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "  # new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "  # new_train_label = new_train_label[compas_y]\n",
        "  # new_train_label = new_train_label.astype('int')\n",
        "  # grid_new = DecisionTreeClassifier(criterion=\"entropy\",max_depth=6, random_state=17)\n",
        "  # grid_new.fit(new_train_x, new_train_label)\n",
        "  # test_predict = grid_new.predict(test_x)\n",
        "  # print(\"new trainset length\", len(new_train_x))\n",
        "  # print(\"fpr\", fpr_onegroup(list(test_label), test_predict))\n",
        "  # print(\"fnr\", fnr_onegroup(list(test_label), test_predict))\n",
        "  print(new_train_data['class'].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n",
        "grid_new = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = param, cv = 6)\n",
        "grid_new.fit(new_train_x, new_train_label)\n",
        "print(\"model accuracy\")\n",
        "print(\"best\", grid_new.best_score_)\n",
        "test_predict = grid_new.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CvRKxY6ne5o",
        "outputId": "ab09ed19-26cb-40a7-9c16-addcdcbc1cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "7\n",
            "The time to compute unfair group is 0.065093994140625\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1], [0, 2, 0], [1, 0, 0], [1, 1, 1], [1, 3, 0], [2, 2, 1]]\n",
            "[[1, 1, 0], [2, 1, 0], [2, 2, 0], [2, 3, 0]]\n",
            "adding more positive\n",
            "[0, 1, 1]\n",
            "0.6494382022471911 13 39 7.47411444141689\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 7 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 2, 0]\n",
            "0.7466487935656837 99 242 46.7689946277821\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 47 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 0]\n",
            "0.949119373776908 39 70 14.0773092369478\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 14 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 1]\n",
            "0.9986577181208054 91 146 27.4204163868368\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 27 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 3, 0]\n",
            "0.9566929133858267 62 105 19.6519114688129\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 20 records\n",
            "4321\n",
            "adding more positive\n",
            "[2, 2, 1]\n",
            "0.7109826589595376 15 37 6.60810810810811\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 7 records\n",
            "4321\n",
            "[1, 1, 0]\n",
            "adding more negative\n",
            "0.8915906788247214 601 495 84.4065345474024\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 84 records\n",
            "4321\n",
            "[2, 1, 0]\n",
            "adding more negative\n",
            "1.1191895113230035 297 160 55.6484814398204\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 56 records\n",
            "4321\n",
            "[2, 2, 0]\n",
            "adding more negative\n",
            "0.8922518159806295 105 86 14.9379398592450\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 15 records\n",
            "4321\n",
            "[2, 3, 0]\n",
            "adding more negative\n",
            "1.1797235023041475 39 25 4.36152219873150\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 4 records\n",
            "4321\n",
            "0    2380\n",
            "1    1941\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "6\n",
            "The time to compute unfair group is 0.0392913818359375\n",
            "The sets of need pos and neg are\n",
            "[[0, 1], [3, 1]]\n",
            "[]\n",
            "adding more positive\n",
            "[0, 1]\n",
            "0.7043478260869566 8 34 9.35714285714286\n",
            "start depromotion\n",
            "['race', 'sex']\n",
            "Changed 9 records\n",
            "4321\n",
            "adding more positive\n",
            "[3, 1]\n",
            "0.7115384615384616 16 40 7.28089887640449\n",
            "start depromotion\n",
            "['race', 'sex']\n",
            "Changed 7 records\n",
            "4321\n",
            "0    2364\n",
            "1    1957\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "5\n",
            "The time to compute unfair group is 0.03004169464111328\n",
            "The sets of need pos and neg are\n",
            "[[0, 1]]\n",
            "[]\n",
            "adding more positive\n",
            "[0, 1]\n",
            "0.7506234413965087 49 122 24.3205128205128\n",
            "start depromotion\n",
            "['age', 'sex']\n",
            "Changed 24 records\n",
            "4321\n",
            "0    2340\n",
            "1    1981\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "4\n",
            "The time to compute unfair group is 0.07058858871459961\n",
            "The sets of need pos and neg are\n",
            "[[0, 3]]\n",
            "[[2, 0], [2, 3]]\n",
            "adding more positive\n",
            "[0, 3]\n",
            "0.8035426731078905 23 58 13.0883928571429\n",
            "start depromotion\n",
            "['age', 'race']\n",
            "Changed 13 records\n",
            "4321\n",
            "[2, 0]\n",
            "adding more negative\n",
            "0.966789667896679 32 20 6.43902439024390\n",
            "start depromotion\n",
            "['age', 'race']\n",
            "Changed 6 records\n",
            "4321\n",
            "[2, 3]\n",
            "adding more negative\n",
            "0.918918918918919 45 30 9.08450704225352\n",
            "start depromotion\n",
            "['age', 'race']\n",
            "Changed 9 records\n",
            "4321\n",
            "0    2342\n",
            "1    1979\n",
            "Name: class, dtype: int64\n",
            "model accuracy\n",
            "best 0.477889826372836\n",
            "fpr and fnr\n",
            "0.11764705882352941\n",
            "0.8110709987966306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Lattice"
      ],
      "metadata": {
        "id": "T6hqSHlurjGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set['predicted'] = test_predict\n",
        "# d,d2,d3 = div_results()\n"
      ],
      "metadata": {
        "id": "pFlN6k7mqLRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c7c0094-e419-4a12-ca1f-68b050c94a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d,d1,d2 = div_results(\"COMPAS\",\"Massaging-Lattice\",\"DT\")\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massaging-Lattice\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridl.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridl.best_score_)\n",
        "test_predict = gridl.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massaging-Lattice\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "svc.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = svc.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Massaging-Lattice\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvXIDnsDsiz4",
        "outputId": "409bf99e-25f9-44e1-96c8-ebaad62aac56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4801070649130617\n",
            "0.26414695126590765\n",
            "0.09535313310573434\n",
            "accuracy is  0.571042679632631\n",
            "['COMPAS', 'Massaging-Lattice', 'DT', 0.4801070649130617, 0.26414695126590765, 0.09535313310573434, 0.571042679632631]\n",
            "\n",
            "rf\n",
            "best 0.47534513535727124\n",
            "fpr and fnr\n",
            "0.11764705882352941\n",
            "0.8110709987966306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4801070649130617\n",
            "0.26414695126590765\n",
            "0.09535313310573434\n",
            "accuracy is  0.571042679632631\n",
            "['COMPAS', 'Massaging-Lattice', 'RF', 0.4801070649130617, 0.26414695126590765, 0.09535313310573434, 0.571042679632631]\n",
            "\n",
            "logistic\n",
            "best 0.5220966892690193\n",
            "fpr and fnr\n",
            "0.10980392156862745\n",
            "0.8014440433212996\n",
            "0.44113356816151356\n",
            "0.29451281751711306\n",
            "0.10137233629900864\n",
            "accuracy is  0.5796866558616964\n",
            "['COMPAS', 'Massaging-Lattice', 'L', 0.44113356816151356, 0.29451281751711306, 0.10137233629900864, 0.5796866558616964]\n",
            "\n",
            "svm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fpr and fnr\n",
            "0.11764705882352941\n",
            "0.8110709987966306\n",
            "0.4801070649130617\n",
            "0.26414695126590765\n",
            "0.09535313310573434\n",
            "accuracy is  0.571042679632631\n",
            "['COMPAS', 'Massaging-Lattice', 'SVM', 0.4801070649130617, 0.26414695126590765, 0.09535313310573434, 0.571042679632631]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Algorithm Leaf"
      ],
      "metadata": {
        "id": "zfBfO1hhytVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in [all_names_lst[0]]:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  # print(temp_g)\n",
        "  # print(temp2, names)\n",
        "  # print(temp)\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  # print(\"started duplication\")\n",
        "  new_train_data = naive_massaging(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  # print(new_train_data)\n",
        "  # new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "  # new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "  # new_train_label = new_train_label[compas_y]\n",
        "  # new_train_label = new_train_label.astype('int')\n",
        "  # grid_new = DecisionTreeClassifier(criterion=\"entropy\",max_depth=6, random_state=17)\n",
        "  # grid_new.fit(new_train_x, new_train_label)\n",
        "  # test_predict = grid_new.predict(test_x)\n",
        "  # print(\"new trainset length\", len(new_train_x))\n",
        "  # print(\"fpr\", fpr_onegroup(list(test_label), test_predict))\n",
        "  # print(\"fnr\", fnr_onegroup(list(test_label), test_predict))\n",
        "  print(new_train_data['class'].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n",
        "grid_new = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = param, cv = 6)\n",
        "grid_new.fit(new_train_x, new_train_label)\n",
        "print(\"model accuracy\")\n",
        "print(\"best\", grid_new.best_score_)\n",
        "test_predict = grid_new.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a7c3e31-dd01-465b-d11b-60c3017f9c78",
        "id": "R6oMxp2hzVXD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7\n",
            "The time to compute unfair group is 0.06770515441894531\n",
            "The sets of need pos and neg are\n",
            "[[0, 1, 1], [0, 2, 0], [1, 0, 0], [1, 1, 1], [1, 3, 0], [2, 2, 1]]\n",
            "[[1, 1, 0], [2, 1, 0], [2, 2, 0], [2, 3, 0]]\n",
            "adding more positive\n",
            "[0, 1, 1]\n",
            "0.6494382022471911 13 39 7.47411444141689\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 7 records\n",
            "4321\n",
            "adding more positive\n",
            "[0, 2, 0]\n",
            "0.7466487935656837 99 242 46.7689946277821\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 47 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 0, 0]\n",
            "0.949119373776908 39 70 14.0773092369478\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 14 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 1, 1]\n",
            "0.9986577181208054 91 146 27.4204163868368\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 27 records\n",
            "4321\n",
            "adding more positive\n",
            "[1, 3, 0]\n",
            "0.9566929133858267 62 105 19.6519114688129\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 20 records\n",
            "4321\n",
            "adding more positive\n",
            "[2, 2, 1]\n",
            "0.7109826589595376 15 37 6.60810810810811\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 7 records\n",
            "4321\n",
            "[1, 1, 0]\n",
            "adding more negative\n",
            "0.8915906788247214 601 495 84.4065345474024\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 84 records\n",
            "4321\n",
            "[2, 1, 0]\n",
            "adding more negative\n",
            "1.1191895113230035 297 160 55.6484814398204\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 56 records\n",
            "4321\n",
            "[2, 2, 0]\n",
            "adding more negative\n",
            "0.8922518159806295 105 86 14.9379398592450\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 15 records\n",
            "4321\n",
            "[2, 3, 0]\n",
            "adding more negative\n",
            "1.1797235023041475 39 25 4.36152219873150\n",
            "start depromotion\n",
            "['age', 'race', 'sex']\n",
            "Changed 4 records\n",
            "4321\n",
            "0    2380\n",
            "1    1941\n",
            "Name: class, dtype: int64\n",
            "model accuracy\n",
            "best 0.5142288873478195\n",
            "fpr and fnr\n",
            "0.10098039215686275\n",
            "0.8158844765342961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Leaf"
      ],
      "metadata": {
        "id": "CM-vpguwyt2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set['predicted'] = test_predict\n",
        "# d,d2,d3 = div_results()"
      ],
      "metadata": {
        "id": "JirQHr31ziUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a63ce6-8a24-491f-b5bb-5cf159598255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d,d1,d2 = div_results(\"COMPAS\",\"Massaging-Leaf\",\"DT\")\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massaging-Leaf\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridl.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridl.best_score_)\n",
        "test_predict = gridl.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massaging-Leaf\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "svc.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = svc.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Massaging-Leaf\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0N6uIH9slwL",
        "outputId": "12a5e19a-9566-442e-ef10-b1829bd55510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5047859655944719\n",
            "0.24051395772019024\n",
            "0.09887802846359563\n",
            "accuracy is  0.5780659103187467\n",
            "['COMPAS', 'Massaging-Leaf', 'DT', 0.5047859655944719, 0.24051395772019024, 0.09887802846359563, 0.5780659103187467]\n",
            "\n",
            "rf\n",
            "best 0.5144603688293009\n",
            "fpr and fnr\n",
            "0.10098039215686275\n",
            "0.8158844765342961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5047859655944719\n",
            "0.24051395772019024\n",
            "0.09887802846359563\n",
            "accuracy is  0.5780659103187467\n",
            "['COMPAS', 'Massaging-Leaf', 'RF', 0.5047859655944719, 0.24051395772019024, 0.09887802846359563, 0.5780659103187467]\n",
            "\n",
            "logistic\n",
            "best 0.5364466147839934\n",
            "fpr and fnr\n",
            "0.0803921568627451\n",
            "0.8279181708784596\n",
            "0.4816722778874921\n",
            "0.22479409120253085\n",
            "0.09414946758815373\n",
            "accuracy is  0.5840086439762291\n",
            "['COMPAS', 'Massaging-Leaf', 'L', 0.4816722778874921, 0.22479409120253085, 0.09414946758815373, 0.5840086439762291]\n",
            "\n",
            "svm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fpr and fnr\n",
            "0.10098039215686275\n",
            "0.8158844765342961\n",
            "0.5047859655944719\n",
            "0.24051395772019024\n",
            "0.09887802846359563\n",
            "accuracy is  0.5780659103187467\n",
            "['COMPAS', 'Massaging-Leaf', 'SVM', 0.5047859655944719, 0.24051395772019024, 0.09887802846359563, 0.5780659103187467]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Algorithm Top"
      ],
      "metadata": {
        "id": "i6oj1yzvyuNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "\n",
        "new_train_data = copy.deepcopy(train_set)\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "all_names_lst_top = find_top(all_names)\n",
        "for a in all_names_lst_top:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], compas_y)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, compas_y)\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  # print(temp_g)\n",
        "  # print(temp2, names)\n",
        "  # print(temp)\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, compas_y)\n",
        "  start = time.time()\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, compas_y, lst_of_counts)\n",
        "  end = time.time()\n",
        "  excute_time = end - start\n",
        "  print(\"The time to compute unfair group is {}\".format(str(excute_time)))\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  # print(\"started duplication\")\n",
        "  new_train_data = naive_massaging(new_train_data, temp2, names, need_pos, need_neg, compas_y)\n",
        "  # print(new_train_data)\n",
        "  # new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "  # new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "  # new_train_label = new_train_label[compas_y]\n",
        "  # new_train_label = new_train_label.astype('int')\n",
        "  # grid_new = DecisionTreeClassifier(criterion=\"entropy\",max_depth=6, random_state=17)\n",
        "  # grid_new.fit(new_train_x, new_train_label)\n",
        "  # test_predict = grid_new.predict(test_x)\n",
        "  # print(\"new trainset length\", len(new_train_x))\n",
        "  # print(\"fpr\", fpr_onegroup(list(test_label), test_predict))\n",
        "  # print(\"fnr\", fnr_onegroup(list(test_label), test_predict))\n",
        "  print(new_train_data['class'].value_counts())\n",
        "new_train_x = pd.DataFrame(new_train_data, columns = columns_compas)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [compas_y])\n",
        "new_train_label = new_train_label[compas_y]\n",
        "new_train_label = new_train_label.astype('int')\n",
        "grid_new = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = param, cv = 6)\n",
        "grid_new.fit(new_train_x, new_train_label)\n",
        "print(\"model accuracy\")\n",
        "print(\"best\", grid_new.best_score_)\n",
        "test_predict = grid_new.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d82f31c-db10-4526-8a15-bb8a01ddcb9e",
        "id": "lXWlcnvmzaef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?????/////\n",
            "1\n",
            "The time to compute unfair group is 0.0060269832611083984\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2343\n",
            "1    1978\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "2\n",
            "The time to compute unfair group is 0.0072002410888671875\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2343\n",
            "1    1978\n",
            "Name: class, dtype: int64\n",
            "?????/////\n",
            "3\n",
            "The time to compute unfair group is 0.003556966781616211\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "0    2343\n",
            "1    1978\n",
            "Name: class, dtype: int64\n",
            "model accuracy\n",
            "best 0.6051783145836545\n",
            "fpr and fnr\n",
            "0.3509803921568627\n",
            "0.4608904933814681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Top"
      ],
      "metadata": {
        "id": "YylnNCsvyuuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set['predicted'] = test_predict\n",
        "# d,d2,d3 = div_results()"
      ],
      "metadata": {
        "id": "b-5OxZ1MzjoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23915f1e-8041-4a73-f3de-c345b7fc0d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d,d1,d2 = div_results(\"COMPAS\",\"Massaging-Top\",\"DT\")\n",
        "print()\n",
        "print(\"rf\")\n",
        "gridrf.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridrf.best_score_)\n",
        "test_predict = gridrf.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massaging-Top\",\"RF\")\n",
        "\n",
        "print()\n",
        "print(\"logistic\")\n",
        "gridl.fit(new_train_x, new_train_label)\n",
        "print(\"best\", gridl.best_score_)\n",
        "test_predict = gridl.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "r,r2,r3 = div_results(\"COMPAS\",\"Massaging-Top\",\"L\")\n",
        "\n",
        "print()\n",
        "print(\"svm\")\n",
        "svc.fit(new_train_x, new_train_label)\n",
        "# print(\"best\", svc.best_score_)\n",
        "test_predict = svc.predict(test_x)\n",
        "print(\"fpr and fnr\")\n",
        "# print(fpr_onegroup(new_labels.tolist(), predict))\n",
        "# print(fnr_onegroup(new_labels.tolist(), predict))\n",
        "print(fpr_onegroup(list(test_label), test_predict))\n",
        "print(fnr_onegroup(list(test_label), test_predict))\n",
        "test_set['predicted'] = test_predict\n",
        "s,s2,s3 = div_results(\"COMPAS\",\"Massaging-Top\",\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWUjzEK5smxi",
        "outputId": "32a76b74-b79c-4c1b-a35f-0c3afe14423f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0452612894198687\n",
            "0.5367298655917477\n",
            "0.06840316723975033\n",
            "accuracy is  0.5996758508914101\n",
            "['COMPAS', 'Massaging-Top', 'DT', 1.0452612894198687, 0.5367298655917477, 0.06840316723975033, 0.5996758508914101]\n",
            "\n",
            "rf\n",
            "best 0.604946833102173\n",
            "fpr and fnr\n",
            "0.3509803921568627\n",
            "0.4608904933814681\n",
            "1.0452612894198687"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0.5367298655917477\n",
            "0.06840316723975033\n",
            "accuracy is  0.5996758508914101\n",
            "['COMPAS', 'Massaging-Top', 'RF', 1.0452612894198687, 0.5367298655917477, 0.06840316723975033, 0.5996758508914101]\n",
            "\n",
            "logistic\n",
            "best 0.5975435994246674\n",
            "fpr and fnr\n",
            "0.38333333333333336\n",
            "0.4332129963898917\n",
            "1.0149613181916723\n",
            "0.5583832084813722\n",
            "0.0746544058565157\n",
            "accuracy is  0.5942733657482442\n",
            "['COMPAS', 'Massaging-Top', 'L', 1.0149613181916723, 0.5583832084813722, 0.0746544058565157, 0.5942733657482442]\n",
            "\n",
            "svm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fpr and fnr\n",
            "0.3509803921568627\n",
            "0.4608904933814681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/divexplorer/FP_DivergenceExplorer.py:489: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  fp = fp.append(row_root, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0452612894198687\n",
            "0.5367298655917477\n",
            "0.06840316723975033\n",
            "accuracy is  0.5996758508914101\n",
            "['COMPAS', 'Massaging-Top', 'SVM', 1.0452612894198687, 0.5367298655917477, 0.06840316723975033, 0.5996758508914101]\n"
          ]
        }
      ]
    }
  ]
}
